{"meta":{"title":"TheSakura's Blog","subtitle":null,"description":null,"author":"chenxiang","url":"http://yoursite.com","root":"/"},"pages":[{"title":"about-me","text":"","path":"about-me/index.html"},{"title":"categories","text":"","path":"categories/index.html"},{"title":"tags","text":"","path":"tags/index.html"}],"posts":[{"title":"paxos算法","text":"paxos算法paxos算法中不包括阴奉阳违的问题。 首先说明一下paxos的算法过程 Paxos 是一个两阶段算法。我们把第一个阶段叫做准备（Prepare）阶段，第二个阶段叫做接受（Accept）阶段。分别对应两轮 RPC。 主要分为 提案节点proposer，主要是针对某个值发起提案，如果值被设置成功，那么就不可以进行改变了，请注意，Paxos 是典型的基于操作转移模型而非状态转移模型来设计的算法，这里的“设置值”不要类比成程序中变量赋值操作，应该类比成日志记录操作，在后面介绍的 Raft 算法中就直接把“提案”叫作“日志”了。 决策节点Acceptor，应答提案的节点，决定这个提案是否可被投票、是否可被接受。提案一旦得到过半数决策节点的接受，即称该提案被批准（Accept），提案被批准即意味着该值不能再被更改，也不会丢失，且最终所有节点都会接受该它。（这个应该就是类似raft的日志被提交）。 记录节点 Learner，只是单纯地从提案、决策节点中学习已经达成共识的提案，譬如少数派节点从网络分区中恢复时，将会进入这种状态。 我们注意，paxos中每隔节点是平等的，可以担任多个角色，不过为了便于确保有明确的多数派，决策节点的数量应该被设定为奇数个，且在系统初始化时，网络中每个节点都知道整个网络所有决策节点的数量、地址等信息。 这里paxos为了就提案达成一致性主要是使用两阶段的办法来进行保证的。 第一轮 Prepare RPCs： 请求（也叫 Prepare 阶段）：Proposer 选择一个提案编号 n，向所有的 Acceptor 广播 Prepare(n) 请求。 响应（也叫 PROMISE 阶段）：Acceptor 接收到 Prepare（n) 请求，这个时候他会保证1.不会接收提案号小于等于n的prepare请求。2.承诺不会接受提案号小于n的Accpet请求。 同时在不违背以前承诺的前提下，回复已经批准过的提案中 ID 最大的那个提案所设定的值和提案 ID，如果该值从来没有被任何提案设定过，则返回空值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Prepare 请求不予理会。 第二轮当提案节点收到了多数派决策节点的应答（称为 Promise 应答）后，可以开始第二阶段“批准”（Accept）过程，这时有如下两种可能的结果： 如果提案节点发现所有响应的决策节点此前都没有批准过该值（即为空），那说明它是第一个设置值的节点，可以随意地决定要设定的值，将自己选定的值与提案 ID，构成一个二元组“(id, value)”，再次广播给全部的决策节点（称为 Accept 请求）。 如果提案节点发现响应的决策节点中，已经有至少一个节点的应答中包含有值了，那它就不能够随意取值了，必须无条件地从应答中找出提案 ID 最大的那个值并接受，构成一个二元组“(id, maxAcceptValue)”，再次广播给全部的决策节点（称为 Accept 请求）。 当每一个决策节点收到 Accept 请求时，都会在不违背以前作出的承诺的前提下，接收并持久化对当前提案 ID 和提案附带的值。如果违反此前做出的承诺，即收到的提案 ID 并不是决策节点收到过的最大的，那允许直接对此 Accept 请求不予理会。 当提案节点收到了多数派决策节点的应答（称为 Accepted 应答）后，协商结束，共识决议形成，将形成的决议发送给所有记录节点进行学习。 参考链接此时有两种情况： multi paxos算法","path":"2022/08/10/分布式/paxos算法/"},{"title":"零拷贝","text":"这个主要是用于文件传输场景的。 一个文件从磁盘中读出来，然后写到网卡中。 如果使用正常的操作 这个过程一开始会使用DMA控制器复制磁盘数据到内核缓冲区。 然后使用CPU将数据从内核缓冲区读到内存中。（read系统调用) 然后使用CPu将数据写到socket缓冲区中。（write系统调用） 然后使用DMA将socket的内容写到网卡中。 这样的过程经过了四次拷贝，四次上下文切换。 解决这个的办法主要有零拷贝技术 1.mmap通过将内核缓冲区的内容映射到内存中，可以减少系统调用，这里我们使用mmap替换read，然后进入内核态，写到socket缓冲区的时候，可以直接将内核缓冲区通过CPU拷贝到socket缓冲区，然后返回。 这里减少了一次拷贝，但是上下文切换还是四次，mmap需要上下文切换，write也需要上下文切换。 2. sendfile通过sendfile可以直接将内核缓冲区的内容拷贝到socket缓冲区，这样就只有两次上下文切换，同时三次数据拷贝。 3. SG-DMA通过SG-DMA技术可以 将数据读到内核缓冲区 将数据直接从内核缓冲区写到网卡缓冲区。 总体只需要两次上下文切换和数据拷贝。 大文件传输但是大文件的传输会使用到pagecache技术，会读很多内容到内存，容易占满内存，影响小文件的读取，因此不使用0拷贝技术比较好。 这里我们可以使用直接IO的方式，就是通过读异步的方式，进行读取直接读到用户缓冲区，然后我们cpu可以执行其他任务，然后读完就IO成功了 当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。","path":"2022/08/10/操作系统/零拷贝/"},{"title":"面经","text":"C++ shard_ptr如何保证线程安全,shard_ptr中make_shard和new初始化有什么区别？ shardptr在赋值的时候要赋值ptr，同时复制引用计数指针，因此在多线程中使用shardptr要加锁。 make_shard 只分配一次内存，对象和shardptr对象的引用计数放在一起，但是new的方式会分配两次内存，对象的区域和shard_ptr对象的引用计数的区域不是一个位置。 同时如果使用prosswidget(std::shard_ptr(new widget));而不是prosswidget(std::make_shard()));可能会导致潜在的内存泄漏问题。因为编译器可能会先new，然后执行函数，然后才初始化shard_ptr,如果函数出现异常，那么new的对象就泄漏了，因为它不会被放到shard_ptr中。 weak_ptr最初的引入，是为了解决shared_ptr互相引用导致的内存无法释放的问题。其lock接口是原子性的。 emplace_back和push_back区别，移动语义底层实现移动语义减少了拷贝，避免反复构造、析构持有资源的对象 在STL中，move只是进行了转换，如果是左值推导为左值引用，然后使用static_cast转为右值引用，如果传的是右值，推导为右值引用，然后使用static_cast转为右值引用 alloc的两级空间配置器，和malloc的方式？alloc的第二级配置器是用的很多个8的倍数的空闲链表的来实现的小于128k的时候使用这个，超过128k使用malloc的方式进行空间分配。这样可以使得小对象快速分配。 malloc对于小的对象会在堆区分配，移动brk指针来分配，然后超过128k的会在共享映射区通过mmap来实现，mmap的原理就算通过将一段虚拟内存空间和物理空间映射起来。当写这块内存区域的时候就相当于写这块物理区域，系统会自动把脏页刷到磁盘上。同时在内核空间对这段空间的修改也反应在用户空间上，从而可以实现不同进程之前的文件共享。 设计模式知道哪些单例设计模式，工厂模式，迭代器设计模式 RPC原理，和Restful区别，为什么有了RPC还需要HTTP raft怎么保持一致性 主要是通过三个方法，一个是选举机制，日志复制，以及保证安全的三个机制。 选举会超时一段随机的时间没有leader的心跳的时候会发起选举，然后先投票给自己，然后如果收到来自超过半数的投票，那么就变为leader，定时向其他节点发送心跳和复制日志。 复制日志的时候，会将日志发送给其他机器上，如果有超过半数的机器都得到了这个日志，那么说明这个内容是可以提交的，每次有一个提交的索引号，然后follower会提交这个日志。 保证安全是只有含有已提交的日志的机器才能成为leader，leader不能够提交上一个任期的日志只能在复制自己的任期的日志到大部分的时候，顺带提交上一个任期的日志。 shardKV中，一个节点上的KV太多，怎么使得数据变得均匀。 增加group或者移动分片 超过半数的决策如何保证leader日志的完整性，为什么使用log，不直接写，如何解决split vote，了解paxos吗 split vote是平票的情况，这个在raft中是通过随机时间来解决的，每个机器等待发起选举的时间是随机的，可以有效防止这个情况。 STL内存池 如何实现无锁队列，输入url中，哪些优化可以提升响应速度。cookie和session，浏览器如何访问本地缓存。 Raft如何保证节点之间的log一致性，主要讨论了旧的Leader挂掉之后产生新的leader，如何保证它们对于log commmit认知一样。 只有具有最新的提交的日志的机器才能成为leader，同时提交这个任期日志的时候顺带提交上一个任期的日志 move转让所有权之后，再调用会发生什么。 stack底层实现，vector为什么是倍数增加不是定量。 raft数据分片如何在raft组间转移。三个协程不断运行：拉取日志协程：通过config group进行管理，更新配置均匀，然后其他的数据group会有一个协程定期的拉取shard的配置，如果配置更新那么看自己有没有之前还没拉到的shard，或者有需要传输的，那么就不做，否则就先向底层的raft写一个更新config的操作。 拉取shard协程：每隔一段时间，就对pullmap中的需要拉取的shard进行拉取（为true），给出args参数，对于返回的reply，如果成功，到底层的raft日志中写入添加shard命令，如果pullmap的valid为false，说明需要删除，向对方发起删除RPC的请求，对于返回的reply，如果成功，向raft添加删除pullmap的命令 处理raft状态机的协程：如果不是快照命令，如果是更新配置op，那么会更新配置，同时需要拉取的会写入pullmap，然后更新配置。 具体拉取shard，更新了对应shard的kvdb，以及clientseqNum,并且将kv.pullMap的valid设置为false，同时更新shardsVerNum 如果是删除pullmap的op命令的话，直接删除即可。 如果是删除shard分片的命令，那么就将对应的kvdbs，clientseqnum置空 如果是一些用户的请求，那么就直接看是不是这个group管理的，在shard版本号和config号对不上时，说明在传输中，刷新resch，如果配置号一致，在数据库中执行操作，如果不是这个group管理的，向结果管道写入错误的group 多继承的时候，虚函数表如何存。 std::cin和using namespace std 之后使用cin有什么区别。后者可能导致命名冲突，最好不要在头文件中使用后面的情况，这样别人的cpp文件也默认就using namespace std了。 元编程 每个进程的虚拟内存有多大，如果物理内存大于4G，可以不使用虚拟内存吗？如果只有单任务，以及不支持分页的操作系统，可以放弃虚拟内存。但是虚拟内存是指多个任务可以使用超过4G的内存 日志被复制到大多数，但是leader没提交就崩溃了，这个日志会被提交吗？会，只有含有这个日志的机器才会成为leader，然后在下一任leader提交日志的时候顺带提交日志。 redo log的作用，为什么不用提交时刷盘来保持持久性，2PC中，prepare阶段做什么。 lambda表达式特点，可以获得lambda函数的函数指针吗 没有捕获变量的lambda表达式可以直接转换为函数指针，而捕获变量的lambda表达式则不能转换为函数指针。 lease在raft中有什么使用，lease机器间的时间不对齐怎么处理 join有哪些，如果有两张表，数据很多，分布在不同的机器上，哪个join效率更高？ raft成员变更，如果就配置为abc，更新为def，如果共同一致的情况下bc挂掉，那么成员变更还可以继续执行吗？ 口述设计一个线程池初始化构建n个线程池，然后当任务队列不为空的时候不断取出数据，然后运行，为空的时候wait 关闭文件的时候会清楚page cache吗 2PC中，如果一个参与者挂了，那么怎么处理？ CAP理论，举例AP和CP的例子。 工业中对于读操作会怎么处理 malloc可以给复杂类分配空间吗，如何让new失败的时候不抛出异常可以，设置new (std::nothrow) int[10],或者设置一个new_handle函数 出现网络分区会有什么情况，恢复之后呢 少数派可能会不断发起选举，但是总是不会成功，然后任期会很大，造成恢复之后，导致leader转为follower，但是实际上它们不可能成为leader，因为没有已经提交的日志，只是这样会打乱日志。","path":"2022/08/02/面试题/面经/"},{"title":"场景题","text":"设计一个域名转换服务器，提供两个接口，从短域名转长域名，或者从长域名转短域名 参考连接 主要是通过K，V查，假设对应的网址是 url/id，查id，然后看id是否有，有的化就将id对应的长连接给过来，然后通过301永久重定向到对应网址。转短域名相反。","path":"2022/08/02/面试题/场景题/"},{"title":"","text":"","path":"2022/08/02/新建 MD_AUTO_FILE 文件/"},{"title":"MapReduce","text":"mapreduce过程MapReduce 主要是分为map过程和reduce过程，主要是这几个步骤： 数据一开始被分为M个分片，然后在机群中创建很多程序副本，一般每个分片是16到64M。 这些副本有些事master，有些是worker，由master分配任务，有M个map任务和R个master任务。master分配一个map或者recude任务给worker。 分配了map任务的worker读取对应的输入数据片段，然后解析出Key、value对（这是对于计算单词数目来说的，机械的对于每个单词记录count为1），然后将这些key、value对传给map函数，它生成并输出中间的key、value对存在内存中。（这个就是相当于将开始混乱的文档，输出成了每个单词，单词数目的对） 内存中的这些pair通过partition函数（先hash（key）mod R，相同key总是在相同位置）分成R个区域，然后周期性的写到本地磁盘上（即map函数会在R个文件写），这些本地磁盘的存储位置会被传送给master，然后master告知reduce worker。 reduce得到位置信息后，通过RPC从map worker所在主机的磁盘上读取对应它需要的parittion数据（注意R和M是远大于worker数目的，那么worker很可能负责多个R，因此需要排序，然后合并聚合），然后通过排序使得所有相同key的聚合在一起，由于不同的key会被映射到相同的reduce 任务上，因此必须排序，然后如果内存不够，会使用外部排序。 reduce worker将这些排完序的数据相同key的对应的value传送给reduce函数，然后reduce函数进行处理，输出追加到对应分区的输出文件中。 map和reduce任务完成之后，master唤醒用户程序，mapreduce返回。 最后所有的输出都在R个输出文件中。 master数据结构，存储每一个map任务和reduce任务空闲或者不空闲，存储worker节点是否空闲。还储存了map任务的中间文件存储的位置。 容错性worker故障在 MapReduce 集群中，Master 会周期地向每一个 Worker 发送 Ping 信号。如果某个 Worker 在一段时间内没有响应，Master 就会认为这个 Worker 已经不可用。 出现故障的时候，worker正在运行的以及已经运行的作废，需要重新分配给其他worker处理。但是reduce已经完成的是不需要的，因为map中间的结果是局部机器上的，但是reduce是全局机器上的。 同时将需要从故障机器上读取数据的reduce会从新机器上读取。 master失败周期性地将内容写进磁盘，然后如果master失效了，可以从磁盘中读取然后启动另外的master进程。 失效的一些处理机制每个任务都将它的输出输出到临时文件中，map会输出R个这样的文件，master会记录这R个文件的位置，reduce只会输出一个文件。 当reduce任务完成得时候，reduce work会以原子得方式将临时文件修改成最终得输出文件。 存储位置尽量将map任务分配给保存有对应数据得机器上进行执行。这可以减少网络带宽耗费。 任务粒度M和R一般比集群中得worker数量多很多。 备用任务当一台机器很慢，但是其他机器执行快，这会拖慢整体的机器的执行速度。 因此当mapreduce快要完成的时候，会使用备用任务进程来执行剩下的，只要原任务和备用任务有一个完成，就标记为已经完成，可以减少运行时间。 技巧分区函数使用hash进行分区能够产生非常平衡的分区。 combiner函数map函数产生的中间结果会有很多重复的，我们可以现在map本地进行一次合并，然后再通过网络发送给reduce任务。 6.824 lab1整体信息整个任务分为Coordinator（master）和worker进程构成 Coordinator通过RPC与worker通过本地的socket进行rpc通信 Coordinator协调整个MR计算任务，分配Task到worker中。 在启动 Coordinator 进程时指定 输入文件名 及 Reduce Task 数量 在启动 Worker 进程时指定所用的 MR APP 动态链接库文件 Coordinator 需要留意 Worker 可能无法在合理时间内完成收到的任务（Worker 卡死或宕机），在遇到此类问题时需要重新派发任务 Coordinator 进程的入口文件为 main/mrcoordinator.go Worker 进程的入口文件为 main/mrworker.go 我们需要补充实现 mr/coordinator.go、mr/worker.go、mr/rpc.go 这三个文件 Coordinator一开始启动时会给出分片的数目，reduce的R的个数。 Coordinator 中会包含分片文件，以及reduce Task以及Map task，在一开始进行初始化。以及完成的map以及完成的reduce 的个数。以及一把锁，以及是否完成。 Task结构体主要包括，Task是否完成，task类型，索引号，以及任务是否分发。 这里面主要就是在map和reduce里面找到一个对应类型的他上课，然后分发这个任务，分发之后会设置一个定时器，然后在定时一段时间之后，检测任务是否完成，如果没完成，标记为后面可以分发这个任务。 Worker主要包含锁，以及id，以及是否在运行 worker节点主要是不断地向master获取Task，然后进行处理。 如果是Map Task，那么就读取对应的分片文件，然后交给map函数处理得到KV，然后按中间结果 Key 的 Hash 值进行分桶 完成之后通过RPC，告知master 如果是reduce task，读取所有属于该 REDUCE Task 的中间结果文件数据，对所有中间结果进行排序，并按 Key 值进行归并，传递归并后的数据至 MR APP 指定的 REDUCE 函数，得到最终结果，写出到结果文件","path":"2022/08/02/分布式/MapReduce/"},{"title":"initializer_list 和结构化绑定","text":"参考链接 即使用列表来进行初始化的方法 vector&lt;int&gt; value = &#123;1,3,6,9,10&#125;; vector&lt;int&gt; velue&#123;1,3,6,9,10&#125;; int array[]&#123;1,3,6,9,10&#125;; struct A &#123; A(initializer_list&lt;int&gt; lists) &#123; auto it = lists.begin(); x = *it++; y = *ot; &#125; int x; int y; &#125;; A a&#123;1,2&#125;; 结构化绑定 结构化绑定主要说的是对于一些public成员，数组，pair之类的可以直接获得 auto [a, b] = pair(2, &quot;3&quot;s); int arr[] = &#123;1, 2&#125;; const auto&amp; [m, n] = arr; cout &lt;&lt; m &lt;&lt; n &lt;&lt; endl; //12","path":"2022/07/31/C++/C++初始化列表和结构化绑定/"},{"title":"thread_local、 注解attribute","text":"thread_local主要是用于声明对象是属于线程存储区的，线程存储期的变量，在线程开始的时候初始化，线程结束的时候释放掉，可以和static一起使用 static thread_local int a; 这个话说明a是属于线程存储期的，不同线程的a是不一样的，在线程内部表现起来和static一样，但是不同线程不一样 注解attribute[[noreturn]]// 正确，函数将永远不会返回。 [[noreturn]] void func1() &#123; throw &quot;error&quot;; &#125; // 错误，如果用false进行调用，函数是会返回的，这时候会导致未定义行为。 [[noreturn]] void func2(bool b) &#123; if (b) throw &quot;error&quot;; &#125; 表示一个函数永远不会返回 [[carries_dependency]]这个属性的作用是允许我们将dependency跨越函数进行传递，用于避免在弱一致性模型平台上产生不必要的内存栅栏导致代码效率降低。一般来说，这个属性是搭配 std::memory_order_consume 来使用的，支持这个属性的编译器可以根据属性的指示生成更合适的代码帮助程序在线程之间传递数据。在典型的情况下，如果在 memory_order_consume 的情况下读取一个值，编译器为了保证合适的内存读取顺序，可能需要额外的内存栅栏协调程序行为顺序，但是如果加上了[[carries_dependency]]的属性，则编译器可以保证函数体也被扩展包含了同样的dependency，从而不再需要这个额外的内存栅栏。同样的事情对于函数的返回值也是一致的。参考如下例子代码： std::atomic p; std::atomic q; void func1(int *val) &#123; std::cout &lt;&lt; *val &lt;&lt; std::endl; &#125; void func2(int * [[carries_dependency]] val) &#123; q.store(val, std::memory_order_release); std::cout &lt;&lt; *q &lt;&lt; std::endl; &#125; void thread_job() &#123; int *ptr1 = (int *)p.load(std::memory_order_consume); // 1 std::cout &lt;&lt; *ptr1 &lt;&lt; std::endl; // 2 func1(ptr1); // 3 func2(ptr1); // 4 &#125; 程序在1的位置因为ptr1明确的使用了memory_order_consume的内存策略，所以对于ptr1的访问一定会被编译器排到这一行之后。因为1的原因，所以2这一行在编译的时候势必会排列在1后面。func1并没有带任何属性，而他访问了ptr1，那么编译器为了保证内存访问策略被尊重所以必须在func1调用之间构建一个内存栅栏。如果这个线程被大量的调用，这个额外的内存栅栏将导致性能损失。在func2中，我们使用了[[carries_dependency]]属性，那么同样的访问ptr1，编译器就知道程序已经处理好了相关的内存访问限制。这个也正如我们再func2中对val访问所做的限制是一样的。那么在func2之前，编译器就无需再插入额外的内存栅栏，提高了效率。 [[deprecated]]表示某个实体在未来会被删除 [[fallthrough]]一般有些编译器在case之后不加break会给警告，这里是表明是故意这么干的 [[nodiscard]]这个是告诉编译器，对于这个修饰的函数，如果按照值返回的时候，返回值不应该被丢弃，如果丢弃会有警告。 对于修饰的类或者枚举类型，返回该类型的时候也不应该丢弃结果 [[maybe_unused]]对声明了但是没使用的变量给出警告信息 [[likely]] 和 [[unlikely]]告诉编译器哪个语句更可能运行，可以用在switch case中，编译器可以进行优化。 [[no_unique_address]]这个是告诉编译器，这个变量可以与其他非相同类型的变量共享内存空间，如果有两个相同的no_unique_address，那么只有一个能够共享空间，另外一个还是需要空间。 参考链接","path":"2022/07/31/C++/thread_local和注解用法/"},{"title":"Go常见知识点","text":"Go常见知识点1. new 主要是返回指针，make返回的是引用，new可以对任意类型使用，但是make主要针对map，slice，channel new 分配的空间被清零。make 分配空间后，会进行初始化； 2. slice，是一个包含长度，容量，以及指向数组的指针。类似动态数组，在超过大小的时候会自动扩容， a:=make([]int,5,3) a=[]int&#123;1,2,3&#125; var a []int 这个切片为nil，大小容量为0，指针为nil a:=make([]int,0)这个是声明空切片 容量大小为0，还没分配数组空间 b:=a[1:2]这种会创建新切片，指针指向原来数组的中间某个位置 切片容量小于1024的时候，扩容为2倍，大于1024，扩容倍数为1.25 迭代切片可以使用 for index,val :=range slice 来进行，或使用for i:=1;i&lt;len(slice);i++ 多维切片：[][]int &#123;&#123;1&#125;,&#123;2&#125;&#125; 复制slice的时候是值传递，复制切片，但是不是深拷贝，不复制数组 3. map 用法 a:=make(map[string]int) 获取map的两种方法，val,ok:=a[key] if ok!=nil&#123;&#125; 或者val:=a[key] if val!=0&#123;&#125; var a map[string]int,这个是创建nil的map，不能进行插入，插入会报错 map传进函数的时候不会创建副本，做的修改会被看到 4. struct： type a struct&#123;&#125; 可以定义结构体 var mystruct a 定义一个结构体，里面的内容会被初始化为0值 5. 编译器不会进行隐式转换，需要显示转换 6. 多个gorontinue 在没有同步的情况下访问同一块内存区域，进行读写就是竞态条件 7. chan 管道类型，包括有缓冲的管道和无缓冲的管道，a:=make(chan string,10),a&lt;-发数据，b:=&lt;-a接收数据 无缓冲的管道发送数据的时候会等待到对方直到阻塞，而接收方如果等待来自发送方的数据也会阻塞 一个nil channel不会通信，发数据和nil的channnel或者从nil的channel里面读取数据会导致永久阻塞，给已经关闭的channel发送数据会导致panic，从已经关闭的channel中读取数据，如果缓冲区为空，返回零值。 8. 类型开关，可以运行时检查变量类型，switch t:=a.(type)&#123;case int64:....default:&#125; 9. 接口之间存在的关系，如果A接口和B接口的方法列表是一样的，那么可以相互赋值，如果A是B的子集，那么B可以赋值给A 10. mutex，mutex主要有几种状态 mutexlocked，已经处于锁定状态 mutexwoken，从正常模式被唤醒 mutexstarving，互斥锁进入饥饿状态 mutexcount，互斥锁上等待的go协程个数 正常模式（性能好）：所有的等待锁的协程按照先进先出的方式顺序等待，唤醒 的协程不会直接拿到锁，需要和新请求的协程竞争锁，新请求的锁有优势，因为它正常cpu执行，更大概率拿到锁，如果超过1ms没有拿到锁，就会变成饥饿模式 饥饿模式（公平模式）：下面直接将锁给队头的协程，然后新来的协程回加到队尾，可以解决老的g一直抢不到锁的状态 mutex进入自旋的情况： mutex 在锁被占用，并且不处于饥饿状态，并且积累的自旋次数小于最大的自旋次数（4） cpu核大于1 有空闲的p。当前g挂载的p，本地待运行队列为空 11. RWmutex实现，是通过记录读锁的数量来控制的，有一个写锁的时候，会记录读锁的数目为-1&lt;&lt;30,然后新进入的读锁会等待，写锁完成释放之后，会加上1&lt;&lt;30,然后通知刚才到来的读锁。 RWmutex在没加锁的情况下释放会panic，rwmutex与特定状态的协程没有关系，可以一个协程加锁，另外一个协程释放锁。 写锁被解锁之后，因为锁定读锁而阻塞的那些协程会被唤醒，从而可以锁定读锁。读锁释放的时候，在没有其他读锁锁定的情况下，那些阻塞的写锁中等待时间最长的协程会被唤醒。主要用于读多写少的情况。 12. GMP：G指的是协程，用户态得轻量级线程，每个gorontine的对象中的sched保存着其上下文信息。 M：对内核级线程的封装，数量对应真实的CPU数目 P：G和M的调度对象，用来调度G和M之间的关联关系，数量可以设置，一般默认为核心数目 GMP的调度流程，一般每个P都有一个g队列，存储需要运行的g，然后还有一个全局队列，每次有g到来的时候，先均匀的加到每个P中，直到每个P都满了，那么就会加到全局队列中，当某个P的队列的G运行完了，会去全局队列取G运行，全局队列没有了，会去其他的P中的队列里面拿，一般是取一半的数据。当某个G因为系统调用阻塞了，M会阻塞，然后P以及它的G队列会去找其他的M运行，如果G因为IO阻塞了，M不会阻塞，回去运行其他的G。 13. sysmon ：监控线程，主要是，超过两分钟没有垃圾回收，强制执行，向长时间运行的G进行抢占调度。收回因为系统调用长时间阻塞的P 14. 三色标记原理：首先有根节点，一开始所有的节点都是白色的，然后将白色的标记为灰色，然后不断地将灰色地引用地对象标记为灰色，把之间地灰色标记为黑色，直到没有灰色节点。然后清除白色节点。 15. 插入写屏障，这个意思就是每次你新引用一个节点地时候，需要将其复值为灰色，因为为了防止它是黑色导致它引用不到被回收。 在没有混合屏障之前一直都是插入写屏障。启动插入写屏障是针对堆地，栈是没有启用这个东西地，需要STW。go地解决办法是，在结束地时候启动STW来重新扫描栈。因此需要停顿，但是后面使用混合写屏障解决这个问题了，没有STW了。 16. 删除写屏障，就是每次删除一个引用，就给引用地那个赋值成灰色，这个是为了防止我删除的原来节点是灰色或者白色，然后还有黑色的指向它，导致它被回收。 go没有这一步，go地写屏障是从插入写屏障到混合写屏障过度地，这个可能会导致它应该被回收，但是没有活到了下一轮，在下一轮被回收。 17. 混合写屏障，具体是，一开始将栈对象全部扫描标记为黑色，GC期间任何在栈上创建的均为黑色。被删除的对象标记为灰色，被添加的对象标记为灰色 它继承了插入写屏障的优点，一开始不需要STW打快照，直接并发扫描垃圾即可。 继承了删除写屏障的优点，GC期间，任何栈上创建的对象均为黑色，扫面一遍之后就不需要了，因此不需要插入写屏障最后的STW的重新扫描栈。 精度继承了删除写屏障，比插入写屏障更低，GC全过程没有 STW。 虽然没有STW，但是具体扫描某个栈还是需要停止这个G的赋值器的工作的。（针对一个G栈来说，是暂停扫的，要么全灰，要么全黑，原子状态切换） 18. GC触发时期：手动触发GC，每隔2minGC一次。使用步调算法，当堆的大小与上一次GC剩下的堆的大小成比例的时候触发GC。 19. GC的流程： 标记准备阶段：为并发标记做准备，启动写屏障 扫描标记阶段，与赋值器并发执行，写屏障开启 标记终止阶段：标记任务完成，停止写屏障 内存清扫阶段，回收内存给堆，关闭写屏障 内存归还阶段：将内存归还给操作系统 20. GC调优，扩大GOGC的GC的内存倍数，就是需要更大的堆的时候才GC。限制goroutine的数量，提高赋值器对CPU的利用率，减少并复用内存，例如使用 sync.Pool 来复用需要频繁创建临时对象，例如提前分配足够的内存来降低多余的拷贝。","path":"2022/07/29/GO/GO 常见知识点/"},{"title":"Redis","text":"RDB将数据库状态保存为快照，存在磁盘上， 一种是通过子进程去保存，不阻塞 一种是阻塞直到保存成功 RDB文件是二进制文件 不同类型的键值对，RDB文件会使用不同的方式来保存 AOF保存所有修改数据库的写命令来记录服务器的数据库状态 AOF文件的所有命令都会以Redis命令请求协议的格式保存 命令请求会先保存到AOF缓冲区中，然后定期写入并同步到AOF文件中。 使用AOF的时候服务器载入并重新执行保存在AOF中的命令，即可还原数据库状态。 AOF重写就是通过将读数据库的键值对来实现，程序不需要对现有的AOF文件进行读取，分析和写入，而是重新生成新的AOF文件，这个AOF与原来的AOF保存的数据库状态一样，体积更小。 在BgrewriteAof的时候，Redis会记录一个AOF重写缓冲区，在子进程创建新的AOF的文件的时候，这个缓冲区可以记录服务器的写命令。子进程完成之后，这个缓冲区的内容会追加到AOF文件的末尾。使得两个AOF所保存的数据库状态一致。然后用新的AOF替换旧的AOF文件，实现AOF重写。 服务器一个命令请求从发送到完成主要包括以下步骤: 1)客户端将命令请求发送给服务器; 2）服务器读取命令请求，并分析出命令参数; 3）命令执行器根据参数查找命令的实现函数，然后执行实现函数并得出命令回复; 4)服务器将命令回复返回给客户端。servercron函数默认每隔100毫秒执行一次，它的工作主要包括更新服务器状态信息，处理服务器接收的SIGTERM信号，管理客户端资源和数据库状态，检查并执行持久化操作等等。 服务器从启动到能够处理客户端的命令请求需要执行以下步骤: 1)初始化服务器状态; 2）载入服务器配置; 3)初始化服务器数据结构; 4)还原数据库状态; 5)执行事件循环。 多机Redis多台服务器要保存同一份数据，这里问题就来了。 这些服务器之间的数据如何保持一致性呢？数据的读写操作是否每台服务器都可以处理？ Redis 提供了主从复制模式，来避免上述的问题。 这个模式可以保证多台服务器的数据一致性，且主从服务器之间采用的是「读写分离」的方式。 主服务器可以进行读写操作，当发生写操作时自动将写操作同步给从服务器，而从服务器一般是只读，并接受主服务器同步过来写操作命令，然后执行这条命令。 也就是说，所有的数据修改只在主服务器上进行，然后将最新的数据同步给从服务器，这样就使得主从服务器的数据是一致的。 同步这两个字说的简单，但是这个同步过程并没有想象中那么简单，要考虑的事情不是一两个。 我们先来看看，主从服务器间的第一次同步是如何工作的？主从服务器间的第一次同步的过程可分为三个阶段： 1. 第一阶段：建立链接、协商同步 执行了 replicaof 命令后，从服务器就会给主服务器发送 psync 命令，表示要进行数据同步。 psync 命令包含两个参数，分别是主服务器的 runID 和复制进度 offset。 runID，每个 Redis 服务器在启动时都会自动生产一个随机的 ID 来唯一标识自己。当从服务器和主服务器第一次同步时，因为不知道主服务器的 run ID，所以将其设置为 &quot;?&quot;。 offset，表示复制的进度，第一次同步时，其值为 -1。 主服务器收到 psync 命令后，会用 FULLRESYNC 作为响应命令返回给对方。 并且这个响应命令会带上两个参数：主服务器的 runID 和主服务器目前的复制进度 offset。从服务器收到响应后，会记录这两个值。 FULLRESYNC 响应命令的意图是采用全量复制的方式，也就是主服务器会把所有的数据都同步给从服务器。 所以，第一阶段的工作时为了全量复制做准备。 那具体怎么全量同步呀呢？我们可以往下看第二阶段。 2. 第二阶段：主服务器同步数据给从服务器 接着，主服务器会执行 bgsave 命令来生成 RDB 文件，然后把文件发送给从服务器。 从服务器收到 RDB 文件后，会先清空当前的数据，然后载入 RDB 文件。 这里有一点要注意，主服务器生成 RDB 这个过程是不会阻塞主线程的，因为 bgsave 命令是产生了一个子进程来做生成 RDB 文件的工作，是异步工作的，这样 Redis 依然可以正常处理命令。 但是，这期间的写操作命令并没有记录到刚刚生成的 RDB 文件中，这时主从服务器间的数据就不一致了。那么为了保证主从服务器的数据一致性，主服务器在下面这三个时间间隙中将收到的写操作命令，写入到 replication buffer 缓冲区里。 主服务器生成 RDB 文件期间； 主服务器发送 RDB 文件给从服务器期间； 「从服务器」加载 RDB 文件期间； 3. 第三阶段：主服务器发送新写操作命令给从服务器 在主服务器生成的 RDB 文件发送完，从服务器加载完 RDB 文件后，然后将 replication buffer 缓冲区里所记录的写操作命令发送给从服务器，然后「从服务器」重新执行这些操作，至此主从服务器的数据就一致了。 至此，主从服务器的第一次同步的工作就完成了。 命令传播主从服务器在完成第一次同步后，双方之间就会维护一个 TCP 连接。 后续主服务器可以通过这个连接继续将写操作命令传播给从服务器，然后从服务器执行该命令，使得与主服务器的数据库状态相同。 而且这个连接是长连接的，目的是避免频繁的 TCP 连接和断开带来的性能开销。 上面的这个过程被称为基于长连接的命令传播，通过这种方式来保证第一次同步后的主从服务器的数据一致性。 分摊主服务器的压力在前面的分析中，我们可以知道主从服务器在第一次数据同步的过程中，主服务器会做两件耗时的操作：生成 RDB 文件和传输 RDB 文件。 主服务器是可以有多个从服务器的，如果从服务器数量非常多，而且都与主服务器进行全量同步的话，就会带来两个问题： 由于是通过 bgsave 命令来生成 RDB 文件的，那么主服务器就会忙于使用 fork() 创建子进程，如果主服务器的内存数据非大，在执行 fork() 函数时是会阻塞主线程的，从而使得 Redis 无法正常处理请求；传输 RDB 文件会占用主服务器的网络带宽，会对主服务器响应命令请求产生影响。这种情况就好像，刚创业的公司，由于人不多，所以员工都归老板一个人管，但是随着公司的发展，人员的扩充，老板慢慢就无法承担全部员工的管理工作了。 要解决这个问题，老板就需要设立经理职位，由经理管理多名普通员工，然后老板只需要管理经理就好。 Redis 也是一样的，从服务器可以有自己的从服务器，我们可以把拥有从服务器的从服务器当作经理角色，它不仅可以接收主服务器的同步数据，自己也可以同时作为主服务器的形式将数据同步给从服务器 通过这种方式，主服务器生成 RDB 和传输 RDB 的压力可以分摊到充当经理角色的从服务器。 那具体怎么做到的呢？ 其实很简单，我们在「从服务器」上执行下面这条命令，使其作为目标服务器的从服务器： replicaof &lt;目标服务器的IP&gt; 6379此时如果目标服务器本身也是「从服务器」，那么该目标服务器就会成为「经理」的角色，不仅可以接受主服务器同步的数据，也会把数据同步给自己旗下的从服务器，从而减轻主服务器的负担。 增量复制主从服务器在完成第一次同步后，就会基于长连接进行命令传播。 可是，网络总是不按套路出牌的嘛，说延迟就延迟，说断开就断开。 如果主从服务器间的网络连接断开了，那么就无法进行命令传播了，这时从服务器的数据就没办法和主服务器保持一致了，客户端就可能从「从服务器」读到旧的数据。 那么问题来了，如果此时断开的网络，又恢复正常了，要怎么继续保证主从服务器的数据一致性呢？ 在 Redis 2.8 之前，如果主从服务器在命令同步时出现了网络断开又恢复的情况，从服务器就会和主服务器重新进行一次全量复制，很明显这样的开销太大了，必须要改进一波。 所以，从 Redis 2.8 开始，网络断开又恢复后，从主从服务器会采用增量复制的方式继续同步，也就是只会把网络断开期间主服务器接收到的写操作命令，同步给从服务器。 主要有三个步骤： 从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的 psync 命令里的 offset 参数不是 -1；主服务器收到该命令后，然后用 CONTINUE 响应命令告诉从服务器接下来采用增量复制的方式同步数据；然后主服务将主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令。那么关键的问题来了，主服务器怎么知道要将哪些增量数据发送给从服务器呢？ 答案藏在这两个东西里： repl_backlog_buffer，是一个「环形」缓冲区，用于主从服务器断连后，从中找到差异的数据；replication offset，标记上面那个缓冲区的同步进度，主从服务器都有各自的偏移量，主服务器使用 master_repl_offset 来记录自己「写」到的位置，从服务器使用 slave_repl_offset 来记录自己「读」到的位置。那repl_backlog_buffer 缓冲区是什么时候写入的呢？ 在主服务器进行命令传播时，不仅会将写命令发送给从服务器，还会将写命令写入到 repl_backlog_buffer 缓冲区里，因此 这个缓冲区里会保存着最近传播的写命令。 网络断开后，当从服务器重新连上主服务器时，从服务器会通过 psync 命令将自己的复制偏移量 slave_repl_offset 发送给主服务器，主服务器根据自己的 master_repl_offset 和 slave_repl_offset 之间的差距，然后来决定对从服务器执行哪种同步操作： 如果判断出从服务器要读取的数据还在 repl_backlog_buffer 缓冲区里，那么主服务器将采用增量同步的方式；相反，如果判断出从服务器要读取的数据已经不存在 repl_backlog_buffer 缓冲区里，那么主服务器将采用全量同步的方式。当主服务器在 repl_backlog_buffer 中找到主从服务器差异（增量）的数据后，就会将增量的数据写入到 replication buffer 缓冲区，这个缓冲区我们前面也提到过，它是缓存将要传播给从服务器的命令。 repl_backlog_buffer 缓行缓冲区的默认大小是 1M，并且由于它是一个环形缓冲区，所以当缓冲区写满后，主服务器继续写入的话，就会覆盖之前的数据。 因此，当主服务器的写入速度远超于从服务器的读取速度，缓冲区的数据一下就会被覆盖。 那么在网络恢复时，如果从服务器想读的数据已经被覆盖了，主服务器就会采用全量同步，这个方式比增量同步的性能损耗要大很多。 因此，为了避免在网络恢复时，主服务器频繁地使用全量同步的方式，我们应该调整下 repl_backlog_buffer 缓冲区大小，尽可能的大一些，减少出现从服务器要读取的数据被覆盖的概率，从而使得主服务器采用增量同步的方式。 那 repl_backlog_buffer 缓冲区具体要调整到多大呢？ repl_backlog_buffer 最小的大小可以根据这面这个公式估算。 我来解释下这个公式的意思： second 为从服务器断线后重新连接上主服务器所需的平均 时间(以秒计算)。write_size_per_second 则是主服务器平均每秒产生的写命令数据量大小。举个例子，如果主服务器平均每秒产生 1 MB 的写命令，而从服务器断线之后平均要 5 秒才能重新连接主服务器。 那么 repl_backlog_buffer 大小就不能低于 5 MB，否则新写地命令就会覆盖旧数据了。 当然，为了应对一些突发的情况，可以将 repl_backlog_buffer 的大小设置为此基础上的 2 倍，也就是 10 MB。 关于 repl_backlog_buffer 大小修改的方法，只需要修改配置文件里下面这个参数项的值就可以。 总结主从复制共有三种模式：全量复制、基于长连接的命令传播、增量复制。 主从服务器第一次同步的时候，就是采用全量复制，此时主服务器会两个耗时的地方，分别是生成 RDB 文件和传输 RDB 文件。为了避免过多的从服务器和主服务器进行全量复制，可以把一部分从服务器升级为「经理角色」，让它也有自己的从服务器，通过这样可以分摊主服务器的压力。 第一次同步完成后，主从服务器都会维护着一个长连接，主服务器在接收到写操作命令后，就会通过这个连接将写命令传播给从服务器，来保证主从服务器的数据一致性。 如果遇到网络断开，增量复制就可以上场了，不过这个还跟 repl_backlog_size 这个大小有关系。 如果它配置的过小，主从服务器网络恢复时，可能发生「从服务器」想读的数据已经被覆盖了，那么这时就会导致主服务器采用全量复制的方式。所以为了避免这种情况的频繁发生，要调大这个参数的值，以降低主从服务器断开后全量同步的概率。 面试题redis主从节点时长连接还是短链接？长连接 怎么判断 redis 某个节点是否正常工作？redis 判断接点是否正常工作，基本都是通过互相的 ping-pong 心态检测机制，如果有一半以上的节点去 ping 一个节点的时候没有 pong 回应，集群就会认为这个节点挂掉了，会断开与这个节点的连接。 redis 主从节点发送的心态间隔是不一样的，而且作用也有一点区别： redis 主节点默认每隔 10 秒对从节点发送 ping 命令，判断从节点的存活性和连接状态，可通过参数repl-ping-slave-period控制发送频率。redis 从节点每隔 1 秒发送 replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量，目的是为了：实时监测主从节点网络状态；上报自身复制偏移量， 检查复制数据是否丢失， 如果从节点数据丢失， 再从主节点的复制缓冲区中拉取丢失数据。 主从复制架构中，过期key如何处理？主节点处理了一个key或者通过淘汰算法淘汰了一个key，这个时间主节点模拟一条del命令发送给从节点，从节点收到该命令后，就进行删除key的操作。 redis 是同步复制还是异步复制？redis 主节点每次收到写命令之后，先写到内部的缓冲区，然后异步发送给从节点。 主从复制中两个 Buffer(replication buffer 、repl backlog buffer)有什么区别？replication buffer 、repl backlog buffer 区别如下： replication buffer 是在全量复制阶段会出现，主库会给每个新连接的从库，分配一个 replication buffer；repl backlog buffer 是在增量复制阶段出现，一个主库只分配一个repl backlog buffer；这两个 Buffer 都有大小限制的，当缓冲区满了之后。repl backlog buffer，因为是环形结构，会直接覆盖起始位置数据，replication buffer则会导致连接断开，删除缓存，从库重新连接，重新开始全量复制。 redis 主从切换如何减少数据丢失？异步复制同步丢失对于 redis 主节点与从节点之间的数据复制，时异步复制的，当客户端发送写请求给主节点的时候，客户端会返回 ok，接着主节点将写请求异步同步给各个从节点，但是如果此时主节点还没来得及同步给从节点时发生了断电，那么主节点内存中的数据会丢失。 可以有 2 种解决方案： 第一种：客户端将数据暂时写入本地缓存和磁盘中，在一段时间后将本地缓存或者磁盘的数据发送给主节点，来保证数据不丢失；第二种：客户端将数据写入到消息队列中，发送一个延时消费消息，比如10分钟后再消费消息队列中的数据，然后再写到主节点。 集群产生脑裂数据丢失先来理解集群的脑裂现象，这就好比一个人有两个大脑，那么到底受谁控制呢？ 那么在 redis 中，集群脑裂产生数据丢失的现象是怎样的呢？ 在 redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。 这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在从节点中选举出一个 leeder 作为主节点，这时集群就有两个主节点了 —— 脑裂出现了。 这时候网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题。 总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。 解决方案： 当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。 在 redis 的配置文件中有两个参数我们可以设置： min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。 这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。 即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了。 等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。我再来给你举个例子。 假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。 redis 主从如何做到故障自动切换？主节点挂了 ，从节点是无法自动升级为主节点的，这个过程需要人工处理，在此期间 redis 无法对外提供写操作。 此时，redis 哨兵机制就登场了，哨兵在发现主节点出现故障时，由哨兵自动完成故障发现和故障转移，并通知给应用方，从而实现高可用性。 为什么要有哨兵机制？在 Redis 的主从架构中，由于主从模式是读写分离的，如果主节点（master）挂了，那么将没有主节点来服务客户端的写操作请求，也没有主节点给从节点（slave）进行数据同步了。 这时如果要恢复服务的话，需要人工介入，选择一个「从节点」切换为「主节点」，然后让其他从节点指向新的主节点，同时还需要通知上游那些连接 Redis 主节点的客户端，将其配置中的主节点 IP 地址更新为「新主节点」的 IP 地址。 这样也不太“智能”了，要是有一个节点能监控「主节点」的状态，当发现主节点挂了 ，它自动将一个「从节点」切换为「主节点」的话，那么可以节省我们很多事情啊！ Redis 在 2.8 版本以后提供的哨兵（Sentinel）机制，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。 哨兵机制是如何工作的？哨兵其实是一个运行在特殊模式下的 Redis 进程，所以它也是一个节点。从“哨兵”这个名字也可以看得出来，它相当于是“观察者节点”，观察的对象是主从节点。 当然，它不仅仅是观察那么简单，在它观察到有异常的状况下，会做出一些“动作”，来修复异常状态。 哨兵节点主要负责三件事情：监控、选主、通知。 所以，我们重点要学习这三件事情： 哨兵节点是如何监控节点的？又是如何判断主节点是否真的故障了？根据什么规则选择一个从节点切换为主节点？怎么把新主节点的相关信息通知给从节点和客户端呢？ 如何判断主节点真的故障了？哨兵会每隔 1 秒给所有主从节点发送 PING 命令，当主从节点收到 PING 命令后，会发送一个响应命令给哨兵，这样就可以判断它们是否在正常运行。 如果主节点或者从节点没有在规定的时间内响应哨兵的 PING 命令，哨兵就会将它们标记为「主观下线」。这个「规定的时间」是配置项 down-after-milliseconds 参数设定的，单位是毫秒。 主观下线？难道还有客观下线？ 是的没错，客观下线只适用于主节点。 之所以针对「主节点」设计「主观下线」和「客观下线」两个状态，是因为有可能「主节点」其实并没有故障，可能只是因为主节点的系统压力比较大或者网络发送了拥塞，导致主节点没有在规定时间内响应哨兵的 PING 命令。 所以，为了减少误判的情况，哨兵在部署的时候不会只部署一个节点，而是用多个节点部署成哨兵集群（最少需要三台机器来部署哨兵集群），通过多个哨兵节点一起判断，就可以就可以避免单个哨兵因为自身网络状况不好，而误判主节点下线的情况。同时，多个哨兵的网络同时不稳定的概率较小，由它们一起做决策，误判率也能降低。 具体是怎么判定主节点为「客观下线」的呢？ 当一个哨兵判断主节点为「主观下线」后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。 例如，现在有 3 个哨兵，quorum 配置的是 2，那么一个哨兵需要 2 张赞成票，就可以标记主节点为“客观下线”了。这 2 张赞成票包括哨兵自己的一张赞成票和另外两个哨兵的赞成票。 PS：quorum 的值一般设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2。 哨兵判断完主节点客观下线后，哨兵就要开始在多个「从节点」中，选出一个从节点来做新主节点。 由哪个哨兵进行主从故障转移？前面说过，为了更加“客观”的判断主节点故障了，一般不会只由单个哨兵的检测结果来判断，而是多个哨兵一起判断，这样可以减少误判概率，所以哨兵是以哨兵集群的方式存在的。 问题来了，由哨兵集群中的哪个节点进行主从故障转移呢？ 所以这时候，还需要在哨兵集群中选出一个 leeder，让 leeder 来执行主从切换。 选举 leeder 的过程其实是一个投票的过程，在投票开始前，肯定得有个「候选者」。 那谁来作为候选者呢？ 哪个哨兵节点判断主节点为「客观下线」，这个哨兵节点就是候选者，所谓的候选者就是想当 Leader 的哨兵。 举个例子，假设有三个哨兵。当哨兵 B 先判断到主节点「主观下线后」，就会给其他实例发送 is-master-down-by-addr 命令。接着，其他哨兵会根据自己和主节点的网络连接情况，做出赞成投票或者拒绝投票的响应。 当哨兵 B 收到赞成票数达到哨兵配置文件中的 quorum 配置项设定的值后，就会将主节点标记为「客观下线」，此时的哨兵 B 就是一个Leader 候选者。 候选者如何选举成为 Leader？ 候选者会向其他哨兵发送命令，表明希望成为 Leader 来执行主从切换，并让所有其他哨兵对它进行投票。 每个哨兵只有一次投票机会，如果用完后就不能参与投票了，可以投给自己或投给别人，但是只有候选者才能把票投给自己。 那么在投票过程中，任何一个「候选者」，要满足两个条件： 第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。举个例子，假设哨兵节点有 3 个，quorum 设置为 2，那么任何一个想成为 Leader 的哨兵只要拿到 2 张赞成票，就可以选举成功了。如果没有满足条件，就需要重新进行选举。 这时候有的同学就会问了，如果某个时间点，刚好有两个哨兵节点判断到主节点为客观下线，那这时不就有两个候选者了？这时该如何决定谁是 Leader 呢？ 每位候选者都会先给自己投一票，然后向其他哨兵发起投票请求。如果投票者先收到「候选者 A」的投票请求，就会先投票给它，如果投票者用完投票机会后，收到「候选者 B」的投票请求后，就会拒绝投票。这时，候选者 A 先满足了上面的那两个条件，所以「候选者 A」就会被选举为 Leader。 为什么哨兵节点至少要有 3 个？ 如果哨兵集群中只有 2 个哨兵节点，此时如果一个哨兵想要成功成为 Leader，必须获得 2 票，而不是 1 票。 所以，如果哨兵集群中有个哨兵挂掉了，那么就只剩一个哨兵了，如果这个哨兵想要成为 Leader，这时票数就没办法达到 2 票，就无法成功成为 Leader，这时是无法进行主从节点切换的。 因此，通常我们至少会配置 3 个哨兵节点。这时，如果哨兵集群中有个哨兵挂掉了，那么还剩下两个个哨兵，如果这个哨兵想要成为 Leader，这时还是有机会达到 2 票的，所以还是可以选举成功的，不会导致无法进行主从节点切换。 当然，你要问，如果 3 个哨兵节点，挂了 2 个怎么办？这个时候得人为介入了，或者增加多一点哨兵节点。 再说一个问题，Redis 1 主 4 从，5 个哨兵 ，quorum 设置为 3，如果 2 个哨兵故障，当主节点宕机时，哨兵能否判断主节点“客观下线”？主从能否自动切换？ 哨兵集群可以判定主节点“客观下线”。哨兵集群还剩下 3 个哨兵，当一个哨兵判断主节点“主观下线”后，询问另外 2 个哨兵后，有可能能拿到 3 张赞同票，这时就达到了 quorum 的值，因此，哨兵集群可以判定主节点为“客观下线”。 哨兵集群可以完成主从切换。当有个哨兵标记主节点为「客观下线」后，就会进行选举 Leader 的过程，因为此时哨兵集群还剩下 3 个哨兵，那么还是可以拿到半数以上（5/2+1=3）的票，而且也达到了 quorum 值，满足了选举 Leader 的两个条件， 所以就能选举成功，因此哨兵集群可以完成主从切换。 如果 quorum 设置为 2 ，并且如果有 3 个哨兵故障的话。此时哨兵集群还是可以判定主节点为“客观下线”，但是哨兵不能完成主从切换了，大家可以自己推演下。 如果 quorum 设置为 3，并且如果有 3 个哨兵故障的话，哨兵集群即不能判定主节点为“客观下线”，也不能完成主从切换了。 可以看到，quorum 为 2 的时候，并且如果有 3 个哨兵故障的话，虽然可以判定主节点为“客观下线”，但是不能完成主从切换，这样感觉「判定主节点为客观下线」这件事情白做了一样，既然这样，还不如不要做，quorum 为 3 的时候，就可以避免这种无用功。 所以，quorum 的值建议设置为哨兵个数的二分之一加1，例如 3 个哨兵就设置 2，5 个哨兵设置为 3，而且哨兵节点的数量应该是奇数。 主从故障转移的过程是怎样的？在哨兵集群中通过投票的方式，选举出了哨兵 leader 后，就可以进行主从故障转移的过程了，如下图： 主从故障转移操作包含以下四个步骤： 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点。第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」；第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端；第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点； 步骤一：选出新主节点故障转移操作第一步要做的就是在已下线主节点属下的所有「从节点」中，挑选出一个状态良好、数据完整的从节点，然后向这个「从节点」发送 SLAVEOF no one 命令，将这个「从节点」转换为「主节点」。 那么多「从节点」，到底选择哪个从节点作为新主节点的？ 随机的方式好吗？随机的方式，实现起来很简单，但是如果选到一个网络状态不好的从节点作为新主节点，那么可能在将来不久又要做一次主从故障迁移。 所以，我们首先要把网络状态不好的从节点给过滤掉。首先把已经下线的从节点过滤掉，然后把以往网络连接状态不好的从节点也给过滤掉。 怎么判断从节点之前的网络连接状态不好呢？ Redis 有个叫 down-after-milliseconds * 10 配置项，其down-after-milliseconds 是主从节点断连的最大连接超时时间。如果在 down-after-milliseconds 毫秒内，主从节点都没有通过网络联系上，我们就可以认为主从节点断连了。如果发生断连的次数超过了 10 次，就说明这个从节点的网络状况不好，不适合作为新主节点。 至此，我们就把网络状态不好的从节点过滤掉了，接下来要对所有从节点进行三轮考察：优先级、复制进度、ID 号。在进行每一轮考察的时候，哪个从节点优先胜出，就选择其作为新主节点。 第一轮考察：哨兵首先会根据从节点的优先级来进行排序，优先级越小排名越靠前，第二轮考察：如果优先级相同，则查看复制的下标，哪个从「主节点」接收的复制数据多，哪个就靠前。第三轮考察：如果优先级和下标都相同，就选择从节点 ID 较小的那个。 第一轮考察：优先级最高的从节点胜出Redis 有个叫 slave-priority 配置项，可以给从节点设置优先级。 每一台从节点的服务器配置不一定是相同的，我们可以根据服务器性能配置来设置从节点的优先级。 比如，如果 「 A 从节点」的物理内存是所有从节点中最大的， 那么我们可以把「 A 从节点」的优先级设置成最高。这样当哨兵进行第一轮考虑的时候，优先级最高的 A 从节点就会优先胜出，于是就会成为新主节点。 第二轮考察：复制进度最靠前的从节点胜出如果在第一轮考察中，发现优先级最高的从节点有两个，那么就会进行第二轮考察，比较两个从节点哪个复制进度。 什么是复制进度？主从架构中，主节点会将写操作同步给从节点，在这个过程中，主节点会用 master_repl_offset 记录当前的最新写操作在 repl_backlog_buffer 中的位置（如下图中的「主服务器已经写入的数据」的位置），而从节点会用 slave_repl_offset 这个值记录当前的复制进度（如下图中的「从服务器要读的位置」的位置）。 如果某个从节点的 slave_repl_offset 最接近 master_repl_offset，说明它的复制进度是最靠前的，于是就可以将它选为新主节点。 第三轮考察：ID 号小的从节点胜出如果在第二轮考察中，发现有两个从节点优先级和复制进度都是一样的，那么就会进行第三轮考察，比较两个从节点的 ID 号，ID 号小的从节点胜出。 什么是 ID 号？每个从节点都有一个编号，这个编号就是 ID 号，是用来唯一标识从节点的。 到这里，选主的事情终于结束了。简单给大家总结下： 在选举出从节点后，哨兵 leader 向被选中的从节点发送 SLAVEOF no one 命令，让这个从节点解除从节点的身份，将其变为新主节点。 如下图，哨兵 leader 向被选中的从节点 server2 发送 SLAVEOF no one 命令，将该从节点升级为新主节点。 在发送 SLAVEOF no one 命令之后，哨兵 leader 会以每秒一次的频率向被升级的从节点发送 INFO 命令（没进行故障转移之前，INFO 命令的频率是每十秒一次），并观察命令回复中的角色信息，当被升级节点的角色信息从原来的 slave 变为 master 时，哨兵 leader 就知道被选中的从节点已经顺利升级为主节点了。 如下图，选中的从节点 server2 升级成了新主节点： 步骤二：将从节点指向新主节点当新主节点出现之后，哨兵 leader 下一步要做的就是，让已下线主节点属下的所有「从节点」指向「新主节点」，这一动作可以通过向「从节点」发送 SLAVEOF 命令来实现。 如下图，哨兵 leader 向所有从节点（server3和server4）发送 SLAVEOF ，让它们成为新主节点的从节点。 步骤三：通知客户的主节点已更换经过前面一系列的操作后，哨兵集群终于完成主从切换的工作，那么新主节点的信息要如何通知给客户端呢？ 这主要通过 Redis 的发布者/订阅者机制来实现的。每个哨兵节点提供发布者/订阅者机制，客户端可以从哨兵订阅消息。 客户端和哨兵建立连接后，客户端会订阅哨兵提供的频道。主从切换完成后，哨兵就会向 +switch-master 频道发布新主节点的 IP 地址和端口的消息，这个时候客户端就可以收到这条信息，然后用这里面的新主节点的 IP 地址和端口进行通信了。 通过发布者/订阅者机制机制，有了这些事件通知，客户端不仅可以在主从切换后得到新主节点的连接信息，还可以监控到主从节点切换过程中发生的各个重要事件。这样，客户端就可以知道主从切换进行到哪一步了，有助于了解切换进度。 步骤四：将旧主节点变为从节点故障转移操作最后要做的是，继续监视旧主节点，当旧主节点重新上线时，哨兵集群就会向它发送 SLAVEOF 命令，让它成为新主节点的从节点，如下图： 至此，整个主从节点的故障转移的工作结束。 哨兵集群是如何组成的？前面提到了 Redis 的发布者/订阅者机制，那就不得不提一下哨兵集群的组成方式，因为它也用到了这个技术。 在我第一次搭建哨兵集群的时候，当时觉得很诧异。因为在配置哨兵的信息时，竟然只需要填下面这几个参数，设置主节点名字、主节点的 IP 地址和端口号以及 quorum 值。 不需要填其他哨兵节点的信息，我就好奇它们是如何感知对方的，又是如何组成哨兵集群的？ 后面才了解到，哨兵节点之间是通过 Redis 的发布者/订阅者机制来相互发现的。 在主从集群中，主节点上有一个名为sentinel:hello的频道，不同哨兵就是通过它来相互发现，实现互相通信的。 在下图中，哨兵 A 把自己的 IP 地址和端口的信息发布到sentinel:hello 频道上，哨兵 B 和 C 订阅了该频道。那么此时，哨兵 B 和 C 就可以从这个频道直接获取哨兵 A 的 IP 地址和端口号。然后，哨兵 B、C 可以和哨兵 A 建立网络连接。 通过这个方式，哨兵 B 和 C 也可以建立网络连接，这样一来，哨兵集群就形成了。 哨兵集群会对「从节点」的运行状态进行监控，那哨兵集群如何知道「从节点」的信息？ 主节点知道所有「从节点」的信息，所以哨兵会每 10 秒一次的频率向主节点发送 INFO 命令来获取所有「从节点」的信息。 如下图所示，哨兵 B 给主节点发送 INFO 命令，主节点接受到这个命令后，就会把从节点列表返回给哨兵。接着，哨兵就可以根据从节点列表中的连接信息，和每个从节点建立连接，并在这个连接上持续地对从节点进行监控。哨兵 A 和 C 可以通过相同的方法和从节点建立连接。 正式通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，然后组成集群，同时，哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。 总结Redis 在 2.8 版本以后提供的哨兵（Sentinel）机制，它的作用是实现主从节点故障转移。它会监测主节点是否存活，如果发现主节点挂了，它就会选举一个从节点切换为主节点，并且把新主节点的相关信息通知给从节点和客户端。 哨兵一般是以集群的方式部署，至少需要 3 个哨兵节点，哨兵集群主要负责三件事情：监控、选主、通知。 哨兵节点通过 Redis 的发布者/订阅者机制，哨兵之间可以相互感知，相互连接，然后组成哨兵集群，同时哨兵又通过 INFO 命令，在主节点里获得了所有从节点连接信息，于是就能和从节点建立连接，并进行监控了。 1、第一轮投票：判断主节点下线 当哨兵集群中的某个哨兵判定主节点下线（主观下线）后，就会向其他哨兵发起命令，其他哨兵收到这个命令后，就会根据自身和主节点的网络状况，做出赞成投票或者拒绝投票的响应。 当这个哨兵的赞同票数达到哨兵配置文件中的 quorum 配置项设定的值后，这时主节点就会被该哨兵标记为「客观下线」。 2、第二轮投票：选出哨兵leader 某个哨兵判定主节点客观下线后，该哨兵就会发起投票，告诉其他哨兵，它想成为 leader，想成为 leader 的哨兵节点，要满足两个条件： 第一，拿到半数以上的赞成票；第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。3、由哨兵 leader 进行主从故障转移 选举出了哨兵 leader 后，就可以进行主从故障转移的过程了。该操作包含以下四个步骤： 第一步：在已下线主节点（旧主节点）属下的所有「从节点」里面，挑选出一个从节点，并将其转换为主节点，选择的规则： 过滤掉已经离线的从节点； 过滤掉历史网络连接状态不好的从节点； 将剩下的从节点，进行三轮考察：优先级、复制进度、ID 号。在每一轮考察过程中，如果找到了一个胜出的从节点，就将其作为新主节点。 第二步：让已下线主节点属下的所有「从节点」修改复制目标，修改为复制「新主节点」； 第三步：将新主节点的 IP 地址和信息，通过「发布者/订阅者机制」通知给客户端； 第四步：继续监视旧主节点，当这个旧主节点重新上线时，将它设置为新主节点的从节点； 完！ 什么是缓存雪崩、击穿、穿透？用户的数据一般都是存储于数据库，数据库的数据是落在磁盘上的，磁盘的读写速度可以说是计算机里最慢的硬件了。 当用户的请求，都访问数据库的话，请求数量一上来，数据库很容易就奔溃的了，所以为了避免用户直接访问数据库，会用 Redis 作为缓存层。 因为 Redis 是内存数据库，我们可以将数据库的数据缓存在 Redis 里，相当于数据缓存在内存，内存的读写速度比硬盘快好几个数量级，这样大大提高了系统性能。 引入了缓存层，就会有缓存异常的三个问题，分别是缓存雪崩、缓存击穿、缓存穿透。 这三个问题也是面试中很常考察的问题，我们不光要清楚地知道它们是怎么发生，还需要知道如何解决它们。 话不多说，发车！ 缓存雪崩通常我们为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到 Redis 里，这样后续请求都可以直接命中缓存。 那么，当大量缓存数据在同一时间过期（失效）或者 Redis 故障宕机时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩的问题。 可以看到，发生缓存雪崩有两个原因： 大量数据同时过期；Redis 故障宕机；不同的诱因，应对的策略也会不同。 大量数据同时过期针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法有下面这几种： 均匀设置过期时间；互斥锁；双 key 策略；后台更新缓存； 均匀设置过期时间 如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，给这些数据的过期时间加上一个随机数，这样就保证数据不会在同一时间过期。 互斥锁 当业务线程在处理用户请求时，如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。 实现互斥锁的时候，最好设置超时时间，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。 双 key 策略 我们对缓存数据可以使用两个 key，一个是主 key，会设置过期时间，一个是备 key，不会设置过期，它们只是 key 不一样，但是 value 值是一样的，相当于给缓存数据做了个副本。 当业务线程访问不到「主 key 」的缓存数据时，就直接返回「备 key 」的缓存数据，然后在更新缓存的时候，同时更新「主 key 」和「备 key 」的数据。 后台更新缓存 业务线程不再负责更新缓存，缓存也不设置有效期，而是让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新。 事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为当系统内存紧张的时候，有些缓存数据会被“淘汰”，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。 解决上面的问题的方式有两种。 第一种方式，后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效，检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。 这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。 第二种方式，在业务线程发现缓存数据失效后（缓存数据被淘汰），通过消息队列发送一条消息通知后台线程更新缓存，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。 在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的缓存预热，后台更新缓存的机制刚好也适合干这个事情。 Redis 故障宕机针对 Redis 故障宕机而引发的缓存雪崩问题，常见的应对方法有下面这几种： 服务熔断或请求限流机制；构建 Redis 缓存高可靠集群； 服务熔断或请求限流机制 因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动服务熔断机制，暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。 服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作 为了减少对业务的影响，我们可以启用请求限流机制，只将少部分请求发送到数据库进行处理，再多的请求就在入口直接拒绝服务，等到 Redis 恢复正常并把缓存预热完后，再解除请求限流的机制。 构建 Redis 缓存高可靠集群 服务熔断或请求限流机制是缓存雪崩发生后的应对方案，我们最好通过主从节点的方式构建 Redis 缓存高可靠集群。 如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。 缓存击穿我们的业务通常会有几个数据会被频繁地访问，比如秒杀活动，这类被频地访问的数据被称为热点数据。 如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被高并发的请求冲垮，这就是缓存击穿的问题。 可以发现缓存击穿跟缓存雪崩很相似，你可以认为缓存击穿是缓存雪崩的一个子集。 应对缓存击穿可以采取前面说到两种方案： 互斥锁方案，保证同一时间只有一个业务线程更新缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。不给热点数据设置过期时间，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间； 缓存穿透当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。 当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是缓存穿透的问题。 缓存穿透的发生一般有这两种情况： 业务误操作，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；黑客恶意攻击，故意大量访问某些读取不存在数据的业务；应对缓存穿透的方案，常见的方案有三种。 第一种方案，非法请求的限制；第二种方案，缓存空值或者默认值；第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；第一种方案，非法请求的限制 当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。 第二种方案，缓存空值或者默认值 当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。 第三种方案，使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在。 我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。 即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。 那问题来了，布隆过滤器是如何工作的呢？接下来，我介绍下。 布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。 布隆过滤器会通过 3 个操作完成标记： 第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。第三步，将每个哈希值在位图数组的对应位置的值设置为 1；举个例子，假设有一个位图数组长度为 8，哈希函数 3 个的布隆过滤器。 在数据库写入数据 x 后，把数据 x 标记在布隆过滤器时，数据 x 会被 3 个哈希函数分别计算出 3 个哈希值，然后在对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6，然后把位图数组的第 1、4、6 位置的值设置为 1。当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中。 布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时存在哈希冲突的可能性，比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。 所以，查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是查询到数据不存在，数据库中一定就不存在这个数据。 总结缓存异常会面临的三个问题：缓存雪崩、击穿和穿透。 其中，缓存雪崩和缓存击穿主要原因是数据不在缓存中，而导致大量请求访问了数据库，数据库压力骤增，容易引发一系列连锁反应，导致系统奔溃。不过，一旦数据被重新加载回缓存，应用又可以从缓存快速读取数据，不再继续访问数据库，数据库的压力也会瞬间降下来。因此，缓存雪崩和缓存击穿应对的方案比较类似。 而缓存穿透主要原因是数据既不在缓存也不在数据库中。因此，缓存穿透与缓存雪崩、击穿应对的方案不太一样。 数据库和缓存如何保证一致性？程序员阿旺听到老板口中的「画饼」后就非常期待，没有任何犹豫就接下了老板给的这个任务。 阿旺登陆到了服务器，经过一番排查后，确认服务器的性能瓶颈是在数据库。 这好办，给服务器加上 Redis，让其作为数据库的缓存。 这样，在客户端请求数据时，如果能在缓存中命中数据，那就查询缓存，不用在去查询数据库，从而减轻数据库的压力，提高服务器的性能。 先更新数据库，还是先更新缓存？阿旺有了这个想法后，就准备开始着手优化服务器，但是挡在在他前面的是这样的一个问题。 由于引入了缓存，那么在数据更新时，不仅要更新数据库，而且要更新缓存，这两个更新操作存在前后的问题： 先更新数据库，再更新缓存；先更新缓存，再更新数据库；阿旺没想到太多，他觉得最新的数据肯定要先更新数据库，这样才可以确保数据库里的数据是最新的，于是他就采用了「先更新数据库，再更新缓存」的方案。 阿旺经过几个夜晚的折腾，终于「优化好了服务器」，然后就直接上线了，自信心满满跑去跟老板汇报。 老板不懂技术，自然也没多虑，就让后续阿旺观察下服务器的情况，如果效果不错，就跟阿旺谈画饼的事情。 阿旺观察了好几天，发现数据库的压力大大减少了，访问速度也提高了不少，心想这事肯定成的了。 好景不长，突然老板收到一个客户的投诉，客户说他刚发起了两次更新年龄的操作，但是显示的年龄确还是第一次更新时的年龄，而第二次更新年龄并没有生效。 老板立马就找了阿旺，训斥着阿旺说：「这么简单的更新操作，都有 bug？我脸往哪儿放？你的饼还要不要了？」 听到自己准备到手的饼要没了的阿旺瞬间就慌了，立马登陆服务器排查问题，阿旺查询缓存和数据库的数据后发现了问题。 数据库的数据是客户第二次更新操作的数据，而缓存确还是第一次更新操作的数据，也就是出现了数据库和缓存的数据不一致的问题。 这个问题可大了，阿旺经过一轮的分析，造成缓存和数据库的数据不一致的现象，是因为并发问题！ 先更新数据库，再更新缓存举个例子，比如「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序： A 请求先将数据库的数据更新为 1，然后在更新缓存前，请求 B 将数据库的数据更新为 2，紧接着也把缓存更新为 2，然后 A 请求更新缓存为 1。 此时，数据库中的数据是 2，而缓存中的数据却是 1，出现了缓存和数据库中的数据不一致的现象。 先更新缓存，再更新数据库那换成「先更新缓存，再更新数据库」这个方案，还会有问题吗？ 依然还是存在并发的问题，分析思路也是一样。 假设「请求 A 」和「请求 B 」两个请求，同时更新「同一条」数据，则可能出现这样的顺序： A 请求先将缓存的数据更新为 1，然后在更新数据库前，B 请求来了， 将缓存的数据更新为 2，紧接着把数据库更新为 2，然后 A 请求将数据库的数据更新为 1。 此时，数据库中的数据是 1，而缓存中的数据却是 2，出现了缓存和数据库中的数据不一致的现象。 所以，无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象。 先更新数据库，还是先删除缓存？阿旺定位出问题后，思考了一番后，决定在更新数据时，不更新缓存，而是删除缓存中的数据。然后，到读取数据时，发现缓存中没了数据之后，再从数据库中读取数据，更新到缓存中。 阿旺想的这个策略是有名字的，是叫 Cache Aside 策略，中文是叫旁路缓存策略。 该策略又可以细分为「读策略」和「写策略」。 写策略的步骤： 更新数据库中的数据；删除缓存中的数据。读策略的步骤： 如果读取的数据命中了缓存，则直接返回数据；如果读取的数据没有命中缓存，则从数据库中读取数据，然后将数据写入到缓存，并且返回给用户。阿旺在想到「写策略」的时候，又陷入更深层次的思考，到底该选择哪种顺序呢？ 先删除缓存，再更新数据库；先更新数据库，再删除缓存。阿旺这次经过上次教训，不再「想当然」的乱选方案，因为老板这次给的饼很大啊，必须把握住。 于是阿旺用并发的角度来分析，看看这两种方案哪个可以保证数据库与缓存的数据一致性。 先删除缓存，再更新数据库阿旺还是以用户表的场景来分析。 假设某个用户的年龄是 20，请求 A 要更新用户年龄为 21，所以它会删除缓存中的内容。这时，另一个请求 B 要读取这个用户的年龄，它查询缓存发现未命中后，会从数据库中读取到年龄为 20，并且写入到缓存中，然后请求 A 继续更改数据库，将用户的年龄更新为 21。 最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库的数据不一致。 可以看到，先删除缓存，再更新数据库，在「读 + 写」并发的时候，还是会出现缓存和数据库的数据不一致的问题。 先更新数据库，再删除缓存继续用「读 + 写」请求的并发的场景来分析。 假如某个用户数据在缓存中不存在，请求 A 读取数据时从数据库中查询到年龄为 20，在未写入缓存中时另一个请求 B 更新数据。它更新数据库中的年龄为 21，并且清空缓存。这时请求 A 把从数据库中读到的年龄为 20 的数据写入到缓存中。 最终，该用户年龄在缓存中是 20（旧值），在数据库中是 21（新值），缓存和数据库数据不一致。 从上面的理论上分析，先更新数据库，再删除缓存也是会出现数据不一致性的问题，但是在实际中，这个问题出现的概率并不高。 因为缓存的写入通常要远远快于数据库的写入，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。 而一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。 所以，「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的。 而且阿旺为了确保万无一失，还给缓存数据加上了「过期时间」，就算在这期间存在缓存数据不一致，有过期时间来兜底，这样也能达到最终一致。 阿旺思考到这一步后，觉得自己真的是个小天才，因为他竟然想到了个「天衣无缝」的方案，他二话不说就采用了这个方案，又经过几天的折腾，终于完成了。 他自信满满的向老板汇报，已经解决了上次客户的投诉的问题了。老板觉得阿旺这小伙子不错，这么快就解决问题了，然后让阿旺在观察几天。 事情哪有这么顺利呢？结果又没过多久，老板又收到客户的投诉了，说自己明明更新了数据，但是数据要过一段时间才生效，客户接受不了。 老板面无表情的找上阿旺，让阿旺尽快查出问题。 阿旺得知又有 Bug 就更慌了，立马就登录服务器去排查问题，查看日志后得知了原因。 「先更新数据库， 再删除缓存」其实是两个操作，前面的所有分析都是建立在这两个操作都能同时执行成功，而这次客户投诉的问题就在于，在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值。 好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。 所以新的问题来了，如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？ 阿旺分析出问题后，慌慌张张的向老板汇报了问题。 老板知道事情后，又给了阿旺几天来解决这个问题，画饼的事情这次没有再提了。 阿旺会用什么方式来解决这个问题呢？ 老板画的饼事情，能否兑现给阿旺呢？ 预知后事，且听下回阿旺的故事。 小结阿旺的事情就聊到这，我们继续说点其他。 「先更新数据库，再删除缓存」的方案虽然保证了数据库与缓存的数据一致性，但是每次更新数据的时候，缓存的数据都会被删除，这样会对缓存的命中率带来影响。 所以，如果我们的业务对缓存命中率有很高的要求，我们可以采用「更新数据库 + 更新缓存」的方案，因为更新缓存并不会出现缓存未命中的情况。 但是这个方案前面我们也分析过，在两个更新请求并发执行的时候，会出现数据不一致的问题，因为更新数据库和更新缓存这两个操作是独立的，而我们又没有对操作做任何并发控制，那么当两个线程并发更新它们的话，就会因为写入顺序的不同造成数据的不一致。 所以我们得增加一些手段来解决这个问题，这里提供两种做法： 在更新缓存前先加个分布式锁，保证同一时间只运行一个请求更新缓存，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。在更新完缓存时，给缓存加上较短的过期时间，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的。对了，针对「先删除缓存，再更新数据库」方案在「读 + 写」并发请求而造成缓存不一致的解决办法是「延迟双删」。 延迟双删实现的伪代码如下： #删除缓存 redis.delKey(X) #更新数据库 db.update(X) #睡眠 Thread.sleep(N) #再删除缓存 redis.delKey(X) 加了个睡眠时间，主要是为了确保请求 A 在睡眠的时候，请求 B 能够在这这一段时间完成「从数据库读取数据，再把缺失的缓存写入缓存」的操作，然后请求 A 睡眠完，再删除缓存。 所以，请求 A 的睡眠时间就需要大于请求 B 「从数据库读取数据 + 写入缓存」的时间。 但是具体睡眠多久其实是个玄学，很难评估出来，所以这个方案也只是尽可能保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。 因此，还是比较建议用「先更新数据库，再删除缓存」的方案。 前情回顾上回程序员阿旺为了提升数据访问的性能，引入 Redis 作为 MySQL 缓存层，但是这件事情并不是那么简单，因为还要考虑 Redis 和 MySQL 双写一致性的问题。 阿旺经过一番周折，最终选用了「先更新数据库，再删缓存」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。 聪明的阿旺还搞了个兜底的方案，就是给缓存加上了过期时间。 本以为就这样不会在出现数据一致性的问题，结果将功能上线后，老板还是收到用户的投诉「说自己明明更新了数据，但是数据要过一段时间才生效」，客户接受不了。 老板转告给了阿旺，阿旺得知又有 Bug 就更慌了，立马就登录服务器去排查问题，查看日志后得知了原因。 「先更新数据库， 再删除缓存」其实是两个操作，这次客户投诉的问题就在于，在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值。 好在之前给缓存加上了过期时间，所以才会出现客户说的过一段时间才更新生效的现象，假设如果没有这个过期时间的兜底，那后续的请求读到的就会一直是缓存中的旧数据，这样问题就更大了。 所以新的问题来了，如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？ 阿旺分析出问题后，慌慌张张的向老板汇报了问题。 老板知道事情后，又给了阿旺几天来解决这个问题，画饼的事情这次没有再提了。 阿旺会用什么方式来解决这个问题呢？老板画的饼事情，能否兑现给阿旺呢？ 如何保证两个操作都能执行成功？这次用户的投诉是因为在删除缓存（第二个操作）的时候失败了，导致缓存还是旧值，而数据库是最新值，造成数据库和缓存数据不一致的问题，会对敏感业务造成影响。 举个例子，来说明下。 应用要把数据 X 的值从 1 更新为 2，先成功更新了数据库，然后在 Redis 缓存中删除 X 的缓存，但是这个操作却失败了，这个时候数据库中 X 的新值为 2，Redis 中的 X 的缓存值为 1，出现了数据库和缓存数据不一致的问题。 那么，后续有访问数据 X 的请求，会先在 Redis 中查询，因为缓存并没有 诶删除，所以会缓存命中，但是读到的却是旧值 1。 其实不管是先操作数据库，还是先操作缓存，只要第二个操作失败都会出现数据一致的问题。 问题原因知道了，该怎么解决呢？有两种方法： 重试机制。 订阅 MySQL binlog，再操作缓存。 先来说第一种。 重试机制我们可以引入消息队列，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。 如果应用删除缓存失败，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是重试机制。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。如果删除缓存成功，就要把数据从消息队列中移除，避免重复操作，否则就继续重试。举个例子，来说明重试机制的过程。 订阅 MySQL binlog，再操作缓存「先更新数据库，再删缓存」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。 于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。 Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。 所以，如果要想保证「先更新数据库，再删缓存」策略第二个操作能执行成功，我们可以使用「消息队列来重试缓存的删除」，或者「订阅 MySQL binlog 再操作缓存」，这两种方法有一个共同的特点，都是采用异步操作缓存。 Redis实现分布式锁这需要能成功的进行加锁，解锁，以及线程挂掉之后，超时一定时间后释放锁 redis可以在加锁的时候设置时间 为了防止超时的时候当前A线程还没执行完，超时自动释放锁。然后B获取锁，然后A执行完成，开始释放锁。这个时候A释放了B的锁。 解决办法：del之前判断是不是自己的锁，用线程id做标识。 为了防止超时的时候当前A线程还没执行完，超时自动释放锁。然后B获取锁，两个线程同时执行。 解决办法，设置超时时间弄长一点。为获取到锁的线程增加守护线程，将过期但是没过期的锁增加有效时间。 防止一个线程多次重入加锁，这个时候应该对锁进行重入计数，看加了几次锁。 等待锁释放，客户端不断轮询，看是否能够获取到锁。使用发布订阅模式，获取锁失败的时候，订阅锁释放的消息，当锁成功释放的时候，发送锁释放消息。 RedLock 获取当前时间锉 按照顺序使用相同的k，v获取所有redis服务的锁。如果redis关闭，就去尝试获取下一个redis实例的锁 获取到能获取的锁之后，减去第一步的时间，需要小于TTL并且过半的redis实例获取成功，才算真的成功 如果成功获取到，那么锁的真正有效时间为TTL减去第三步的时间差的时间， 如果获取失败，即少于一半，那么必须释放锁。 优点：实现简单，逻辑简单 缺点： 需要不断尝试获取锁，消耗性能，redis容易单点故障，不是强一致性的，锁不够健壮。 Redis场景缓存， 消息队列，除了使用发布订阅模式，还可以使用List实现队列机制 参考文献","path":"2022/07/24/Redis/Redis/"},{"title":"工厂设计模式-C++","text":"主要分为三类，一个是简单工厂模式，一个是工厂方法模式，一个是抽象工厂模式 简单工厂模式class Produce &#123; public: virtual void show() = 0; &#125;; class ProduceA :public Produce &#123; void show() &#123; cout &lt;&lt; &quot;Prodece A\\n&quot;; &#125; &#125;; class ProduceB :public Produce &#123; void show() &#123; cout &lt;&lt; &quot;Prodece B\\n&quot;; &#125; &#125;; class SimpleFact &#123; Produce* creatProduce(int typenum) &#123; if (typenum == 1) &#123; return new ProduceA(); &#125; else if (typenum == 2) &#123; return new ProduceB(); &#125; &#125; &#125;; 这个工厂设计模式，需要传入产品的类型，然后生产一个产品，这样如果后面有新的产品就需要再createproduce里面加内容，这可能会会破坏开闭原则，对修改关闭对拓展打开。 工厂方法模式class Produce &#123; public: virtual void show() = 0; &#125;; class ProduceA :public Produce &#123; public: void show() &#123; cout &lt;&lt; &quot;Prodece A\\n&quot;; &#125; &#125;; class ProduceB :public Produce &#123; public: void show() &#123; cout &lt;&lt; &quot;Prodece B\\n&quot;; &#125; &#125;; class Factory &#123; public: virtual Produce* createProdu() = 0; &#125;; class FactoryA &#123; public: Produce* createProdu() &#123; return new ProduceA(); &#125; &#125;; class FactoryB &#123; public: Produce* createProdu() &#123; return new ProduceB(); &#125; &#125;; 这个工厂方法模式就是我们不使用if判断来生产产品，通过确定某个类型的工厂来实现，这样每次新加产品需要一个新类。 抽象工厂模式class MultiCore &#123; public: virtual void Show() = 0; &#125;; class MultiCoreA : public MultiCore &#123; public: void Show() &#123; cout &lt;&lt; &quot;Multi Core A&quot; &lt;&lt; endl; &#125; &#125;; class MultiCoreB : public MultiCore &#123; public: void Show() &#123; cout &lt;&lt; &quot;Multi Core B&quot; &lt;&lt; endl; &#125; &#125;; //工厂 class CoreFactory &#123; public: virtual SingleCore* CreateSingleCore() = 0; virtual MultiCore* CreateMultiCore() = 0; &#125;; //工厂A，专门用来生产A型号的处理器 class FactoryA :public CoreFactory &#123; public: SingleCore* CreateSingleCore() &#123; return new SingleCoreA(); &#125; MultiCore* CreateMultiCore() &#123; return new MultiCoreA(); &#125; &#125;; //工厂B，专门用来生产B型号的处理器 class FactoryB : public CoreFactory &#123; public: SingleCore* CreateSingleCore() &#123; return new SingleCoreB(); &#125; MultiCore* CreateMultiCore() &#123; return new MultiCoreB(); &#125; &#125;; 这个主要是可以区分AB两种产品之外，还有单核和多核两种区分方式，我们首先分单核，多核两个抽象类，然后产生单核A，单核B，多核A，多核B这些类，然后构建工厂抽象类，分为A工厂类，B工厂类，在A工厂类中两个创建单核A，多核A的方法。工厂B中两个创建单核B，多核B的方法。 优点是除了A，B还可以有多核单核的类型区分，但是这个拓展的时候比较麻烦，产品种类需要提前确定下来，才能在区分单核双核的时候弄好，风格也要确定，不确定的话也要到工厂类中修改内容。","path":"2022/07/08/设计模式/工厂设计模式/"},{"title":"单例设计模式-C++","text":"线程安全的单例设计模式，使用局部静态变量的方式，C++11保证线程安全 class Singleton &#123; public: static Singleton&amp; getInstance() &#123; static Singleton singleton; return singleton; &#125; ~Singleton() &#123;&#125; private: Singleton() &#123;&#125; Singleton(const Singleton&amp;) = delete; Singleton&amp; operator =(const Singleton&amp;) = delete; &#125;; Singleton::getInstance();","path":"2022/07/08/设计模式/单例设计模式-C++/"},{"title":"客户端掉线，服务端怎么样才能知道","text":"TCP中的RST复位信号 RST的几种情况","path":"2022/07/01/网络编程/客户端掉线，服务端怎么样才能立刻知道/"},{"title":"覆盖索引和回表","text":"覆盖索引和回表 回表就是在普通索引查询的时候，需要先查到聚簇索引的位置，然后再让聚簇索引查数据，需要两次查树 覆盖索引就是在要查的位置建立索引，然后就只需要一次查询。","path":"2022/06/28/数据库/覆盖索引和回表/"},{"title":"MVCC多版本并发控制","text":"参考链接 参考链接2 这个就是在访问数据库的时候，对数据进行多版本的控制，在每个事务都有一个版本号，数据在事务中的读取的时候会比较版本号，主要有三个，一个是最小的活跃事务号，最大的事务号+1，以及undo log，以及某条数据被修改的最大的事务号，通过版本号的比较来确定数据可不可见，这样就可以使得在读取数据的时候不需要加锁实现了事务的隔离性。 主要的核心有，事务的版本号，readview（），隐藏字段，undolog， readview事务在进行快照读的时候，普通的select都是快照读，的时候会创建一个readeviwe，这个读视图主要有三个字段，当前活跃的事务版本号，最小的事务版本号，readview生成时候出现的最大版本号+1， 隐藏字段每一行都有几个隐藏的列，最近修改这个数据的事务版本号，隐藏的自增id（没有主键的时候用作聚簇索引），回滚指针，指向这个记录的上一个版本，是否删除的标记 undolog主要包括 insert undo log，在事务插入的时候生成，提交之后可以删除 update undo log,在事务更新或者删除数据的时候生成，只有当目前没有比它更老的readview的时候才可以在提交的时候删除，如果数据库中有许多长事务，会导致很多更新的undo log无法删除，占用空间。 每个进行多版本控制的时候就是用隐藏字段中的最近修改数据的事务版本号去和读视图中的字段进行比较从而控制数据是否可见的 首先比较这条记录的 DB_TRX_ID（最近修改数据的事务版本号） 是否是 小于 up_limit_id 或者 等于当前事务id。如果满足，那么说明当前事务能看到这条记录。如果大于则进入下一轮判断 然后判断这条记录的 DB_TRX_ID 是否 大于等于 low-limit-id。如果大于等于则说明此事务无法看见该条记录，不然就进入下一轮判断。 判断该条记录的 DB_TRX_ID 是否在活跃事务的数组中，如果在则说明这条记录还未提交对于当前操作的事务是不可见的，如果不在则说明已经提交，那么就是可见的。 如果此条记录对于该事务不可见且 ROLL_PTR 不为空那么就会指向回滚指针的地址，通过undolog来查找可见的记录版本。","path":"2022/06/27/数据库/MVCC多版本并发控制/"},{"title":"乐观锁和悲观锁","text":"参考链接 乐观锁就是在每次读取数据的时候不加锁，然后要写回数据的时候判断数据是否有变化，如果有就放弃，没有就操作，乐观锁实际上没加锁 主要实现方式有两种，cas(compare and swap)，和多版本机制 cas这个是硬件层面原子操作，不用加锁，是自旋的，比较了读取的位置和预期的值一样，就swap读取的值和给定的数据 多版本机制每次都会有一个版本号，然后数据更改的时候新增版本号，如果版本号一样就说明没变化， 缺点ABA问题，先变A再变B右变回A容易出现问题，只能针对单个变量 悲观锁在每次读取数据之前都加锁，然后操作完数据再解锁，缺点是效率低，但是不会出现不一致的问题，适合在容易冲突的适合使用","path":"2022/06/27/数据库/乐观锁和悲观锁/"},{"title":"GO实现生产者消费者问题，读者写者问题","text":"生产者消费者问题： 具体的PV操作可以看另外一篇博客package main // 带缓冲区的channel import ( &quot;fmt&quot; &quot;time&quot; ) func producer(ch chan&lt;- int ) &#123; for i:=0;i&lt;3;i++&#123; ch&lt;-i fmt.Println(&quot;Send:&quot;, i) &#125; &#125; func consumer(ch &lt;-chan int) &#123; for i:=1;i&lt;3;i++&#123; tmp:=&lt;-ch fmt.Println(&quot;Receive:&quot;, tmp) &#125; &#125; func main() &#123; ch:=make(chan int,3) for i:=0;i&lt;5;i++&#123; go consumer(ch) go producer(ch) &#125; //这里sleep，因为main也是一个协程，防止其他的还没执行完，main就退出了 time.Sleep(5 * time.Second) &#125; 读者写者问题： 具体的PV操作可以看另外一篇博客 package main 读者优先的代码 import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) var mu sync.Mutex var mu_writer sync.Mutex var readercount int //读者优先 func reader( ) &#123; mu.Lock() if readercount==0&#123; mu_writer.Lock() &#125; readercount++ mu.Unlock() fmt.Printf(&quot;read ……\\n&quot;) mu.Lock() readercount-- if readercount==0&#123; mu_writer.Unlock() &#125; mu.Unlock() &#125; func writer() &#123; mu_writer.Lock() fmt.Printf(&quot;write ……\\n&quot;) mu_writer.Unlock() &#125; func main() &#123; for i:=0;i&lt;5;i++&#123; go writer() go reader() &#125; time.Sleep(5 * time.Second) &#125; 下面的是写者优先问题，与上面的类似，需要一个mu保护共享变量，writercount，然后还需要多一个mu_writer保护多个写者之间的访问 package main // 带缓冲区的channel import ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot; ) var mu sync.Mutex var mu_reader sync.Mutex var mu_writer sync.Mutex var writer_count int //写者优先 func reader( ) &#123; mu_reader.Lock() fmt.Printf(&quot;read ……\\n&quot;) mu_reader.Unlock() &#125; func writer() &#123; mu.Lock() if writer_count==0&#123; mu_reader.Lock() &#125; writer_count++ mu.Unlock() mu_writer.Lock() fmt.Printf(&quot;write ……\\n&quot;) mu_writer.Unlock() mu.Lock() writer_count-- if writer_count==0&#123; mu_reader.Unlock() &#125; mu.Unlock() &#125; func main() &#123; for i:=0;i&lt;5;i++&#123; go writer() go reader() &#125; time.Sleep(5 * time.Second) &#125;","path":"2022/06/26/GO/GO实现生产者消费者问题，读者写者问题/"},{"title":"labgob和labrpc","text":"labrpc参考链接 go gob包参考链接 什么是 RPC远程过程调用（Remote Procedure Call，简称 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而开发人员无需额外地为这个交互作用编程。如果涉及的软件采用面向对象编程，那么远程过程调用亦可称作远程调用或远程方法调用。 通俗的来讲就是，RPC 允许跨机器、跨语言调用计算机程序。例如我们用Go语言写了一个获取用户信息的方法 getUserInfo，并把Go语言程序部署在阿里云服务器上面，另外我们还有一个部署在腾讯云上面的 php 项目，需要调用Go语言的 getUserInfo 方法获取用户信息，php 跨机器调用 Go 方法的过程就是 RPC 调用。 在RPC框架中有三个重要的角色：RPC Server、RPC Client和Registry RPC Server：即Provider，暴露服务的服务提供者 RPC Client：即Consumer，调用远程服务的服务消费者 Registry：服务注册与发现的服务注册中心 RPC架构包含五个核心组件，Client，Client Stub，Server，Server Stub，NetWork Service，Stub可以理解为存根。 Client：客户端，服务的调用方 Client Stub：客户端存根，存放服务端的地址消息，负责将客户端的请求信息组装成网络消息，通过网络远程发送给服务提供方 Server：服务端，真正的服务提供方 Server Stub：服务端存根，接收客户端发来的消息，并将消息解压后调用本地服务方法 NetWork Service：底层网络传输，可以是TCP或HTTP 调用过程 1.客户端Client通过以本地调用的方式，调用远程接口服务; 2.客户端存根Client Stub接收到调用后，将调用信息对象进行序列化，组装成网络传输的二进制消息体; 3.客户端Client通过Sockets将消息发送到远程服务端; 4.服务端存根Server Stub收到消息后，对网络信息对象进行反序列化解码; 5.服务端存根Server Stub根据解码结果，调用服务端本地的接口服务; 6.本地接口服务执行，并将处理结果返回给服务端存根Server Stub; 7.服务端存根Server Stub将返回结果对象进行序列化，组装成消息体; 8.服务端Server再通过Sockets将消息发送到客户端; 9.客户端存根Client Stub收到结果消息后，对网络信息对象进行序列化解码; 10.客户端Client拿到最终接口处理结果。 Go语言中如何实现 RPC 的在Go语言中实现 RPC 非常简单，有封装好的官方包和一些第三方包提供支持。Go语言中 RPC 可以利用 tcp 或 http 来传递数据，可以对要传递的数据使用多种类型的编解码方式。 Go语言的 net/rpc 包使用 encoding/gob 进行编解码，支持 tcp 或 http 数据传输方式，由于其他语言不支持 gob 编解码方式，所以使用 net/rpc 包实现的 RPC 方法没办法进行跨语言调用。 golang标准库中的encoding/gob包一、golang中的gob包是什么?gob是golang包自带的一个数据结构序列化的编码/解码工具。 gob的目的是什么？应用场景？让数据结构能够在网络上传输或能够保存到文件中。gob可以通过json或gob来序列化struct对象，虽然json的序列化更为通用，但利用gob编码可以实现json所不能支持的struct方法序列化。但是gob是golang提供的“私有”的编码方式，go服务之间通信可以使用gob传输。一种典型的应用场景就是RPC。程序之间相互通信的。 labgob数据安全性检查：labgob6.824的labgob库在gob的基础上添加了安全性检查。尝试通过RPC发送非大写的字段会产生一系列错误的行为，包括错误计算和机器崩溃。因此，labgob库会警告未大写的字段名称。 labgob通过checkType函数在encode/decode之前检测数据中包含的结构体是否有未导出字段。 func checkType(t reflect.Type) checkType的思想就是查找t中的结构体，然后遍历字段，如果是非导出的字段会提示错误。如果t是切片、数组或者指针、字典等的话，会递归检查它们的元素，直到递归到基本类型才终止。 checkDefault用来在decode之前检测decode()的参数中是否提前覆盖了部分或全部数据。checkDefault调用checkDefault1，检测value的数据是否被覆盖了。 func checkDefault1(value reflect.Value, depth int, name string) 如果value是结构体、切片、数组、字典和指针等复杂结构，会递归检查其元素，直到递归到基本类型或者达到递归层数。通过检测该基本类型的数据和该类型的空值是否相同来判断是否被覆盖，否则会提示错误。 网络和客户端：labrpclabrpc库实现了基于通道的RPC。 labrpc模拟一个可能丢失请求，丢失回复，延迟消息以及断开特定主机的网络。这个网络使用labgob库encode/decode数据，以确保RPC不包含对程序对象的引用。 以下是labrpc中的接口： net：= MakeNetwork() -- 构建客户端节点、服务器节点的网络 end：= net.MakeEnd(endname) -- 创建一个客户端节点，以便与一台服务器通信。 net.AddServer(servername, server) --将一个服务器节点添加到网络。 net.DeleteServer(servername) -- 删除一个服务器。 net.Connect(endname，servername) -- 将客户端连接到服务器。 net.Enable(endname，enabled) -- 启用/禁用客户端节点。 net.Reliable(bool) -- false表示丢弃/延迟消息。 end.Call(&quot;Raft.AppendEntries&quot;, ＆args, ＆reply) --发送RPC，等待回复。&quot;Raft&quot;是要调用的服务的名称。 &quot;AppendEntries&quot;是要调用的方法的名称。Call()返回true，表示服务器执行了请求，并且回复有效。如果网络丢失了请求或回复或服务器已关闭，则Call()返回false。一个客户端节点上同时可以进行多个Call()调用。 srv：= MakeServer() -- 创建一个服务器节点 srv.AddService(svc) -- 一个服务器节点可以具有多种服务，例如Raft和k/v数据库。 svc：= MakeService(receiverObject) -- 创建一个服务，receiverObject的方法将处理客户端节点end发起的RPC调用 网络：NetWorkNetWork持有所有的客户端节点、服务器节点，并且可以实现网络传输丢包、切除节点等功能。 type Network struct &#123; mu sync.Mutex reliable bool longDelays bool // pause a long time on send on disabled connection longReordering bool // sometimes delay replies a long time ends map[interface&#123;&#125;]*ClientEnd // ends, by name enabled map[interface&#123;&#125;]bool // by end name servers map[interface&#123;&#125;]*Server // servers, by name connections map[interface&#123;&#125;]interface&#123;&#125; // endname -&gt; servername endCh chan reqMsg done chan struct&#123;&#125; // closed when Network is cleaned up count int32 // total RPC count, for statistics bytes int64 // total bytes send, for statistics &#125; MakeNetWork()函数创建一个NetWork，开启一个后台线程接收endCh传入的客户端请求，调用processReq(xreq)处理。 select &#123; case xreq := &lt;-rn.endCh: atomic.AddInt32(&amp;rn.count, 1) atomic.AddInt64(&amp;rn.bytes,int64(len(xreq.args))) go rn.processReq(xreq) case &lt;-rn.done: return &#125; endCh是一个传输reqMsg的channel，reqMsg包含客户端请求信息。 type reqMsg struct &#123; endname interface&#123;&#125; // name of sending ClientEnd svcMeth string // e.g. &quot;Raft.AppendEntries&quot; argsType reflect.Type args []byte replyCh chan replyMsg &#125; 在processReq中，首先通过readEndnameInfo来获取该客户端节点的相关状态，如果该节点被启用&amp;&amp;该节点连接的服务器节点存在&amp;&amp;有相应的服务比如Raft，就对请求进行处理，否则就返回false表示请求没有被处理。 func (rn *Network) processReq(req reqMsg) 处理客户端请求： 如果网络设置reliable为false，就休眠一段随机时间模拟线路延迟，然后随机选择是否模拟丢失请求并返回false给客户端节点。新开一条线程执行服务(在这里是Raft)的dispatch(req)函数。通过循环等待直到请求被处理或者服务不可用，将处理结果返回给客户端节点。当然这一切的前提都是通过Connect函数将客户端节点和服务器节点连接起来了。 func (rn *Network) Connect(endname interface&#123;&#125;, servername interface&#123;&#125;) 客户端节点：ClientEnd定义如下： type ClientEnd struct &#123; endname interface&#123;&#125; // this end-point&#39;s name ch chan reqMsg // copy of Network.endCh done chan struct&#123;&#125; // closed when Network is cleaned up &#125; ClientEnd包含有一个channel用来向NetWork中发送请求，NetWork将请求转发给对应的服务，在这个过程中可能会模拟网络通信问题；这个channel通过复制NetWork.endCh得到。 ClientEnd只有一个方法，就是用于发起RPC调用，向对应的服务发送请求。 func (e *ClientEnd) Call(svcMeth string, args interface&#123;&#125;, reply interface&#123;&#125;) bool 在Call方法中，首先根据传入的参数构建reqMsg，初始化其中的replyCh以便于接收NetWork传回的响应数据。通过e.ch向网络中发起请求，然后等待回复。将回复的结果decode到参数reply指向的地址中(reply一般为指针类型)。 服务器节点：Server服务器的结构体定义如下： type Server struct &#123; mu sync.Mutex services map[string]*Service count int // incoming RPCs &#125; 一个服务器中包含多个服务，例如有Raft或者k/v数据库等，都通过一个字典保存。 服务器可以通过AddService方法将服务添加到自己的服务集合中。 服务器中最主要的方法就是dispatch方法了，这个方法由收到客户端节点请求的NetWork调用，用于将请求分派给该服务器中的指定服务。 通过req.svcMeth获取服务的名称和方法名，req.svcMeth一般为&quot;Raft.AppendEntries&quot;，所以获得的服务名为&quot;Raft&quot;，方法名为&quot;AppendEntries&quot; 从服务器的服务集合中查找对应的服务，如果有该服务就直接调用该服务的dispatch方法来处理请求。否则就报错并返回false作为响应信息。 服务：Service服务是可以被RPC调用其方法的，一个服务器可以包含很多个服务。 type Service struct &#123; name string rcvr reflect.Value typ reflect.Type methods map[string]reflect.Method &#125; 通过MakeService初始化一个服务时，传入的参数是任意一个对象，之后的方法调用都是通过反射实现的，具体可以看之后的dispatch方法实现。 func MakeService(rcvr interface{}) *Service在MakeService方法中，使用反射遍历rcvr的方法，只把参数有三个且第三个参数是指针的方法添加到methods方法集合中。 for m := 0; m &lt; svc.typ.NumMethod(); m++ &#123; method := svc.typ.Method(m) mtype := method.Type mname := method.Name if method.PkgPath != &quot;&quot; || // capitalized? mtype.NumIn() != 3 || mtype.In(2).Kind() != reflect.Ptr || mtype.NumOut() != 0 &#123; &#125; else &#123; svc.methods[mname] = method &#125; &#125; 在上一小节可以看到，服务器会调用指定服务的dispatch方法，让它来处理对应的请求。 func (svc *Service) dispatch(methname string, req reqMsg) replyMsg 在Service.dispatch方法中，通过参数methname获取对应的方法，然后通过req中的信息构造方法中的参数，把方法执行之后的结果返回给上级调用者。 总结在Lab2中测试Raft代码，6.824实现了一个Config，用来控制网络的通断、客户端节点、服务器节点的创建、删除、模拟崩溃等操作，这些都是基于NetWork实现的。 所以总的测试思路： 1.使用NetWork创建多个客户端节点和服务节点，将客户端节点连接到指定的服务节点，即实现网络连接。 2.一个或者多个客户端同时向一个或多个服务节点(Raft)发送请求(包含客户端指令) 在发送请求时可以模拟网络的断开、服务器节点的崩溃重启 3. Raft将指令复制到其他的实例中，然后应用。在复制和应用的过程中： 模拟Raft实例中leader的崩溃、其他实例的崩溃以及一段时间之后重新加入集群、新实例加入集群。 labrpc库实现了基于通道的RPC，不是基于TCP和HTTP的。 总体的调用RPC的过程就是在labrpc包中（注意labgob包主要是用来编解码的），这里的client调用call函数，这里首先将参数用labgob编码成二进制，然后向client的管道（这个管道是network管道的一个拷贝）中发送请求数据，然后在makeNetwork中构建了一个network，然后不断地等待管道中的请求数据，然后开启协程处理调用请求（processReq），在这个协程中，（当客户端状态正常而且服务器存在，并且服务也是有的）如果网络不可信赖，会休眠一段随机时间模拟线路延迟，然后随机选择是否模拟丢失请求并返回false给客户端节点，然后新开一条线程执行服务(Raft)的dispatch(req)函数。通过循环等待直到请求被处理或者服务不可用，将处理结果返回给客户端节点。 在这个dispatch函数中，会具体的执行diapatch某个RPC服务（比如追加日志RPC之类的），就是分发到具体的RPC进行处理， 在具体的这个处理这个RPC服务的函数中，会解码请求的内容，然后call对应的方法，然后将结果编码然后返回reply的msg。","path":"2022/06/26/分布式/labgob和labrpc/"},{"title":"GO的make和new的区别","text":"Go语言中的 new 和 make 主要区别如下：make 只能用来分配及初始化类型为 slice、map、chan 的数据。new 可以分配任意类型的数据；new 分配返回的是指针，即类型 *Type。make 返回引用，即 Type；new 分配的空间被清零。make 分配空间后，会进行初始化；","path":"2022/06/25/GO/Go的make和new的区别/"},{"title":"GO的GMP模型","text":"参考链接 GMP：顾名思义，可以分为协程，线程，以及处理器 Goroutine：就是咱们常用的用go关键字创建的执行体，它对应一个结构体g，结构体里保存了goroutine的堆栈信息 Machine：表示操作系统的线程 Processor：表示处理器，有了它才能建立G、M的联系 MM就是对应操作系统的线程，最多会有GOMAXPROCS个活跃线程能够正常运行，默认情况下GOMAXPROCS被设置为内核数，假如有四个内核，那么默认就创建四个线程，每一个线程对应一个runtime.m结构体。线程数等于CPU个数的原因是，每个线程分配到一个CPU上就不至于出现线程的上下文切换，可以保证系统开销降到最低。 M里面存了两个比较重要的东西，一个是g0，一个是curg。 g0：会深度参与运行时的调度过程，比如goroutine的创建、内存分配等 curg：代表当前正在线程上执行的goroutine。 刚才说P是负责M与G的关联，所以M里面还要存储与P相关的数据。 刚才说M是负责P与G的关联，所以M里面还要存储与P相关的数据。 type m struct &#123; ... p puintptr nextp puintptr oldp puintptr &#125; p：正在运行代码的处理器 nextp：暂存的处理器 oldp：系统调用之前的线程的处理器 ProcessorProccessor负责Machine与Goroutine的连接，它能提供线程需要的上下文环境，也能分配G到它应该去的线程上执行，有了它，每个G都能得到合理的调用，每个线程都不再浑水摸鱼，真是居家必备之良品。 同样的，处理器的数量也是默认按照GOMAXPROCS来设置的，与线程的数量一一对应。 type p struct &#123; m muintptr runqhead uint32 runqtail uint32 runq [256]guintptr runnext guintptr ... &#125; 结构体P中存储了性能追踪、垃圾回收、计时器等相关的字段外，还存储了处理器的待运行队列，队列中存储的是待执行的Goroutine列表。 三者的关系首先，默认启动四个线程四个处理器，然后互相绑定。 这个时候，一个Goroutine结构体被创建，在进行函数体地址、参数起始地址、参数长度等信息以及调度相关属性更新之后，它就要进到一个处理器的队列等待发车。 啥，又创建了一个G？那就轮流往其他P里面放呗，相信你排队取号的时候看到其他窗口没人排队也会过去的。 假如有很多G，都塞满了怎么办呢？那就不把G塞到处理器的私有队列里了，而是把它塞到全局队列里（候车大厅）。 除了往里塞之外，M这边还要疯狂往外取，首先去处理器的私有队列里取G执行，如果取完的话就去全局队列取，如果全局队列里也没有的话，就去其他处理器队列里偷，哇，这么饥渴，简直是恶魔啊！ 如果哪里都没找到要执行的G呢？那M就会因为太失望和P断开关系，然后去睡觉（idle）了。 那如果两个Goroutine正在通过channel做一些恩恩爱爱的事阻塞住了怎么办，难道M要等他们完事了再继续执行？显然不会，M并不稀罕这对Go男女，而会转身去找别的G执行。 系统调用如果G进行了系统调用syscall，M也会跟着进入系统调用状态，那么这个P留在这里就浪费了，怎么办呢？这点精妙之处在于，P不会傻傻的等待G和M系统调用完成，而会去找其他比较闲的M执行其他的G。 当G完成了系统调用，因为要继续往下执行，所以必须要再找一个空闲的处理器发车。 如果没有空闲的处理器了，那就只能把G放回全局队列当中等待分配。 sysmonsysmon是我们的保洁阿姨，它是一个M，又叫监控线程，不需要P就可以独立运行，每20us~10ms会被唤醒一次出来打扫卫生，主要工作就是回收垃圾、回收长时间系统调度阻塞的P、向长时间运行的G发出抢占调度等等。","path":"2022/06/25/GO/GO语言的GMP模型/"},{"title":"GO的channel的用法","text":"参考链接 Channel是Go中的一个核心类型，你可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通讯(communication)。 它的操作符是箭头 &lt;- 。 ch &lt;- v // 发送值v到Channel ch中 v := &lt;-ch // 从Channel ch中接收数据，并将数据赋值给v 就像 map 和 slice 数据类型一样, channel必须先创建再使用: ch := make(chan int) 容量(capacity)代表Channel容纳的最多的元素的数量，代表Channel的缓存的大小。如果没有设置容量，或者容量设置为0, 说明Channel没有缓存，只有sender和receiver都准备好了后它们的通讯(communication)才会发生(Blocking)。如果设置了缓存，就有可能不发生阻塞， 只有buffer满了后 send才会阻塞， 而只有缓存空了后receive才会阻塞。一个nil channel不会通信。 可以通过内建的close方法可以关闭Channel。 你可以在多个goroutine从/往 一个channel 中 receive/send 数据, 不必考虑额外的同步措施。 Channel可以作为一个先入先出(FIFO)的队列，接收的数据和发送的数据的顺序是一致的。 blocking默认情况下，发送和接收会一直阻塞着，直到另一方准备好。这种方式可以用来在gororutine中进行同步，而不必使用显示的锁或者条件变量。","path":"2022/06/25/GO/GO的channel的用法/"},{"title":"GO的select的用法","text":"selectselect语句选择一组可能的send操作和receive操作去处理。它类似switch,但是只是用来处理通讯(communication)操作。它的case可以是send语句，也可以是receive语句，亦或者default。 receive语句可以将值赋值给一个或者两个变量。它必须是一个receive操作。 最多允许有一个default case,它可以放在case列表的任何位置，尽管我们大部分会将它放在最后。 如果有同时多个case去处理,比如同时有多个channel可以接收数据，那么Go会伪随机的选择一个case处理(pseudo-random)。如果没有case需要处理，则会选择default去处理，如果default case存在的情况下。如果没有default case，则select语句会阻塞，直到某个case需要处理。 需要注意的是，nil channel上的操作会一直被阻塞，如果没有default case,只有nil channel的select会一直被阻塞。 select语句和switch语句一样，它不是循环，它只会选择一个case来处理，如果想一直处理channel，你可以在外面加一个无限的for循环 timeoutselect有很重要的一个应用就是超时处理。 因为上面我们提到，如果没有case需要处理，select语句就会一直阻塞着。这时候我们可能就需要一个超时操作，用来处理超时的情况。下面这个例子我们会在2秒后往channel c1中发送一个数据，但是select设置为1秒超时,因此我们会打印出timeout 1,而不是result 1。 import &quot;time&quot; import &quot;fmt&quot; func main() &#123; c1 := make(chan string, 1) go func() &#123; time.Sleep(time.Second * 2) c1 &lt;- &quot;result 1&quot; &#125;() select &#123; case res := &lt;-c1: fmt.Println(res) case &lt;-time.After(time.Second * 1): fmt.Println(&quot;timeout 1&quot;) &#125; &#125; 其实它利用的是time.After方法，它返回一个类型为&lt;-chan Time的单向的channel，在指定的时间发送一个当前时间给返回的channel中。","path":"2022/06/25/GO/GO的select用法/"},{"title":"GO的slice和数组的区别","text":"数组是在由长度和类型决定的一种list，长度和类型都一样的才是一种类型，长度不可变，在传参的时候是值拷贝的（默认是深复制的）。 slice是可变的，是一个结构体里面包括指向实际数组的指针，长度和容量，超过容量会以两倍大小扩容。当长度没超过容量的时候会在对应的数组里面增加内容，如果增加的大小超过了容量，那么会有一块新内存放内容，指针地址会变化。参考地址","path":"2022/06/25/GO/GO的slice和数组的区别/"},{"title":"STL:默认的内存分配器","text":"STL:默认的内存分配器","path":"2022/06/25/C++/STL的默认的内存分配器/"},{"title":"main函数执行之前发生了什么","text":"在 main函数之前发生了什么对于编程人员来讲，main 函数是程序的入口，但事实上 main 函数之前也发生了很多操作。在 main 函数开始前，分成两部分 “系统调用部分” 和 “C++ 程序自身的部分”。我们首先假设程序的 main 函数原型是int main(int argc, char *argv[]);，其中，argc 指命令行参数的数目， argv 是指向参数的各个指针所构成的数组。 系统调用部分对于 Linux 系统而言，当内核执行 C 程序时使用 exec 函数，在调用 main 前先调用一个特殊的启动例程。可执行文件将此启动例程指定为程序的起始地址。启动例程从内核取得命令行参数和环境变量值。 简而言之，系统会为你设置栈，并且将argc，argv和envp压入栈中。文件描述符0，1和2（stdin, stdout和stderr）保留shell之前的设置。加载器会帮你完成重定位，调用你设置的预初始化函数。当所有搞定之后，控制权会传递给_start()，即程序的入口函数 程序本身的 main() 执行前入口函数对运行库和程序运行环镜进行初始化，包括 堆、I/O、线程、全局变量构造等等。入口函数完成初始化后，调用 main 函数，正式开始执行程序主体部分。 main() 结束之后呢？main函数执行完毕后，返回到入口函数，入口函数进行清理工作，包括全局变量的析构、堆销毁、关闭I/O等，然后系统调用结束进程。 main函数结束可以通过 return 0;或者 exit(0) 来结束，此时程序并非直接结束，而是先调用一些终止处理程序然后再结束。可以使用int atexit(void (*func)(void));来追加自定义终止处理程序，终止处理程序由 exit函数自动调用，调用顺序与登记顺序相反。如果main函数发生了异常或者使用_exit和_Exit来退出程序，则不会调用终止处理程序。","path":"2022/06/22/C++/main函数执行之前发生了什么/"},{"title":"attention机制","text":"广州网易（可分为网易互联网，网易雷火，网易互娱）唯品会欢聚时代酷狗音乐UCzakerSHEIN太平洋三七互娱科大讯飞百度成都摩尔线程intelAMD华为中国农业银行中国建设银行中国工商银行中国邮政储蓄银行长沙tigergrapher三一重工中联重科芒果TV方正证券国开行农发行进出口银行中国农业银行中国建设银行中国工商银行中国邮政储蓄银行交通银行深圳大疆北京上海等","path":"2022/06/18/秋招/秋招投递/"},{"title":"Cmake学习","text":"aux_source_directory(&lt;dir&gt; &lt;variable&gt;) 收集指定目录中所有源文件的名称，并将列表存储在提供的变量中。 # 指定生成目标 add_executable(Demo main.cc MathFunctions.cc) 参考链接 https://www.cnblogs.com/sddai/p/10328977.html","path":"2022/05/10/makefile和Cmake/Cmake学习/"},{"title":"makefile学习","text":"-w：关闭编译时警告 -Wall：编译后显示所有警告。 -W：类似-Wall，会显示警告，但是只显示编译器认为会出现错误的警告 -O2:O2会尝试更多的寄存器级的优化以及指令级的优化，它会在编译期间占用更多的内存和编译时间。 foo = abc // 定义变量并赋值 bar = $(foo) // 使用变量, $(变量名) CC = gcc #arm-linux-gcc CPPFLAGS : C预处理的选项 -I CFLAGS: C编译器的选项 -Wall -g -c LDFLAGS : 链接器选项 -L -l all: install: 这两个的区别在于make install，只会执行install后面的，但是make会执行第一个目标，如果all是第一个目标，那么make all和make是一样的 最简单的makefile,这里的calc，代表要生成的目标，冒号后面是它的依赖 calc: main.c getch.c getop.c stack.c gcc -o calc main.c getch.c getop.c stack.c 用了变量替换的makefile，缺点在于修改一个文件时就要全部重新编译的问题。而且如果我们修改的是calc.h文件，make就无法察觉到变化了（所以有必要为头文件专门设置一个常量，并将其加入到依赖关系表中）。&lt;!—hexoPostRenderEscape:cc = gccprom = calcsource = main.c getch.c getop.c stack.c $(prom)&lt;/span&gt;: $(source)&lt;/span&gt; $(cc)&lt;/span&gt; -o $(prom)&lt;/span&gt; $(source)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;还是没能解决当我们只修改一个文件时就要全部重新编译的问题，但是解决了头文件变化时候依赖关系的问题&lt;!—hexoPostRenderEscape:cc = gccprom = calcdeps = calc.hobj = main.o getch.o getop.o stack.o $(prom)&lt;/span&gt;: $(obj)&lt;/span&gt; $(cc)&lt;/span&gt; -o $(prom)&lt;/span&gt; $(obj)&lt;/span&gt; main.o: main.c $(deps)&lt;/span&gt; $(cc)&lt;/span&gt; -c main.c getch.o: getch.c $(deps)&lt;/span&gt; $(cc)&lt;/span&gt; -c getch.c getop.o: getop.c $(deps)&lt;/span&gt; $(cc)&lt;/span&gt; -c getop.c stack.o: stack.c $(deps)&lt;/span&gt; $(cc)&lt;/span&gt; -c stack.c &lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;简化的makefile， 在这里，我们用到了几个特殊的宏。首先是%.o:%.c，这是一个模式规则，表示所有的.o目标都依赖于与它同名的.c文件（当然还有deps中列出的头文件）。再来就是命令部分的$&lt;和$@，其中$&lt;代表的是依赖关系表中的第一项（如果我们想引用的是整个关系表，那么就应该使用$^），具体到我们这里就是%.c。而$@代表的是当前语句的目标，即%.o。这样一来，make命令就会自动将所有的.c源文件编译成同名的.o文件。不用我们一项一项去指定了。整个代码自然简洁了许多。 cc = gcc prom = calc deps = calc.h obj = main.o getch.o getop.o stack.o $(prom): $(obj) $(cc) -o $(prom) $(obj) %.o: %.c $(deps) $(cc) -c $&lt; -o $@ 增加清理功能的makefile cc = gcc prom = calc deps = calc.h obj = main.o getch.o getop.o stack.o $(prom): $(obj) $(cc) -o $(prom) $(obj) %.o: %.c $(deps) $(cc) -c $&lt; -o $@ clean: rm -rf $(obj) $(prom)","path":"2022/05/10/makefile和Cmake/makefile学习/"},{"title":"395. 至少有 K 个重复字符的最长子串","text":"这里一开始看题很难想到，但是我们如果假设字符种类是知道的，那么可以直接用滑动窗口， 那么我们直接遍历字符种类的个数就可以。 与传统的滑动窗口的不同之处在于，需要手动选取字符类型数目 class Solution &#123; public: int longestSubstring(string s, int k) &#123; int len=s.size(); vector&lt;int&gt; count; int res=0; for(int i=1;i&lt;=26;++i) &#123;//与传统的滑动窗口的不同之处在于，需要手动选取字符类型数目 count=vector&lt;int&gt;(26,0); for(int j=0,r=0,cnt=0,sum=0;j&lt;len;++j) &#123; count[s[j]-&#x27;a&#x27;]++; if(count[s[j]-&#x27;a&#x27;]==1) &#123; cnt++; &#125; if(count[s[j]-&#x27;a&#x27;]==k) &#123; sum++; &#125; while(cnt&gt;i) &#123; int p=s[r++]-&#x27;a&#x27;; count[p]--; if(count[p]==0) cnt--; if(count[p]==k-1) sum--; &#125; if(cnt==sum) &#123; res=max(res,j-r+1); &#125; &#125; &#125; return res; &#125; &#125;;","path":"2022/05/10/算法/滑动窗口/395. 至少有 K 个重复字符的最长子串/"},{"title":"webserver项目","text":"（这里的epollout事件需要注意的一点是，因为我们一开始关注epollin，所以收到数据的时候会读，然后后面改成关注epollout，当内核可写/能写的时候，epollwait就会返回写事件） 一开始初始化webserver对象里的 线程池对象，以detach的方式创建8个线程。 计时器堆对象，即初始化堆的大小（vector构建的） epoller对象，创建epollFd_，初始化epoll_event（epoll事件）的vector的大小。 初始化http连接类的静态变量值（包括静态资源目录，用户连接数目） 数据库连接池 设置ET或者LT模式，（默认listenEvent和connEvent均为边缘触发）同时设置HttpConn连接类的模式（静态变量初始化） 创建监听描述符，设置监听地址，设置优雅关闭，设置监听套接字，设置套接字状态，设置端口复用，绑定套接字监听地址，设置监听可以排队的连接数，将监听描述符加入到epoll的监听事件中，监听EPOLLIN读事件，设置监听事件为非阻塞的 初始化LOG类设置，如果消息队列大于0，说明启用了异步写入log，那就要初始化异步写入所需的变量，还有一个就是需要开启异步线程，不断取出队列中数据，写入文件中。如果小于0，那么设置变量状态为不开启异步写入。获取当前时间，保存到变量t中，初始化文件路径以及后缀名，根据 路径+时间+后缀名创建log文件，使用互斥量保证线程安全，在创建文件之前需要清空之前文件的缓冲区，将当前的数据都写入到之前的文件中去。 启动服务器之后,不断循环下面过程 一开始设置的超时时间为-1，没有事件就阻塞，然后后面每次设置wait的时间为删除超时节点之后的最近一个连接的超时时间 epoll等待到事件之后，根据不同的事件进行不同的处理 如果是事件的套接字为监听描述符，那么处理客户端的连接事件，这个时候可能有多个连接事件，因为这里设置的是ET模式，所以会不断地accept，然后初始化一个http连接对象，初始化这个对象的读写缓冲区，地址和fd。同时在定时器堆中添加一个定时器，添加epoll监听EPOLLIN事件，连接设置为非阻塞，直到没有连接返回-1，如果这里的连接数超过了定义的最大数量，向客户端发送错误信息，发送完之后关闭连接。 如果epoll事件为EPOLLRDHUP，EPOLLHUP，EPOLLERR，表示连接出现问题，关闭HTTP连接. 若epoll事件为EPOLLIN，表示有对应套接字收到数据，需要读取出来，这个时候首先调整定时器的过期时间，然后线程池中添加读数据的任务，调用了模板函数，使用bind方法绑定任务，向任务队列添加任务，然后唤醒一个线程。 线程池中线程被唤醒之后，取任务（使用右值的方法），然后执行任务。这里调用Httpconn的read方法读取socket中的数据，保存到读缓冲区中。 在读数据的时候，用一个vector剩下的容量和65k的栈空间读入数据，如果读取的数据长度小于0，那么肯定是发生错误了，将错误码返回，如果读取的数据比缓冲区（vector）小，移动缓冲区指针即可。如果读取的数据比缓冲区大，首先将写指针指到缓冲区尾部表明这一块内存都写满了。然后进行空间扩容，如果前面已经读取的内容加后面剩下的空间够，那么就把需要读的数据复制到开头，然后更新读写指针，后面的用来读新的。如果不够的话，那么就在后面扩充len+1的大小。扩充之后，将栈空间的数据写到缓冲区中，更新写指针。 如果读数据完成之后，错误信息小于0并且错误码不为EAGAIN，说明出现错误了，此时关闭http连接，同时删除这个监听的套接字。如果没错误，则Http连接对象处理数据，成功处理则将epoll在该文件描述符上的监听事件改为EPOLLOUT写事件。如果没有处理成功，说明还需要读，继续改为epollin。 当上一条数据请求完之后（即状态码为Finish），重新初始化http请求对象的内容。检查读缓冲区的数据，没有就返回false。首先对读缓冲区进行解析。 如果读缓冲区没有数据返回NO_REQUEST，然后用状态机的方法解析http请求头，先一行一行得解析，先解析请求行，将解析的数据保存下来，然后改为HEADER状态，如果解析失败，返回false，直接返回BAD_REQUEST。然后解析请求头，每次将解析的数据保存下来，如果没匹配到，说明这是空行，那么状态改为BODY。注意我们如果状态改为body，同时method为Get，这时候状态码应该改为Finish，清空读缓冲区，返回GET_REQUEST。当解析body的时候，说明是POST，同时注意这里的提交数据只支持一种方式，然后将post的数据解析完，存起来，这里的形式是a=1&amp;b=2这种，空格被编码为+,非字母字母字符，encode成百分号+其ASCII码的十六进制。同时根据路径判断这里的数据是请求还是登录，如果验证成功，则返回欢迎页面，否则返回错误页面。 验证的这个地方，首先获取一个sql连接，然后查询对应用户，如果是登录并且用户存在密码正确，那么返回成功，如果是注册，并且用户名没被使用，那么在数据库里面插入数据，返回成功，其他返回错误。 解析完body之后，状态置为FINISH，清空读缓冲区，返回GET_REQUEST。如果没能解析完，那么返回NO_REQUEST。如果中间出现未知的状态码，返回INTERNAL_ERROR 如果为GET_REQUEST说明解析完，那么初始化httpResponse对象的路径,是否为长连接，状态码200，以及资源目录。如果为NO_REQUEST说明请求不完整，返回false。其他情况初始化httpResponse对象的路径,为短连接，状态码400，以及资源目录。然后拼装返回的头部以及文件信息。 如果文件路径不存在，状态码为404，如果没有权限，状态码为403。若状态码码为400，403，404其中之一，则将文件路径与信息读取到path与mmFileStat变量中。根据状态码将返回信息中的状态行添加到写缓冲区中。然后将返回信息的响应文件映射到内存中，这里采用的是mmap方式，将映射的地址赋值给mmFile_变量。同时继续向写缓冲添加信息（内容长度）。 写缓冲区读指针到写指针中间的内容是需要输出的，以及映射的问题的文件内容需要输出。保存到一个iov_中用于后续输出，返回true。 若epoll事件为EPOLLOUT，表示返回给客户端的数据已准备好，需要向对应套接字连接发送数据。这个时候首先调整定时器的过期时间，然后线程池中添加写数据的任务，调用了模板函数，使用bind方法绑定任务，向任务队列添加任务，然后唤醒一个线程。 线程池中线程被唤醒之后，取任务（使用右值的方法），然后执行任务。这里调用httpconn类的write方法向socket发送数据 这里是通过将iov写到对应的fd中，若是缓冲区满了，errno会返回EAGAIN，记录错误值，返回写的长度。如果发送的数据长度大于iov[0].iovlen，说明第一块区域的数据是发送完毕，再根据多发送了多少调整iov[1]的取值，同时区域一的数据发送完毕，回收缓冲空间，并将长度归0。如果没有传输完区域一的内容那么就继续传区域一的，同时回收对应长度的空间。两个传输位置长度都为0，表示传输结束。在ET状态下，如果没有发送完，继续发送。 如果还需要写的数据为0，那么完成传输，检查客户端是否设置了长连接字段，如果客户端设置了长连接，那么调用OnProcess函数，因为此时的client-&gt;process()会返回false，所以该连接会重新注册epoll的EPOLLIN事件。若是缓冲区满了，errno会返回EAGAIN，这时需要重新注册EPOLL上的EPOLLOUT事件。其余情况，关闭连接。 其余事件皆为错误，向log文件写入该事件 Log类 根据宏定义以及##VA_ARGS可以调用可变参数以及字符串常量数据，这个类也是单例的模式，在第一次使用的时候初始化对象，然后每次根据是LOG_DEBUG，LOG_INFO，LOG_WARN，LOG_ERROR调用不同等级的信息调用write，向log文件中写入log信息 具体的是获取当前时间，如果当前日期相比初始化的时候的日期变了，也就是到第二天了，或者当前log文件行数达到规定的最大值时都需要创建一个新的log文件，创建文件时上锁，保证线程安全，同时需要将缓冲区的数据写入到之前的文件中，关闭之前的文件，然后创建新文件，更新文件指针指向新文件。 首先加锁保证线程安全，然后组装信息至缓冲区buff中，移动缓冲区指针，向缓冲区中写入日志级别信息，根据用户传入的参数，向缓冲区添加数据，移动缓冲区指针，写入换行符。根据变量选择是否异步写入，如果是异步写入，那么向阻塞队列中写入缓冲区信息，如果不是异步写入，直接将缓冲区内容写入到文件，然后回收缓冲区空间。 在析构时将所有log信息写入文件，再关闭异步的写入线程。 webserverC++实现的高性能web服务器，经过webbench压力测试可以实现上万的qps 构造函数一开始初始化当前的绝对目录，初始化sqlpool，设置ET模式，并且注册监听对端关闭的事件，创建listenfd, 然后调用start函数，每次先获取下一次定时器过期的时间，wait这么久，收到事件就去给epoll模块处理， 如果是消息事件的fd=listendf，accpet这个，然后在epoller中加入这个fd，然后设置定时器。同时设置非阻塞。这里要一直循环就是当accept接受不到新连接时才会跳出 如果是事件是这些情况EPOLLRDHUP 或者EPOLLHUP 或者 EPOLLERR，即代表对端关闭，那么就关闭连接。删除epoll中的fd，同时调用httpCon的close 如果是需要读的事件EPOLLIN，就给线程池加入read的任务，这个任务被线程池的线程执行后，先调用webserver的回调函数，在这里面如果是read就调用httpconn的read函数，出错时需要调用关闭连接的函数（这里删除epoll_fd，调用httpcon的close函数），如果处理好了，就设置为epollout，否则设置为epollin。 如果是write，就给线程池加入write的任务，这个任务被线程池的线程执行后，先调用webserver的回调函数，然后调用httpcon的写函数，将iov的内容写出到fd中，如果写完成，同时keepalive的情况，用httpcon的处理函数，如果处理好了，就设置为epollout，否则设置为epollin。如果需要写的内容大于0，并且错误内容为EAGAIN，则修改fd为epollout，返回，否则调用关闭连接的函数。 buffer主要是用于当web上的消息发送过来时，要先发送到缓冲区，再从缓冲区读，本地发送去web的时候，也要先发送到缓冲区，然后将缓冲区写出到某个fd。 这里主要有两个原子变量，readpos_,write_pos（原子变量）,来指示读到哪里以及写到哪里了，两个指针中间就是还需要读的(或者需要写的)。prepen就是指的readpos之前的，write之后的就是还可以利用的。 缓冲区这里用的是vector 来存储的，除了用vector还会使用一个栈数组stack_buf[65536]来存储 比如当读fd的时候，如果vector存不下，就会放到stack_buf里面，同时进行vector扩容，扩容时刚好扩到比缓存大1个字节的大小，同时如果扩容的时候发现还能放的下就移动数据到vector头部的位置。 当写fd的时候，将readpos和writepos之间的内容写到fd中就可以。 http模块这个模块分为三个部分，主要是httpcon，httprequest，httpresponse模块。 httpcon模块主要是负责http连接的，包含有读写缓冲区，一个httprequest对象，一个httpresponse对象，两个个iovec缓存数组，fd，sockaddr_in（套接字地址）,以及资源路径，http连接的数目（原子变量），以及是否ET模式。 当读fd的时候，需要调用读buffer的接口，直到读到内容长度小于等于0，并且会提供saveError信息. 写fd的时候，将iovec的内容写到fd中，直到写的长度小于等于0，同时每次写要更新iovec的base位置和len位置。 还有一个处理用户请求的函数，当数据不完整的时候，还需要等待数据的时候，返回false，可以发送响应报文的时候返回true。(有错误的话code会相应地设为BAD_REQUEST,INTERNAL_ERROR等），当已经读完缓冲区的数据的时候，去匹配读缓冲区的内容，同时根据结果设置文件路径（包含相对路径和文件绝对路径）和状态码，iskeepalive，然后在写缓冲区设置respose内容，同时在iov_0中设置响应头，在iov_1中设置文件。 close函数，取消文件映射，然后设置关闭，usecount数目减少，关闭某个fd httprequest模块包含状态码，方法，路径，版本，body部分。 主要的函数为parse函数，匹配缓冲区内容，这里的实现是通过状态机方法来匹配的，每次查一行，查到\\r\\n的位置，然后查看状态机的行为，去匹配这一行，匹配的时候用的是regex的正则语法？？，状态行匹配主要是获得方法，相对路径，版本，和状态码。相对路径这里要根据路径变换到自己的本地文件相对路径名下。 然后是匹配head部分，记录信息到header_哈希表中。 匹配body部分，这里要先匹配post，就是如果method为post，并且匹配url中的key，Value到post_的哈希表中，如果此时的相对路径为注册或者登陆，那么就验证登陆信息，如果验证成功就返回欢迎，否则返回error路径，在验证的过程中，通过mysql查询对应的密码和账号，如果账号存在并且为登陆，那么就返回结果为ok，否则，插入对应的mysql，然后根据结果返回，结束的时候需要释放sqlpool的一个位置。 然后转换为Finnish状态机 httpResponse模块主要由makereponse函数对应，然后先获取对应的文件，确定状态码，如果状态码为4XX就获取错误码对应的文件，并把mmFileStat_指向这个html。 然后添加状态行。（http1.1） 添加头部，头部需要确定添加不添加keep-alive然后添加Content-type 然后添加body部分，这个部分先获取指向对应文件的指针，然后用mmap映射到内存中提高访问速度，建立一个写入时拷贝的私有映射，注意析构函数的时候需要用munmap接触进程的映射关系，当映射关系解除后，对原来映射地址的访问将导致段错误发生。 当映射错误的时候，或者打开文件错误的时候需要写入缓冲区errorContent Log 模块blockqueue类似一个生产者消费者的阻塞队列，生产者如果满了就等待，没满就生产，消费者相反，主要由两个条件变量和锁来实现 log是实现的日志系统，静态局部变量实现单例模式，对运行状态错误信息和访问数据进行记录，按天分类，可分为异步和同步写入 其中异步写入方式，将生产者-消费者模型封装为阻塞队列即（blockqueue），创建一个写线程，工作线程将要写的内容push进队列，写线程从队列中取出内容，写入日志文件。 同步日志，日志写入函数与工作线程串行执行，由于涉及到I/O操作，当单条日志比较大的时候，同步模式会阻塞整个处理流程，服务器所能处理的并发能力将有所下降，尤其是在峰值的时候，写日志可能成为系统的瓶颈。 init生成日志文件 &amp;&amp; 判断写入方式 通过单例模式获取唯一的日志类，调用init方法，初始化生成日志文件，服务器启动按当前时刻创建日志，前缀为时间，后缀为自定义log文件名，并记录创建日志的时间day和行数count。 写入方式通过初始化时是否设置队列大小（表示在队列中可以放几条数据）来判断，若队列大小为0，则为同步，否则为异步。 日志分级与分文件 日志分级的实现大同小异，一般的会提供五种级别，具体的， Debug，调试代码时的输出，在系统实际运行时，一般不使用。Warn，这种警告与调试时终端的warning类似，同样是调试代码时使用。Info，报告系统当前的状态，当前执行的流程或接收的信息等。Error和Fatal，输出系统的错误信息。 上述的使用方法仅仅是个人理解，在开发中具体如何选择等级因人而异。项目中给出了除Fatal外的四种分级，实际使用了Debug，Info和Error三种。 超过行数、按天分文件逻辑： 日志写入前会判断当前day是否为创建日志的时间，行数是否超过最大行限制 若为创建日志时间，写入日志，否则按当前时间创建新log，更新创建时间和行数 若行数超过最大行限制，在当前日志的末尾加count/max_lines为后缀创建新log 将系统信息格式化后输出，具体为：格式化时间 + 格式化内容 调用流程 主线程调用init初始化并获得日志文件指针，如果是异步则创建线程从阻塞队列获取日志字符串。 程序中调用LOG_INFO等同/异步写日志，同步直接写，异步放入阻塞队列 参考链接 https://blog.csdn.net/qq_36459662/article/details/106901292 PoolthreadPool在构造函数中，基本原理是维护一个任务队列queue和一个线程池vector .每个线程都是一个无限循环,当任务队列为空时wait,不为空时取一个任务执行.每添加一个新任务都会调用notify_one尝试唤醒一个线程.设计细节可以参考项目源码. sqlconnPool局部静态变量实现单例模式同时init中向队列中加入n个已经连接的sql连接，然后初始化信号量。 每次连接的时候，信号量-1，然后队列pop，然后返回pop的sql。 每次释放的时候，信号量+1，队列push这个sql。注意需要加锁 析构函数中需要关闭pool，关闭pool的时候，需要pop每个sql并关闭。 同时为了保持RAII，用一个类RAII类封装sqlpool，每次构造函数从pool提供sql，同时西沟函数自动将sql加入pool。 定时器timer为了提高Web服务器的效率，我们考虑给每一个HTTP连接加一个定时器。 定时器给每一个HTTP连接设置一个过期时间，然后我们定时清理超过过期时间的连接 我们还需要考虑一下如何管理和组织这些定时器。设置定时器的主要目的是为了清理过期连接，为了方便找到过期连接，首先考虑使用优先队列，按过期时间排序，让过期的排在前面就可以了。但是这样的话，虽然处理过期连接方便了，当时没法更新一个连接的过期时间。 最后，选择一个折中的方法。用vector容器存储定时器，然后在这之上实现堆结构，同时用哈希表来标记每个位置fd的Vector的为位置。 每一个HTTP连接的fd都用来标记唯一的定时器，记为id。同时，我们还需要设置每一个HTTP连接的过期时间。 为了后面处理过期连接的方便，我们给每一个定时器里面放置一个回调函数，用来关闭过期连接。 为了便于定时器结点的比较，主要是后续堆结构的实现方便，我们还需要重载比较运算符。 删除某个id的定时器，主要通过先调用回调函数删除http连接，然后删除对应的堆节点。 删除堆节点主要是先和堆尾交换位置，然后调整堆，然后删除哈希表的内容删除堆尾的元素。 调整id的时间，主要是通过先更新对应的节点的时间，然后调整堆。 清除超时的节点主要是通过，将堆头部的节点全都清除直到找到没超时的节点，节点总是直到开头才能被清除。 获取下一个处理超时定时器的时间，查看堆头的超时节点还有多久超时，返回时间，如果已经超时，就返回0。 epoll模块主要提供了几个函数，addfd，加入某个监听的fd， modfd，修改某个fd的监听内容 delfd，删除某个监听的fd。 或者epoll_wait 参考链接 https://github.com/InnovatorZhang/my-WebServer https://github.com/Zongyin-Hao/SimpleWebServerhttps://mp.weixin.qq.com/s/BfnNl-3jc_x5WPrWEJGdzQhttps://github.com/qinguoyi/TinyWebServerhttps://mp.weixin.qq.com/s?__biz=MzAxNzU2MzcwMw==&amp;mid=2649274431&amp;idx=1&amp;sn=2dd28c92f5d9704a57c001a3d2630b69&amp;chksm=83ffb167b48838715810b27b8f8b9a576023ee5c08a8e5d91df5baf396732de51268d1bf2a4e&amp;token=1686112912&amp;lang=zh_CN#rdhttps://blog.csdn.net/qq_36459662?type=bloghttps://blog.csdn.net/hao_zong_yin/article/details/118977278","path":"2022/05/04/webserver/webserver项目/"},{"title":"yield sleep  wait区别","text":"yield（）暂时交出 cpu 控制权，从 running 状态转为 runnalbe 状态，但是仍有 可能被调度， sleep（）线程指定休眠一段时间， wait（）在其他线程调用此对 象的 notify（）或 notifyAll（）方法时才能继续执行 线程中 sleep()方法和 yeild()方法的主要区别: 1.sleep()方法会给其他线程运行的机会,而不管其他线程的优先级,因此会给较 低优先级的线程运行的机会； 2.yeild()方法只会给优先 级相同的或者比自己高的线程运行的机会.3.sleep()方法使线程进入阻塞状态,而 yeild()方法使线程进入就绪状态.","path":"2022/04/22/操作系统/yield和sleep和wait区别/"},{"title":"跳表","text":"跳表跳表参考文章","path":"2022/04/20/算法/树/跳表/"},{"title":"6.824 实验","text":"lab2首先是选举，raft必须保证大部分机器可用。 以下是一些raft的基础的内容，三种角色，leader，candidate，follower。 follower对于每个机器，一开始是follower，然后每隔一段时间如果没有收到Leader的心跳，那么任期+1，变为candidate，投票给自己，然后启动新的协程发起选举（如果在这过程中任期被改变或者role被改变（？？需不需要变为leader），那么选举结束），向其他的机器发送RPC，请求它们投票。 如果收到的reply的任期比我更大，那么转变为follower，更新任期。（需要保存磁盘） 如果收到投票给我的结果，并且我还是candidate，那么直接票数+1，超过半数的票，变为leader，并且初始化nextIndex为最后一条日志的索引值+1（代表下一条需要复制给server的日志索引，索引0代表快照）（需要保存磁盘） requestVoteRPC实现如果当收到来自其他server的选举请求的时候，如果对方任期更旧直接拒绝投票。 如果任期更新，那么更新自己的任期，并且转变为follower。（需要保存磁盘） 如果我的日志更新（比较日志任期和索引）那么也拒绝投票。 如果我的日志没有更新，同时我还没投票或者已经投了它（说明之前返回的RPC丢失了），那么投票给他，更新任期，刷新心跳（保存磁盘） 否则（说明已经投了别人），拒绝投票。 leaderleader每隔一段时间sleep之后开始处理事务，查看nextIndex中的日志，如果index比leader快照的日志还旧，就发起InstallSnapshotRPC请求。 1.应对InstallSnapshotRPC请求的回复如果对方任期更新，那么更新任期，转为follower，然后（保存磁盘），否则更新nextIndex为快照的最后一条日志号+1. 1.1 InstallSnapshotRPC请求当收到来自leader 的安装快照RPC的时候，首先肯定检查任期，任期太旧直接拒绝然后回复，然后变为follower（防止此时为candidate）。如果我的快照比leader发来的快照更新，那么就直接返回，不需要安装。否则，把对应的leader发来的快照以及我比leader快照更新的信息，打包到一起变为server的log，然后应用leader快照到状态机，然后更新commitIndex,快照数据（保存到磁盘）。 2.应对AppendEntriesRPC请求的回复否则就发送日志和心跳，这个时候要把从nextIndex到自己日志的最后一条日志复制给对方，然后附加自己，commitIndex（已经提交的索引号），之前已经已经发送的最后一条日志的索引和任期，以及自己的任期。发起AppendEntriesRPC请求 如果收到AppendEntriesRPC回复，如果对方拒绝，如果是因为对方的任期更新，那么更新任期，变为follower（需要保存磁盘），如果是因为日志号冲突了，那么更新自己的nextIndex（需要保存磁盘），然后返回。 如果复制的日志太老了早就复制过了，那么直接返回 如果没有，那么更新nextindex，matchIndex(每个服务器已经复制的最高索引), （检查已经提交的日志索引如果大于等于已经复制到其他的服务器的索引，直接返回（这个时候说明已经提交了，后面再做没有必要）） （检查fig8的情况，如果复制的日志的任期和当前的任期不一致，那么不能提交，直接返回（后面也没必要了）） 对于每个server，如果已经复制的日志索引（matchIndex）已经大于想要提交的日志索引,那么计数值+1，如果超过半数，那么就直接提交，应用到状态机，更新已经提交的索引号（需要保存磁盘）。 2.1AppendEntriesRPC请求首先肯定检查任期，如果leader的任期太旧，直接拒绝。否则，先转变为follower，更新任期，刷新心跳。 如果leader已经发送的最后一条日志索引比server的快照的最后一条还旧，说明发来的日志有一部分是重复的，直接返回。 如果leader已经发送的最后一条日志记录和server的冲突了，同时leader的lastcopyindex大于快照日志索引小于server最大的日志索引直接回退到这个任期的第一条日志（说明下一次leader从这个任期的第一条开始发）。如果同时leader的lastcopyindex大于server最大的日志索引，那么直接返回快照的最大索引+1。然后返回结果。 前面保证了lastcopyIndex在lastSnapshotIndex与lastLogIndex之间，然后追加日志（如果追加的日志比lastLogIndex小就不用追加）。 从那么从server发过来的commitIndex到leader的commitindex，应用到状态机。 Go 语言在这里的特性，Goroutine这个的用法在于比如说一开始每次机器都会有两个协程不断循环检查自己是follower，以及是leader的情况 follower：当发现leader给自己的心跳超时的时候，就开启协程开始选举，在这个协程开启n个协程来请求其他的机器给自己投票，每个请求投票的协程依据情况处理。 leader：每次经过一定的时间，对于每一个follower的机器，发现follower的机器太旧的时候，就启动一个发送快照的协程来处理，否则启动一个发送心跳和日志的协程来处理。 lab3Gob的小问题Gob这个包序列化数据的时候，需要知道具体的类型，才可以将它正确的反序列化回来。我们在Start()中传入的参数是interface{}类型，所以如果不进行一些预先的安排，那么在follower中不能将OpArgs反序列出来。所以在StartKVServer()中需要调用gob.Register来注册一下 只有leader可以处理客户端的请求，如果其他角色接收到了请求，会重定向到leader。（这个实际上代码没这么写，我看大家都是如果不是leader就换下一个直到找到leader）。 客户端发起请求，然后 监听raft状态机以及如何去重保持幂等性对于每隔监听raft状态机的协程，如果发现是快照的命令，那么就读取快照，如果是op（如get，putappend）就首先去重，如果不是重复的命令就在kvdb中存下来，如果是重复的就不用做了，保持了幂等性，这个地方为什么不在RPC响应那里做呢，那里实际上有可能执行完之后，鉴定到raft状态机的命令，但是返回的resChan丢失了，这样就客户端就得不到结果了，因为会重发，但是重发总是被过滤。 对于返回给RPC的消息管道，用一个map管道数组来代替，然后每次使用之前防止有空的已有的消息，每次先清空。因为这个管道会有读写的情况，索引了一把锁来同步互斥。然后每次处理完OP如果发现日志太大就保存一下快照。 这里有一个关键点是对于重复的命令如何去重，去重采用的是应用到raft日志之后，达成一致性之后，如果没重复就写入到kvstorage中，如果重复了那么就跳过。 如果知道是不是重复的命令呢，要在kv中保存clientId到SeqNumId的一个map，SeqNumId记录的是已经执行的最大的命令号。小于等于的视为重复。一开始seqnum初始化为0.然后递增。 RPC这里的RPC主要是get，put，append的RPC请求，比较简单，每次收到先执行raft的start函数，如果不是leader，直接返回结果，如果是，等待来自reschan的消息，如果消息超时，也返回对应的结果，如果没超时并且返回的Op和我们执行的一致就返回ok的结果。 如何加锁对于整体的函数，每次进入加一把大锁就行，然后对于reschan每次读的时候加锁，同时每次处理完OP如果发现日志太大（大于某个比例）就保存一下快照。 快照每次server启动就读取快照，每次收到来自raft状态机的消息，如果是快照类的，就读取快照。（读写快照时也需要加大锁） 每次server启动的时候都会读取快照信息，从persisit的snapshot中获取自己想要的内容，比如clisqe,kvdb,rf_commit_index等。 然后每次applyDB执行完都会查看日志大小是否大于某个某个值，如果是就保存clisqe,kvdb,rf_commit_index，存成snapshot 数据块保存到persisit中，然后执行raft的保存快照函数，然后将快照之前的日志删除。 我们注意到创建KVserver的时候会有最大的maxraftstate，如果这个时候保存的数据（persist的raftstate的内容）超过了maxraftstate，那么就建立快照。 我们知道在lab2中我们是调用persist函数将数据保存到persist的raftstate中，包括votefor，currenterm，Log。 如果这个太大了，我们需要建快照，调用raft.Savesnapshot()建立快照，保存kvdb，clientSeq等信息到snapshot中，这个时候可以丢弃已经已经提交的日志。 同时我们当收到raft状态机的snapshot命令的时候，就需要保存这些snapshot数据，复原数据。 lab4lab4是基于lab2实现的基于raft协议的分片的key-value存储，主要包括ctrler节点和分片的group的服务端，还有客户端。 Shard把所有数据按照Key Hash然后取模10,把数据切分成10片.每一片称为一个Shard, 其中包括一组键值对 ShardServer (Group)每个Group都是一个Raft集群, 通过Raft保证这组服务器上的数据一致性. 一组服务器负责几个Shard的读写请求.整个集群由N个Group组成 Client客户端, 发起读写请求. Shardctrler是集群中的协调者, 他负责调整Shard在集群间的分配, 以及集群路由的查询工作. 扩容: 新加入了一组服务器Group3, 需要将针对某个Shard的历史数据和后续的读写请求由Group1交给Group3负责以扩容集群. 缩容: 需要下线Group3, 需要将Group3负责的Shard历史数据和后续读写请求交给其他Group负责.扩缩容操作后需要保证Group间的负载均衡 路由查询: 假设Client 需要 Put(key:”name”, value: “L” ), “name”这个key存储在Shard1上. 需要Client根据从ShardMaster获取到的配置来确认向哪个Group发起写请求. Config由ShardCtrler维护, 客户端和ShardServer拉取的配置, 其中包括的所有服务器分组地址以及集群路由信息. 每次集群动作的变更都会引起Config Version的更新. 每个组的服务器的配置信息以及每个分片到组的对应关系，以及每个group包含的server，称为配置。配置都保存在服务器中，每次对配置进行修改操作，最新的配置会复制一份副本，然后修改，然后被追加到原本的配置集合中。同时配置号加一。 Recoverable快照和Raft中的状态要及时落盘,每一台服务器都要能够在故障后重启恢复 线性一致性需要能立刻读到之前完成的写请求(这个需要每次读请求向全体发起心跳，得到响应后发现自己仍然还是leader，或者使用租约) 负载均衡Shard在Group间的分布要尽可能均衡, 可以通过一致性哈希或者其他方法来实现 multiRaft我们使用 Raft 一致性算法来确保在机器发生故障时数据也能保持一致。在大多数使用 Raft 的系统中，如 etcd 和 Consul，整个系统只有一个 Raft 共识组。然而，在 CockroachDB 中，数据被分成不同的范围，每个范围都有自己的共识组。这意味着每个节点都可能参与成千上万个共识组。这就提出了一些独特的挑战，我们通过在 Raft 之上引入一层 MultiRaft 来解决这些问题。 简单来说，MultiRaft 是在整个系统中，把所管理的数据按照一定的方式切片，每一个切片的数据都有自己的副本，这些副本之间的数据使用 Raft 来保证数据的一致性，在全局来看整个系统中同时存在多个 Raft-Group单个 Raft-Group 在 KV 的场景下存在一些弊端: (1) 系统的存储容量受制于单机的存储容量（使用分布式存储除外）。 (2) 系统的性能受制于单机的性能（读写请求都由Leader节点处理）。 MultiRaft 需要解决的一些核心问题： (1) 数据何如分片。 (2) 分片中的数据越来越大，需要分裂产生更多的分片，组成更多 Raft-Group。 (3) 分片的调度，让负载在系统中更平均（分片副本的迁移，补全，Leader 切换等等）。 (4) 一个节点上，所有的 Raft-Group 复用链接（否则 Raft 副本之间两两建链，链接爆炸了）。 (5) 如何处理 stale 的请求（例如 Proposal 和 Apply 的时候，当前的副本不是 Leader、分裂了、被销毁了等等）。 (6) Snapshot 如何管理（限制Snapshot，避免带宽、CPU、IO资源被过度占用）。 lab4a(实现过程和lab3很像):Shard ctrler负责管理所有的组，决定每个组负责存储哪些分片，以及响应用户对组的增加（Join）、删除（Leave）、移动（Move）和查询（Query）操作。与Lab 3中实现的简易分布式Key-Value存储系统类似，Shard Ctrler同样分为服务器和客户端。其框架与Lab 3完全相同，区别仅在需要处理的请求的语义不同。Lab 3中需要处理Get、Put以及Append，本节则处理Join、Leave、Move和Query操作。 每个组的服务器配置信息以及分片到组的对应关系，称为配置（config）。历史上的所有配置均保留在服务器中，每次对配置进行修改操作（即Join、Leave以及Move操作）时，最新的配置会被复制一份，然后再进行修改，同时其序号（Num）增加一。用户可以通过Query查询最新配置，或历史上某一个特定配置。 shardctrler负责管理这些group，决定每个组存储哪些分片，响应用户对组的join（增加），删除（leave），移动（shard move）和查询（config query）。 这个客户的程序就是，对于已知的server，不断循环去遍历请求(query,move,join,leave)如果对方不是leader或者返回不对，就休息一段时间，选下一个机器，其中msgid是随机生成的，ckid也是随机生成的 RPC处理服务端收到来自客户端的RPC之后就交给下层的raft进行处理（这里要判断是不是leader），然后准备一个消息接受的管道，接受来自消息完成的通知，然后返回给客户端，如果超时就返回超时信息。（每次处理完要注意删除管道） 监听raft状态机提交的信息每次完成之后监听raft状态机的信息，这里要去重，然后和lab3的区别主要是Op的不同，主要分为leave，query，move，join，每次执行对应的函数 具体实现为： join操作，参数为一系列的组的配置信息，首先复制一个新的配置副本，然后新增配置号，然后将组的配置添加到配置副本中，然后进行重平衡算法。 Leave操作，参数是一些组的编号，首先复制一个新的配置副本，然后新增配置号，然后将配置中这些组删除，将属于这些组的分片暂时设置为0，然后进行重平衡算法。执行完该操作后，服务器要求至少剩余一个组。 move操作，参数是移动的分片和目标的组，首先复制一个新的配置副本，然后新增配置号，然后更新目标分片到目标组中，这个接口是为了调试和测试用的 query操作，查询任意时期的配置，没有指定的函数（query每次都是在底层的raft命令中发现这个命令之后就直接返回对应的config就可以） query可以查询最新的配置或者历史上某一个特定的配置。 重平衡算法在对配置进行修改后，每个组存储的分片数量可能会变得不均匀，因此需要进行重平衡。重平衡的目标是使得每个组存储的分片数量变得均匀（数量的最大值与最小值之差别太大），并且重新达到平衡的过程中被移动的分片的数量最少。 对于配置，如果只有一个group，肯定所有的shard都在这上面。 对于配置，如果只有0个group，此时什么都没有，shard也应该为空 如果shard的数目大于group的数目，那么求出每个group平均分配的最小数目，以及剩余的余数数目， 此时分四种情况讨论，如果group的shard和avg一样，continue， 如果group的shard大于avg，并且remain=0，将多于avg的shard的group置为0，小于的补上 如果group的shard大于avg，并且remain&gt;0，将多于avg+remain的shard的group置为0，如果group的shard小于avg，从group为0的那些shard选一些补到avg，如果还不足avg，还需要循环一次,因为此时的有可能其他分片还没有空出来这个最严重的情况下，会导致某一个group最大为avg+remain 如果shard_num&lt;group_num,那么就把多于一个shard的group的多的shard拿出来，shard还没选group的拿出来分别分配到一个都没有的group中。 这个重平衡算法的优点在于移动次数比较少，但是最坏情况可能最大最小差距为avg,reamin的shard都在一个机器上 这个重平衡算法还有可以优化的地方， 还有一种平衡机制是这样的，这种会更平衡一些， 对于一个配置，重平衡算法首先通过分片到组的对应关系计算出每个组存储的分片的列表，然后将这些组按照其存储的分片数量从大到小排序。为了确保Shard Master所有服务器执行相同的操作，当某两个组的分片数量一致时，编号更小的组排在更前。排序后，算法计算每个组平衡后应当存储的分片数量。假设共有ngroups个组，nshards个分片，那么前nshards % ngroups个组存储nshards / ngroups + 1个分片，剩下的组存储nshards / ngroups个分片。接着算法遍历每个组，将分片数量多于预期的组的多余分片取出并统一暂存。最后，算法遍历每个组，将暂存的多余分片分配至分片数量少于预期的组。算法总计需要一次对组的排序、两次对组的遍历以及其中的分片复制操作，总体时间复杂度为O(ngroups * log(ngroups) + nshards)。 运行的流程：当客户端发起group的加入，离开，移动，或者查询任意配置的时候，server执行join（例如）函数，然后执行runcmd函数（在这里将加入reqId，随机值）然后执行waitcmd函数，交给底层的raft提交日志，如果非leader，或者超时，返回，如果没有这些问题，就等待收到的回复，这个回复是这样的流程（当server收到raft的信息的时候，同时处理完相关的函数，然后向msgnotify返回信息），当收到返回的msgnotify信息的时候，删除通道的数据，返回rpc对应的结果 即服务端两个线，一条是RPC接收到客户端信息的时候，交给底层的raft日志处理不断监听结果，同时一方面，一个apply不断从raft applymsg信息中查看是否达成一致性，是就进行处理返回msgnotify结果信息。实现总体架构和lab3类似，分为客户端和服务端，每次客户端向服务端发送请求，如果不是leader就换server重试，然后道）。同时客户端还有一个 lab4b：lab4b的challenge背景: Group1 在 V1 负责 Shard0, Shard1 的读写, 但是在 V2 后 Shard0 由 Group2 负责读写请求, 需要Group1 将Shard0 的历史数据安全的发送给Group2.所有时间必须保持线性一致性. 需要进行针对Shard的Garbage Collection, Group1在迁移Shard0 结束后及时的清理掉Shard0以释放空间. Group1 在升级到 V2后, 仍负责Shard1的读写请求, 所以迁移Shard0的过程不能影响Shard1的读写请求 一开始客户端尝试旧的group，如果收到wrongGroup回复，那么就查询新配置，再查询。服务器中如果这个shard是自己管理的，同时需要这个shardversion和本地的配置号是一样的，因为如果不一样说明肯定正在传输，这个时候返回InTransit错误， 一些设计思想：本节的核心设计思想为，服务器存储的分片可以分为实际存储数据的分片和不实际存储数据的分片引用(即正在传输)。分片引用存储该分片实际数据的来源（配置序号以及分片编号），表示服务器正在等待其他组的服务器将此分片迁移至当前服务器。这一设计允许服务器将配置更新与分片迁移操作分离，配置更新时仅需快速更新分片引用，而分片数据则可以后续独立传送。一旦某一分片数据传送（迁移）完成，服务器可立即开始处理对该分片的请求，而无需等待其他正在传送的分片数据（对应TestChallenge2Unaffected及TestChallenge2Partial）。 在实际的生产系统中，不同 raft 组的成员可能存在于一个物理节点上，而且一般情况下都是一个物理节点拥有一个状态机(一批数据)，不同 raft 组使用不同地命名空间或前缀来操作同一个状态机。系统的运行方式：一开始系统会创建一个 shardctrler 组来负责配置更新，分片分配等任务，接着系统会创建多个 raft 组来承载所有分片的读写任务。此外，raft 组增删，节点宕机，节点重启，网络分区等各种情况都可能会出现。 对于集群内部，我们需要保证所有分片能够较为均匀的分配在所有 raft 组上，还需要能够支持动态迁移和容错。 对于集群外部，我们需要向用户保证整个集群表现的像一个永远不会挂的单节点 KV 服务一样，即具有线性一致性。 所有涉及修改集群分片状态的操作都应该通过 raft 日志的方式去提交，这样才可以保证同一 raft 组内的所有分片数据和状态一致。 数据迁移的实现为 pull 还是 push？这里实现成了 pull 的方式。 在 6.824 的框架下，涉及状态的操作都需要 leader 去执行才能保持正确性，否则需要添加一些额外的同步措施，而这显然不是 6.824 所推荐的。因此配置更新，分片迁移，分片清理和空日志检测等逻辑都只能由 leader 去检测并执行。 首先，每个 raft 组的 leader 需要有一个协程去向 shardctrler 定时拉取最新配置，一旦拉取到就需要提交到该 raft 组中以更新配置。此外，为了防止集群的分片状态被覆盖，从而使得某些任务永远被丢弃，因此一旦存在某一分片的状态不是默认状态，配置更新协程就会停止获取和提交新配置直至所有分片的状态都为默认状态为止。 客户端：与lab3类似，客户端的seqNum初始化为0，然后每次递增，保证命令号不重复，put 或者append或者get 每次请求，对于每个key，获取它所处的shard，对于shard的第一个字符转成正整数然后对分片的个数取模得到shard号码，然后从config中找到负责这个shard的group，对其的每个server，进行请求， 如果成功，或者没有这个key，返回reply，如果group错误或者正在传输中，退出对这个group的请求，过一会再次查配置对group上的server进行请求。 同时每隔一段时间向ctrler节点查询最新配置 RPC请求PullShard:如果对方想拉shard，同时我的配置号比他的更新，就把shard给他，否则返回false DeleteShard：如果我的对应的shard的配置号比RPC参数发过来的配置号更旧，说明确实可以删除，那么就向底层的raft写入同步删除shard的命令DeleteShardOp，（需要判断是否为leader），并且等待reschan对应命令的管道信息，如果不是正在传输的状态，reply的结果那么就为success，超时或者其他情况返回reply false get:应对客户端发起的get请求，先交给底层的raft进行处理，然后等待reschan通道结果，这里的实现和lab3和lab4a的实现基本一样，主要区别在于返回的错误种类更多，可能是正在传输，可能是group错误。 PutAppend应对客户端发起的putappend请求，先交给底层的raft进行处理，然后等待reschan通道结果， PullConfig协程服务端自己每隔一定时间会发起拉取配置的请求（pollconfig），如果发现有新配置（注意每次只能更新更新一个版本的配置），说明我们应该更新配置了，同时这个时候还需要检查上一个版本的配置有没有更新好，比如说需要拉取的shard有没有拉过来，需要删除的有没有删除，pullmap有没有删除掉。有的话就暂时不更新配置。（如果有原来的配置号和之前属于这个group的shard的配置号不一样，这个说明上一个版本还没更新好，比如说正在更新配置，又有一个更新的配置了，如果只有pullmap的约束，那么就可以继续更新，但是实际上配置还没更新好）否则就向raft写入日志进行同步，表明大家可以更新日志了。 pullshard协程服务端每隔一段时间会处理拉取shard的命令（pollshard）（处理pullmap），然后如果发现pullmap的valid是true（需要拉取shard）发起pullshard RPC，如果拉取成功，就向raft写入日志大家可以更新shard了。 如果pullmap是false，说明需要删除，这个时候就发起删除shard的RPC请求（告诉对方的group，老哥你的group可以删除了），删除了之后，就向raft写删除pullmap，表示大家可以删除pullmap了。 G2GPullShardRPC当有一个group的兄弟给我们说，想要shard，如果他的配置版本和我一样，那么可以给他shard，如果比我的旧也可以给他（这个对应我同时失去了两个分片，但是没有需要更新的，所以配置可以更新，也不需要拉取，这个时候应该给他shard）（比我的新暂时不能给，因为可能这边还没更新配置，shard配置号和group配置号是一致的，需要先更新配置再给） G2GDeleteShardRPC当一个老哥告诉我们让我们删除我的shard，如果我的这个shard的版本号小于这个老哥的版本号（小于的情况对应的是可能我这边更新了两个版本，假设都失去了一个shard，那么这个时候对方还是上个版本，应该给他这个shard，但是如果大于等于是不可能的，因为如果需要配置号大，肯定是进行了原来就一直在，或者从别人那里拉取了，但是这个老哥还没拿到根本拉不了），那么就像raft表示大家一起删除这个shard。 applyDb协程一个不断获取底层raft的状态机的信息，如果为快照的命令，那么就读取快照信息如果不是那么就看日志的command是哪种命令， ShardConfigOp这个时候说明我们已经拿到新配置了，然后这个时候也表明在raft group中完成共识了，这个时候就具体更新配置，（注意需要新配置号大于现在的配置号，表示去重）如果原来就是这个group的shard就只更新shard配置号，原来不是这个group的shard但是现在是的，就添加需要pullmap的信息，后续进行拉取。如果原来是，但是现在不是的了，这个先不管，其他group会过来进行拉取。同时正式更新这个group的配置号。 PullShardOp命令（PullShardOp这里必须要求op.ver是当前配置号减一，这里保证的是我只能拿上一个版本的那个版本的，如果是上上上版本的，可能是它之前没删除，同时还没拉取得，这个时候不能拿，要等他更新好才能拿，同时这里还有一个原因是raft虽然写入是有顺序的，但是返回的时候可能是乱的，可能配置已经更新到9，但是只返回配置6的数据，所以这个时候不能重复更新，不然可能会覆盖之前的内容） 这个时候说明我们已经拿到shard了，然后这个时候也表明在raft group中完成共识了，这个时候就是具体更新内容的时候了，更新了对应shard的kvdb即（存储信息），以及clientseqNum（就是某个客户的最大的命令号）,并且将kv.pullMap的valid设置为false（表明已经拉取好了shard）（因为这里就是说组把一个shard交给了另外一个组，所以需要删除），同时更新对应分片的shardsVerNum DeleteShardOp这个时候说明可以删除，这个时候也表明在raft group中完成共识了，这个时候就是具体删除内容的时候了，如果是删除shard的命令DeleteShardOp，这里把我们需要删除的shard的版本号记为A，那个请求我们删除shard的group的版本号记为B，如果A小于等于B（小于是很容易理解的，因为我这边的shard没更新，所以是上个版本的版本号，但是等于是？？），那么可以进行删除，同时清楚kvdbs和clientSeq，刷新管道，向结果中写入没有在传输的标志，如果A大于B，那么就刷新结果管道（把管道的结果清除掉），向管道写入正在传输的标志。 RemovePullMapOp如果是删除pullmap的命令RemovePullMapOp，那么就删除对应的pullmap get,put,append 在执行Get、Put以及Append时，服务器会首先检查请求的Key对应的分片在当前配置下是否由本服务器负责，若不由本服务器负责，则直接返回组错误响应。若确实由本服务器负责，则若shard的版本号与kv的配置号不一样，可能还没拉到返回正在传输，如果一致，在对应的数据库中更新，返回reschan结果。 思路详解定时拉取配置，整体的过程是pollConfig会定时调用写raft命令，然后再applyDb中达成一致后具体应用 定时拉取shard的会定时检查pullmap需要拉取的，如果需要就调用pullshardRPC，然后写入拉取shard的命令 如果pullmap拉取完了说明对方需要删除，那么就调用deleteShardRPC，在对应raft写入删除shard的命令 如果deleteshardRPC删除成功需要写入删除pullmap的命令 apply针对达成一致性的命令进行处理，这里处理的时候需要注意去重，以及修改pullmap，以及可能正在传输。 发现有新配置（每次配置号加一查新配置），必须保证上次的配置更新好才能更新下次的（即pullmap为空） PullShardRPC中只需要config号更大或者一样，就可以把shard给对方，同时还要给shardVersion号，而且在raft达成一致性之后需要check这个shardversion是否刚好为当前的config号减一， deleteShardRPC需要本地的shardversion号小于等于对方的config号 并且raft达成一致性之后需要shard的config号小于等于执行op的配置号（对方的请求RPC的配置号） 这里当配置是旧配置的时候一定是访问到的之前的group，此时如果配置更新了，说明正在传输配置给新group，或者要删除这个shard，这个时候这个shard的服务就暂停了，让客户端更新一下配置。然后访问新的group，如果我还是旧配置是可以提供服务的。 正在传输的情况有哪几种？Get、put、append中有可能，只要配置号不一样不是默认的情况就是正在传输 challenge的服务1.当副本组失去碎片的所有权时，该副本组应消除其数据库中丢失的键。它是浪费的，以保持它不再拥有的价值，不再为请求提供服务。但是，这会给迁移带来一些问题。假设我们有两个组，G1和G2，并且有一个新的配置C，它将Shard S从G1移动到G2。如果G1从其数据库中擦除S中的所有键，当它转换为C时，G2如何在尝试移动到C时获得数据？ 这个使用deleteshard 和deletepullmap来提供，当pullshard完成之后，会标记pullmap迁移完成，发现迁移完成接收者会发起deleteshardRPC请求，使其删除这个shard，当删除shardRPC完成之后就写入deletepullmap的操作，达成一致性后删除pullmap。 2.当配置迁移的时候，不是迁移的分片应该可以提供服务。 在迁移配置的时候，即使配置更新正在迁移，但是旧的shard的的group是可以提供服务的，这里我们可以看如果这个时候都是旧的配置，那么说明还没更新配置，那么shardversion和config号是一样的，如果更新了配置，那么都是新配置，也都是一致的，是可以提供服务的。 3.虽然上面的优化是好的，但我们仍然可以做得更好。例如，在转换到C时，一些副本组G3需要从G1的碎片S1，并且来自G2的碎片S2。我们真的希望G3立即开始在收到必要的状态后开始提供碎片，即使它仍在等待其他一些碎片。例如，如果G1关闭，G3仍应开始在从G2接收到G2的适当数据后为S2服务的请求，尽管过渡到尚未完成。 当收到一部分的分片的时候，客户端查询新的配置，发现shardversioon号和config号是一致的，都是新的号，可以提供服务。 加锁的情况规则 1：当您有多个 goroutine 使用的数据，并且至少有一个 goroutine 可能会修改数据时，goroutine 应该使用锁来防止同时使用数据。Go race 检测器非常擅长检测违反此规则的情况（尽管它对下面的任何规则都没有帮助）比如修改任期啥的 规则 2：每当代码对共享数据进行一系列修改时，如果其他 goroutine 查看 sequence 中间的某个数据，则可能会出现故障，您应该对整个 sequence 临界区使用锁。 规则 3：每当代码执行一系列共享数据读取（或读写）时，如果另一个 goroutine 在该 sequence 中途修改数据了，则会出现故障，您应该在整个 sequence 使用锁。 规则 4：在执行任何可能等待的操作时保持锁定通常不是一个好主意：读取 channel、发送 channel、等待 timer、调用 time.sleep () 或发送 RPC (并等待回复)。其中一个原因是，可能希望其他 goroutine 在等待期间能够继续执行代码。另一个原因是避免死锁。设想两个 peer 在持有锁的同时相互发送 RPC；两个 RPC 处理程序都需要接收 peer 的锁；两个 RPC 处理程序都无法完成，因为它需要等待的 RPC 调用持有的锁。 为什么需要分片 Lab2和Lab3构成基础分布式数据库的框架，实现多节点间的数据一致性，支持增删查改，数据同步和快照保存。然而，在实际应用中，当数据增长到一定程度时，若仍然使用单一集群服务所有数据，将会造成大量访问挤压到leader上，增加集群压力，延长请求响应时间。这是由于lab2和lab3所构成的分布式数据库的核心在于分布式缓存数据，确保在leader宕机后，集群仍然可用，并没有考虑集群负载问题，每时每刻，所有数据请求都集中在一台机器上，显而易见的，在数据访问高峰期，请求队列将会无比漫长，客户等待时间也会变长。一个非常直接的解决方法，就是将数据按照某种方式分开存储到不同的集群上，将不同的请求引流到不同的集群，降低单一集群的压力，提供更为高效、更为健壮的服务。Lab4就是要实现分库分表，将不同的数据划分到不同的集群上，保证相应数据请求引流到对应的集群。这里，将互不相交并且合力组成完整数据库的每一个数据库子集称为shard。在同一阶段中，shard与集群的对应关系称为配置，随着时间的推移，新集群的加入或者现有集群的离去，shard需要在不同集群之中进行迁移，如何处理好配置更新时shard的移动，是lab4的主要挑战。 一是提升服务器的性能，将请求分散到多个group，充分利用多机的计算能力可网络带宽，有助于提高总体的服务能力。 二是提高了服务器的数据存储能力。存储的横向扩展，即使Redis的服务能力能够满足应用需求，但是随着存储数据的增加，单台机器受限于机器本身的存储容量，将数据分散到多台机器上存储使得保存的数据可以变多。 其他优点： 增加可用性：如果数据库的某些group出现了故障，在其他节点的数据仍旧可用 维护方便：如果数据库的某个group出现故障，需要修复数据，只需要修复该group 均衡IO：可以将不同的请求映射到各节点以平衡IO，改善整个系统的性能 改善查询性能：对分区对象的查询可以仅搜索自己关心的节点，提高检索速度 分布式存储首先要解决把整个数据集按分区规则映射到多个节点的问题，即把数据集划分到多个group，每个group负责整体数据的一个shard： 分片可以让系统管理更大的内存，系统将可以使用所有机器的内存。如果没有分片，你最多只能使用一台机器的内存。 分片使系统的计算能力通过简单地增加计算机得到成倍提升，系统的网络带宽也会随着计算机和网卡的增加而成倍增长。","path":"2022/04/06/分布式/6.824实验/"},{"title":"mit6.824 lab实现","text":"lab2首先是选举，raft必须保证大部分机器可用。 以下是一些raft的基础的内容，三种角色，leader，candidate，follower。 follower对于每个机器，一开始是follower，然后每隔一段时间如果没有收到Leader的心跳，那么任期+1，变为candidate，投票给自己，然后启动新的协程发起选举（如果在这过程中任期被改变或者role被改变（？？需不需要变为leader），那么选举结束），向其他的机器发送RPC，请求它们投票。 如果收到的reply的任期比我更大，那么转变为follower，更新任期。（需要保存磁盘） 如果收到投票给我的结果，并且我还是candidate，那么直接票数+1，超过半数的票，变为leader，并且初始化nextIndex为最后一条日志的索引值+1（代表下一条需要复制给server的日志索引，索引0代表快照）（需要保存磁盘） requestVoteRPC实现如果当收到来自其他server的选举请求的时候，如果对方任期更旧直接拒绝投票。 如果任期更新，那么更新自己的任期，并且转变为follower。（需要保存磁盘） 如果我的日志更新（比较日志任期和索引）那么也拒绝投票。 如果我的日志没有更新，同时我还没投票或者已经投了它（说明之前返回的RPC丢失了），那么投票给他，更新任期，刷新心跳（保存磁盘） 否则（说明已经投了别人），拒绝投票。 leaderleader每隔一段时间sleep之后开始处理事务，查看nextIndex中的日志，如果index比leader快照的日志还旧，就发起InstallSnapshotRPC请求。 1.应对InstallSnapshotRPC请求的回复如果对方任期更新，那么更新任期，转为follower，然后（保存磁盘），否则更新nextIndex为快照的最后一条日志号+1. 1.1 InstallSnapshotRPC请求当收到来自leader 的安装快照RPC的时候，首先肯定检查任期，任期太旧直接拒绝然后回复，然后变为follower（防止此时为candidate）。如果我的快照比leader发来的快照更新，那么就直接返回，不需要安装。否则，把对应的leader发来的快照以及我比leader快照更新的信息，打包到一起变为server的log，然后应用leader快照到状态机，然后更新commitIndex,快照数据（保存到磁盘）。 2.应对AppendEntriesRPC请求的回复否则就发送日志和心跳，这个时候要把从nextIndex到自己日志的最后一条日志复制给对方，然后附加自己，commitIndex（已经提交的索引号），之前已经已经发送的最后一条日志的索引和任期，以及自己的任期。发起AppendEntriesRPC请求 如果收到AppendEntriesRPC回复，如果对方拒绝，如果是因为对方的任期更新，那么更新任期，变为follower（需要保存磁盘），如果是因为日志号冲突了，那么更新自己的nextIndex（需要保存磁盘），然后返回。 如果复制的日志太老了早就复制过了，那么直接返回 如果没有，那么更新nextindex，matchIndex(每个服务器已经复制的最高索引), （检查已经提交的日志索引如果大于等于已经复制到其他的服务器的索引，直接返回（这个时候说明已经提交了，后面再做没有必要）） （检查fig8的情况，如果复制的日志的任期和当前的任期不一致，那么不能提交，直接返回（后面也没必要了）） 对于每个server，如果已经复制的日志索引（matchIndex）已经大于想要提交的日志索引,那么计数值+1，如果超过半数，那么就直接提交，应用到状态机，更新已经提交的索引号（需要保存磁盘）。 2.1AppendEntriesRPC请求首先肯定检查任期，如果leader的任期太旧，直接拒绝。否则，先转变为follower，更新任期，刷新心跳。 如果leader已经发送的最后一条日志索引比server的快照的最后一条还旧，说明发来的日志有一部分是重复的，直接返回。 如果leader已经发送的最后一条日志记录和server的冲突了，同时leader的lastcopyindex大于快照日志索引小于server最大的日志索引直接回退到这个任期的第一条日志（说明下一次leader从这个任期的第一条开始发）。如果同时leader的lastcopyindex大于server最大的日志索引，那么直接返回快照的最大索引+1。然后返回结果。 前面保证了lastcopyIndex在lastSnapshotIndex与lastLogIndex之间，然后追加日志（如果追加的日志比lastLogIndex小就不用追加）。 从那么从server发过来的commitIndex到leader的commitindex，应用到状态机。 Go 语言在这里的特性，Goroutine这个的用法在于比如说一开始每次机器都会有两个协程不断循环检查自己是follower，以及是leader的情况 follower：当发现leader给自己的心跳超时的时候，就开启协程开始选举，在这个协程开启n个协程来请求其他的机器给自己投票，每个请求投票的协程依据情况处理。 leader：每次经过一定的时间，对于每一个follower的机器，发现follower的机器太旧的时候，就启动一个发送快照的协程来处理，否则启动一个发送心跳和日志的协程来处理。 lab3Gob的小问题Gob这个包序列化数据的时候，需要知道具体的类型，才可以将它正确的反序列化回来。我们在Start()中传入的参数是interface{}类型，所以如果不进行一些预先的安排，那么在follower中不能将OpArgs反序列出来。所以在StartKVServer()中需要调用gob.Register来注册一下 只有leader可以处理客户端的请求，如果其他角色接收到了请求，会重定向到leader。 lab4Shard把所有数据按照Key Hash然后取模10,把数据切分成10片.每一片称为一个Shard, 其中包括一组键值对 ShardServer (Group)每个Group都是一个Raft集群, 通过Raft保证这组服务器上的数据一致性. 一组服务器负责几个Shard的读写请求.整个集群由N个Group组成 Client客户端, 发起读写请求. Shardctrler是集群中的协调者, 他负责调整Shard在集群间的分配, 以及集群路由的查询工作. 扩容: 新加入了一组服务器Group3, 需要将针对某个Shard的历史数据和后续的读写请求由Group1交给Group3负责以扩容集群. 缩容: 需要下线Group3, 需要将Group3负责的Shard历史数据和后续读写请求交给其他Group负责.扩缩容操作后需要保证Group间的负载均衡 路由查询: 假设Client 需要 Put(key:”name”, value: “L” ), “name”这个key存储在Shard1上. 需要Client根据从ShardMaster获取到的配置来确认向哪个Group发起写请求. Config由ShardMaster维护, 客户端和ShardServer拉取的配置, 其中包括的所有服务器分组地址以及集群路由信息. 每次集群动作的变更都会引起Config Version的更新. Recoverable快照和Raft中的状态要及时落盘,每一台服务器都要能够在故障后重启恢复 线性一致性需要能立刻读到之前完成的写请求(这个需要每次读请求向全体发起心跳，得到响应后发现自己仍然还是leader，或者使用租约) 负载均衡Shard在Group间的分布要尽可能均衡, 可以通过一致性哈希或者其他方法来实现 multiRaft我们使用 Raft 一致性算法来确保在机器发生故障时数据也能保持一致。在大多数使用 Raft 的系统中，如 etcd 和 Consul，整个系统只有一个 Raft 共识组。然而，在 CockroachDB 中，数据被分成不同的范围，每个范围都有自己的共识组。这意味着每个节点都可能参与成千上万个共识组。这就提出了一些独特的挑战，我们通过在 Raft 之上引入一层 MultiRaft 来解决这些问题。 简单来说，MultiRaft 是在整个系统中，把所管理的数据按照一定的方式切片，每一个切片的数据都有自己的副本，这些副本之间的数据使用 Raft 来保证数据的一致性，在全局来看整个系统中同时存在多个 Raft-Group单个 Raft-Group 在 KV 的场景下存在一些弊端: (1) 系统的存储容量受制于单机的存储容量（使用分布式存储除外）。 (2) 系统的性能受制于单机的性能（读写请求都由Leader节点处理）。 MultiRaft 需要解决的一些核心问题： (1) 数据何如分片。 (2) 分片中的数据越来越大，需要分裂产生更多的分片，组成更多 Raft-Group。 (3) 分片的调度，让负载在系统中更平均（分片副本的迁移，补全，Leader 切换等等）。 (4) 一个节点上，所有的 Raft-Group 复用链接（否则 Raft 副本之间两两建链，链接爆炸了）。 (5) 如何处理 stale 的请求（例如 Proposal 和 Apply 的时候，当前的副本不是 Leader、分裂了、被销毁了等等）。 (6) Snapshot 如何管理（限制Snapshot，避免带宽、CPU、IO资源被过度占用）。 Lab 4A and 4b(ShardCtrler)Shard Master负责管理所有的组，决定每个组负责存储哪些分片，以及响应用户对组的增加（Join）、删除（Leave）、移动（Move）和查询（Query）操作。与Lab 3中实现的简易分布式Key-Value存储系统类似，Shard Master同样分为服务器和客户端。其框架与Lab 3完全相同，区别仅在需要处理的请求的语义不同。Lab 3中需要处理Get、Put以及Append，本节则处理Join、Leave、Move和Query操作。 每个组的服务器配置信息以及分片到组的对应关系，称为配置（config）。历史上的所有配置均保留在服务器中，每次对配置进行修改操作（即Join、Leave以及Move操作）时，最新的配置会被复制一份，然后再进行修改，同时其序号（Num）增加一。用户可以通过Query查询最新配置，或历史上某一个特定配置。上述修改操作具体实现为： 在实际的生产系统中，不同 raft 组的成员可能存在于一个物理节点上，而且一般情况下都是一个物理节点拥有一个状态机，不同 raft 组使用不同地命名空间或前缀来操作同一个状态机。系统的运行方式：一开始系统会创建一个 shardctrler 组来负责配置更新，分片分配等任务，接着系统会创建多个 raft 组来承载所有分片的读写任务。此外，raft 组增删，节点宕机，节点重启，网络分区等各种情况都可能会出现。 对于集群内部，我们需要保证所有分片能够较为均匀的分配在所有 raft 组上，还需要能够支持动态迁移和容错。 对于集群外部，我们需要向用户保证整个集群表现的像一个永远不会挂的单节点 KV 服务一样，即具有线性一致性。 所有涉及修改集群分片状态的操作都应该通过 raft 日志的方式去提交，这样才可以保证同一 raft 组内的所有分片数据和状态一致。在 6.824 的框架下，涉及状态的操作都需要 leader 去执行才能保持正确性，否则需要添加一些额外的同步措施，而这显然不是 6.824 所推荐的。因此配置更新，分片迁移，分片清理和空日志检测等逻辑都只能由 leader 去检测并执行。数据迁移的实现为 pull 还是 push？其实都可以，个人感觉难度差不多，这里实现成了 pull 的方式。 首先，每个 raft 组的 leader 需要有一个协程去向 shardctrler 定时拉取最新配置，一旦拉取到就需要提交到该 raft 组中以更新配置。此外，为了防止集群的分片状态被覆盖，从而使得某些任务永远被丢弃，因此一旦存在某一分片的状态不是默认状态，配置更新协程就会停止获取和提交新配置直至所有分片的状态都为默认状态为止。 lab4是基于lab2实现的基于raft协议的分片的key-value存储，主要包括ctrler节点和分片的group的服务端，还有客户端。 lab4a:shardctrler负责管理这些group，决定每个组存储哪些分片，响应用户对组的join（增加），删除（leave），移动（shard move）和查询（config query）。 实现总体架构和lab3类似，分为客户端和服务端，然后服务端对底层的raft完成一致性的命令进行处理，客户端每次不断请求服务。 每个组的服务器的配置信息以及每个分片到组的对应关系，以及每个group包含的server，称为配置。配置都保存在服务器中，每次对配置进行修改操作，最新的配置会复制一份副本，然后修改，然后被追加到原本的配置集合中。同时配置号加一。 query可以查询最新的配置或者历史上某一个特定的配置。 具体实现为： join操作，参数为一系列的组的配置信息，首先复制一个新的配置副本，然后新增配置号，然后将组的配置添加到配置副本中，然后进行重平衡算法。 Leave操作，参数是一些组的编号，首先复制一个新的配置副本，然后新增配置号，然后将配置中这些组删除，将属于这些组的分片暂时设置为0，然后进行重平衡算法。执行完该操作后，服务器要求至少剩余一个组。 move操作，参数是移动的分片和目标的组，首先复制一个新的配置副本，然后新增配置号，然后更新目标分片到目标组中，这个接口是为了调试和测试用的 query操作，查询任意时期的配置，没有指定的函数（query每次都是在底层的raft命令中发现这个命令之后就直接返回对应的config就可以） 重平衡算法在对配置进行修改后，每个组存储的分片数量可能会变得不均匀，因此需要进行重平衡。重平衡的目标是使得每个组存储的分片数量变得均匀（数量的最大值与最小值之差别太大），并且重新达到平衡的过程中被移动的分片的数量最少。 对于配置，如果只有一个group，肯定所有的shard都在这上面。 对于配置，如果只有0个group，此时什么都没有，shard也应该为空 如果shard的数目大于group的数目，那么求出每个group平均分配的最小数目，以及剩余的余数数目， 此时分四种情况讨论，如果group的shard和avg一样，continue， 如果group的shard大于avg，并且remain=0，将多于avg的shard的group置为0， 如果group的shard大于avg，并且remain&gt;0，将多于avg+remain的shard的group置为0，如果group的shard小于avg，从group为0的那些shard选一些补到avg，如果还不足avg，还需要循环一次,因为此时的有可能其他分片还没有空出来这个最严重的情况下，会导致某一个group最大为avg+remain 如果shard_num&lt;group_num,那么就把多于一个shard的group的多的shard拿出来，shard还没选group的拿出来分别分配到一个都没有的group中。 这个重平衡算法的优点在于移动次数比较少，但是最坏情况可能最大最小差距为avg,reamin的shard都在一个机器上 这个重平衡算法还有可以优化的地方， 还有一种平衡机制是这样的，这种会更平衡一些， 对于一个配置，重平衡算法首先通过分片到组的对应关系计算出每个组存储的分片的列表，然后将这些组按照其存储的分片数量从大到小排序。为了确保Shard Master所有服务器执行相同的操作，当某两个组的分片数量一致时，编号更小的组排在更前。排序后，算法计算每个组平衡后应当存储的分片数量。假设共有ngroups个组，nshards个分片，那么前nshards % ngroups个组存储nshards / ngroups + 1个分片，剩下的组存储nshards / ngroups个分片。接着算法遍历每个组，将分片数量多于预期的组的多余分片取出并统一暂存。最后，算法遍历每个组，将暂存的多余分片分配至分片数量少于预期的组。算法总计需要一次对组的排序、两次对组的遍历以及其中的分片复制操作，总体时间复杂度为O(ngroups * log(ngroups) + nshards)。 server相关的实现：对于每个server一开始初始化每个元素，然后启动apply协程，这个协程中，不断接收来自raft的状态机管道信息，如果信息中的msg非快照类的，同时这个请求没有重复，没重复就执行join函数，leave函数，move函数，query函数，（这四个函数就相当于上述的操作）同时向msgnotify写入管道信息 4个RPC函数：这四个最后都是执行waitcmd函数，对于每个命令执行在底层的raft中添加命令，然后等待msgnotify结果根据是否是leader，是否超时，返回对应的msgnotify 客户端： 这个客户的程序就是，对于已知的server，不断循环去遍历请求(query,move,join,leave)如果对方不是leader或者返回不对，就休息一段时间，选下一个机器，其中msgid是随机生成的，ckid也是随机生成的 运行的流程： 当客户端发起group的加入，离开，移动，或者查询任意配置的时候，server执行join（例如）函数，然后执行runcmd函数（在这里将加入reqId，随机值）然后执行waitcmd函数，交给底层的raft提交日志，如果非leader，或者超时，返回，如果没有这些问题，就等待收到的回复，这个回复是这样的流程（当server收到raft的信息的时候，同时处理完相关的函数，然后向msgnotify返回信息），当收到返回的msgnotify信息的时候，删除通道的数据，返回rpc对应的结果 即服务端两个线，一条是RPC接收到客户端信息的时候，交给底层的raft日志处理不断监听结果，同时一方面，一个apply不断从raft applymsg信息中查看是否达成一致性，是就进行处理返回msgnotify结果信息。 lab4b： 客户端：put 或者append或者get 每次请求，对于每个key，获取它所处的shard，然后对负责这个shard的group上的每个server，进行请求， 如果成功，或者没有这个key，返回reply，如果group错误或者正在传输中直接退出这一次对这个group的请求，同时每隔一段时间向ctrler节点查询最新配置 server： 本节的核心设计思想为，服务器存储的分片可以分为实际存储数据的分片和不实际存储数据的分片引用。分片引用存储该分片实际数据的来源（配置序号以及分片编号），表示服务器正在等待其他组的服务器将此分片迁移至当前服务器。这一设计允许服务器将配置更新与分片迁移操作分离，配置更新时仅需快速更新分片引用，而分片数据则可以后续独立传送。一旦某一分片数据传送（迁移）完成，服务器可立即开始处理对该分片的请求，而无需等待其他正在传送的分片数据（对应TestChallenge2Unaffected及TestChallenge2Partial）。 一开始启动三个协程 applydb： 一个不断获取底层raft的状态机的信息，如果为快照的命令，那么就读取快照信息如果不是那么就看日志的command是哪种命令， 如果是更新配置的命令，如果原来就是这个group的shard就只更新shard配置号，原来不是这个group的shard的，就添加需要pullmap的信息，后续进行拉取 分片服务器在启动时会启动一个goroutine负责更新配置，其定期利用Shard Master客户端向Shard Master轮询最新的配置，并获取当前配置之后的所有新配置。然后，其调用Raft协议的Start接口来将分片组服务器当前配置之后的所有新配置逐一加入Raft日志（log）中。当这些日志（新配置）被Raft协议提交（commit）后，便会出现在applyCh。此时，分片组服务器会进行配置更新，配置更新一般会导致每个组负责的分片的情况发生变化， 如果是拉取shard的命令PullShardOp，实际上更新了对应shard的kvdb即（存储信息），以及clientseqNum,并且将kv.pullMap的valid设置为false（表明已经拉取了shard了），同时更新shardsVerNum 如果是删除shard的命令DeleteShardOp，如果请求我们删除的配置号不比我们旧，删除shard和clientseqnum，否则不删除（可能正在传输中），返回reschan结果 如果是删除pullmap的命令RemovePullMapOp，那么就删除对应的pullmap 如果是get，put，append命令，若shard的版本号与kv的配置号不一样，说明正在传输，返回正在传输的结果，如果一致，在对应的数据库中更新，返回reschan结果 在执行Get、Put以及Append时，服务器会首先检查请求的Key对应的分片在当前配置下是否由本服务器负责，若不由本服务器负责，则直接返回组错误响应。若确实由本服务器负责，则服务器继续按照规定的语义执行，并产生返回值。其中，若被访问的分片由本服务器负责但尚为引用，服务器不会阻塞，其会返回分片正在传输的响应，期望客户端一段时间后重试。 pollconfig: 每隔一段时间就向ctrler节点请求新的配置，如果请求到了新配置，同时如果不需要拉取shard，没有正在传输的config，就向raft添加ShardConfigOp更新配置的命令(表示更新config) pollshard: 每隔一段时间，就对pullmap中的还没拉取的shard进行拉取（此时pullmap valid为true），给出args参数，call RPC进行拉取shard，对于返回的reply，如果成功，向raft写入拉取shard的命令（同时要将给出的reply的参数放入命令中） 如果（此时pullmap valid为false），说明需要删除，给出args参数，call RPC进行deleteshard，对于返回的reply，如果成功，也向底层raft写入removePullmap(即删除pullmap)的命令 4个RPC函数： 对于kvdb相关的RPC: PullShard:如果对方想拉shard，同时我的配置号比他的更新，就把shard给他，否则返回false DeleteShard：如果我的对应的shard的配置号比RPC参数发过来的配置号更旧，说明确实可以删除，此时让底层的raft进行同步删除shard的命令DeleteShardOp，如果是leader，并且reschan对应命令的管道信息不是正在传输的状态，reply的结果那么就为success，超时或者其他情况返回reply false get:应对客户端发起的get请求，先交给底层的raft进行处理，然后等待reschan通道结果 PutAppend应对客户端发起的putappend请求，先交给底层的raft进行处理，然后等待reschan通道结果， 这里的流程主要为： （每一个kv还记录了每一个shard的版本配置号） 客户端发起get、put、append，然后服务端的Get，putappend的RPC函数收到后交给底层的raft提交，等待结果，applydbd等待到raft的提交结果之后，就进行kvdb的更新，然后返回结果，然后结束。（这里处理的时候可能会发现shard还在传输，会返回正在传输） 服务端自己每隔一定时间会发起拉取配置的请求（pollconfig），如果发现有新配置，那么就向底层raft写入更新配置的命令，applydbd等待到raft的提交结果之后，就对这个命令进行处理，原来就是这个group的shard现在还是的就只更新shard配置号，原来不是这个group的shard的，就添加需要pullmap的信息，后续进行拉取，原来是现在不是的暂时不删除 服务端每隔一段时间会处理拉取shard的命令（pollshard），然后如果发现pullmap的valid是true发起pullshard RPC，返回的reply如果成功，就向raft写入拉取shard的命令，applydbd等待到raft的提交结果之后（PullShardOp）（PullShardOp这里必须要求op.ver是当前配置号减一，为什么是这样呢，因为正常操作就是我们config更新了，然后配置号加一，然后拉取配置），更新信息，然后设置pullmap的valid是false（因为这里就是说组把一个shard交给了另外一个组，所以需要删除） 如果发现pullmap的valid是false发起deleteshard RPC，在deleteshardRPC中向底层raft写入DeleteShardOp，applydbd等待到raft的提交结果之后，处理结果然后返回（这里可能会发现这个shard已经被更新了，不是原来的shard就返回还在传输），如果返回的这个结果成功，那么再向底层的raft写入removePullmap命令，applydbd等待到raft的提交结果之后，返回结果然后返回。","path":"2022/04/05/分布式/mit6.824 lab实现/"},{"title":"effective C++笔记","text":"3.尽可能使用const当non-const和const实现相同逻辑时，non-const对象可以调用const成员函数，这样可以缩减代码量。另外注意const对象不能调用non-const成员函数，编译报错：discards qualifiers。 4.确定对象使用前被初始化&lt;!—hexoPostRenderEscape: 在构造函数的初始化列表中的才算是初始化，而构造函数的内容是在初始化列表之后执行的，已经不算是初始化操作。在初始化列表中进行初始化，调用的是string的拷贝构造函数，而在构造函数中进行赋值的话，调用的是：默认构造函数+赋值函数，调用默认构造的原因是，调用构造函数之前会先对成员进行初始化（这也就是为什么在构造函数中进行的操作不能称之为初始化操作），而对于大多数类，默认构造函数+赋值函数的效率是小于只调用拷贝构造函数的。 1.因此最好是在初始化列表中进行初始化操作。 2.内置类型要手动初始化，不同的平台不能保证对内置类型进行初始化&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 5.C++默认编写并调用的函数 编译器默认实现的函数：默认构造、析构、拷贝构造、赋值函数。 6.不想使用默认生成的函数，可以明确拒绝 默认的构造可以被其他构造替换，拷贝构造和赋值函数如果不想被外面调用可以将其声明为private。 8.别让异常逃离析构函数 绝不要让析构函数抛出异常，应该让用户自己处理可能发生异常的操作。这个应该说是提供给用户接口来close东西，如果用户没有这么做，可以在析构函数中try，catch. 9.不要在构造和析构函数调用virtual函数 由于父类的构造函数发生在子类之前，而此时子类的成员变量等并未初始化，因此在父类的构造函数中调用virtual函数，绝对不会调用子类的方法，即使现在你在创建一个子类对象。换句话说，在构造函数中调用的virtual函数，都会下降到父类类型，即都不是virtual函数，因为一进入析构函数，子类对象就不存在了，默认就是调用父类的函数。 10.令operator=返回reference to *this 并 11处理自我赋值 赋值操作返回*this的引用。在shardptr以及很多相关的类型都是这样的。返回引用比临时变量要少几次构造析构，效率高。 13.以对象管理资源 在构造中获得资源并在析构函数中释放资源（RAII） 14.在资源管理类中小心copy行为 在RAII对象中进行复制的时候，可能会导致出现双重释放。 这个解决办法有几种，一个是禁止对象赋值。一个是使用引用计数，最后一个释放的时候才真的释放资源，使用shard_ptr包装，或者使用深拷贝，资源复制一份，或者直接转移所有权，向auto_ptr一样。 条款 15：在资源管理类中提供对原始资源的访问 1. RAII 类应该提供访问其所管理的原始资源的方法，例如条款 14 中提到的 shared_ptr 中的 get 方法。 16.成对的使用new和delete 1 使用new申请内存，必须使用delete释放内存，使用new [] 申请内存，必须使用delete []释放内存 17以单独的语句将newed对象置入shared_ptr 1. 意思为不要写下类似Function(shared_ptr&lt;Class&gt;(new Class), x())，其中Function和x为函数，Class是一个类。原因在于shared_ptr的构造分为3，new class, 构建shard_ptr对象，然后调用fuction，这个顺序在编译器中是不确定的，如果是先new然后调用fuction， 构建shard_ptr对象，如果第二步出现异常，指针丢失，可能导致内存泄漏。 20.以pass-by-reference-const替换pass-by-value 主要考虑两点： 1效率问题，pass-by-value会导致很多临时对象的产生和销毁，就会多调用几次构造和析构，因此效率更低 2 对象切割问题，pass-by-value的方式将一个子类对象传入一个参数类型父类的函数，那么拷贝的对象将被切割成只有父类对象被保留，调用方法会调用父类的方法而不是子类。const引用可以解决这个问题，因为引用本质上也是指针，就和多态是一样的 另外，内置类型，STL迭代器和函数对象一般采用pass-by-value，因为其复制代价很小 21.不要返回临时对象的引用 不要返回一个临时对象的引用 不要返回在堆上分配的对象的引用，因为这违背了new和delete成对出现的原则，这样的方式是很不合理的，很容易导致内存泄漏。 也不要返回一个static对象的引用，因为static可能同时被很多地方需要，是存在于静态变量区的，比如重载*之后，a*b==c*d,永远都是true，因为他们都指向那一个位置。 所以对于这种问题，最好的解决方法就是不返回引用就OK了。 24.若所有参数皆需类型转换，那么请采用non-member函数 文中举了一个有理数Rational运算的例子，在类中加入一个operator*(const Rational&amp; other)的函数，可以实现类似 rational * 2的操作，其中2是个int，但是因为rational有一个以int为参数的构造，因此编译器帮你执行了隐式类型转换。但是反过来写2 * rational的时候，编译就报错了。因为2是个int，并没有operator*这个函数。但是为什么这样写就没有执行隐式类型转换呢？这又引出一个问题：隐士类型转换的合格条件是什么？答案是：必须是参数列中的参数才是隐士类型转换的有效参与者，类的执行者也就是&#x27;.&#x27;前面的那个对象（this指向的对象，比如说rational.func()中的rational是类执行者，相当于他是函数的调用人，地位较高，不能参与隐式类型转换），这就解释了为什么2放在前面是不行的。解决此种问题的方法是提供一个non-mem的operator*(Rational a, Rational b)即可。 25.写一个不抛出异常的swap函数（有点没看懂） 一般写swap最普通的方法就是利用中间变量，temp = a;a = b;b = temp，这种方法对于内置类型没任何问题，内置类型上的赋值绝对不会抛出异常，并且效率很高。但是如果a,b不是内置类型，就会调用类的copy构造函数和assign函数，并且必须是深拷贝。这样如果类的成员较多就会造成交换的效率很低，特别是针对pimpl实现方法，即成员中包含指针（即资源）时。更好的做法就是直接交换指针就可以了，相当于交换了两个int(指针都是4字节的)，这就比拷贝这个指针指向的资源要快得多。 如何实现呢？只要将swap都转换成内置类型的swap就可以了，做法就是在类中提供一个public的swap(T&amp; b)函数（T为一个类），将每个成员进行交换（如果成员中包含其他非内置对象，调用这个对象的swap函数即可）。然后提供一个non-member的swap(T&amp; a, T&amp; b)重载函数，在函数内部调用类中的a.swap(b)，就可以像如下方式实现交换两个对象的操作：swap(a, b)。 注意： 1在类内的swap交换内置类型时要调用std命名空间内的swap函数，必须使用using std::swap，否则就变成递归函数了 2另外文中说在std命名空间内不能加入新东西，比如重载swap函数，但是经博主测试是可以在std内重载swap函数的（g++版本为5.4.0）。 26.尽可能延后变量定义得时间 1因为变量（对类而言）的定义，需要承担一次构造函数的时间，在函数结束后还可能承担一次析构函数的时间，假如该变量未被使用，那么构造函数和析构函数的时间就白白浪费了，尤其是在可能发生异常的函数中，假如你过早的定义变量，然后在你使用这个变量之前抛出了异常，那么这个变量的构造函数就没有意义而且降低效率。所以应该尽可能延后变量定义得时间，只有真正使用这个变量的时候才定义它 2条款4讲过，copy construction的效率 &gt; default construction +assign function，所以最好的做法是直接调用copy construction函数对变量直接进行初始化，而不是先定义，再赋值 3对于有循环的情况，假设一个n次的循环，如图所示： 那么方法A的代价：1次构造+1次析构+n次赋值 方法B的代价：n次构造+n次析构 如果n较大，那么应该选择方法A，如果n较小，可以选择方法B。 27.尽量避免转型 1最好使用C++4个新式的类型转换函数，因为这很容易辨识，代码可读性提高 Static cast ：常规转换，可以将子类指针转换为父类指针，dynamic_cast 将父类指针转换为子类指针，reinterpret_cast 可以转指针成为一个int，const_cast 转const到非const类型 2尽量避免使用dynamic_cast，因为这种转换效率很低，一般用虚函数的方式来避免转型 28.避免返回一个指针、引用或者迭代器指向类内的成员 原因是如果返回了成员的引用或者指针，就可以通过这个引用或者指针修改雷内的private成员，这样是不合理的（这样的话成员就相当于public的了），这一点可以通过给函数的返回类型加const修饰符来防止内部成员变量被修改。但是还有一种情况是，如果获得的类内的一个成员的引用或指针，但是在使用之前，对象被释放了，那么这个引用或指针就变成了野指针了，必然会导致core dump错误。所以应该避免返回类内成员的指针或引用。 30.inline 函数 inline只是一种申请，编译器会根据具体情况来决定一个函数是否可以是inline得，比如递归函数、virtual函数、代码较多的函数，即使你声明了inline关键字，编译器也不会将此类函数视为inline的函数。 31.编译依存关系降低至最低&lt;!—hexoPostRenderEscape:理解此条款关键是要理解C++的编译方式，具体可以参考：https://www.cnblogs.com/jerry19880126/p/3551836.html文中说的很详细。理解了文中的意思，再回头看这个条款就清晰多了。其关键点如下： 1 关于前置声明的一个限制是：编译器必须在编译时确定类的大小，即分配多少内存。因此如果你前置声明一个类class TEST，然后在后面试图创建一个TEST的对象TEST test，那么这个代码是不会通过编译的，因为编译器不确定要给test分配多少内存。那怎么规避这个问题呢？答案就是指针，典型的pimpl方式，因为指针的字节数是固定的（相对于平台，一般就是4或者8字节）。例如下面的代码就是可以通过编译的。 include &lt;iostream&gt;using namespace std;class TEST;class AA&#123; public: TEST aa; //TEST&amp; b; //引用不可以，因为引用必须在初始化列表中进行初始化 void T(TEST&amp; tt) &#123; &#125; void wdt(TEST tt) &#123; &#125; void PP() &#123; cout &lt;&lt; &quot;AA::PP()&quot; &lt;&lt; endl; &#125; AA() &#123;&#125; ~AA() &#123;&#125;&#125;; int main() &#123; AA aa; aa.PP(); return 0;&#125; 可见，前置声明一个TEST类，并没有对应的类的实现，在另外一个类A中声明一个TEST的成员，包括在函数中使用TEST 或者 TEST&amp;类型的参数都没问题。但是在用这两个函数的时候还是要有TEST的定义和实现，那么这个时候怎么办，就是再创建一个TEST.h和TEST.cc，然后在A.cc中#Include&quot;TEST.H&quot;(假如class A也单独创建一个A.cc和A.h)，这样当TEST中的内容有所改变的时候，只有TEST.cc和A.cc被重新编译。所有使用class A和class TEST的地方都不会被重新编译。假如使用这两个类的地方特别多，那么这样就可以减少很多文件的编译了。 2. 上面利用指针是一种实现方法，另一种就是Interface class，即类中全部都是pure virtual函数，这样的类在使用的时候只能是以指针的形式出现，这样就同样达到了减少编译依赖的效果。 ③当然这两种方式都存在一定的代价：指针方式的实现要多分配指针大小的内存，每次访问都是间接访问。接口形式的实现方式要承担虚函数表的代价以及运行时的查找表的代价。但是一般这两种实现对资源和效率的影响通常不是最关键的，因此可以放心的使用，类似tensorflow源码中就大量使用这种方式降低编译依赖。&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 33.名称遮掩问题 子类会遮掩父类同名的函数，即使参数不一样也被遮掩了。可以使用类名作用域决定调用父类还是子类的函数,using base:: fun1; 34.接口继承与实现继承 理解接口继承和实现继承的区别，纯虚函数、非纯虚函数和普通函数在这两方面的区别：纯虚函数只指定接口继承、非纯虚函数指定接口继承并存在默认的实现继承、普通函数指定接口继承及强制实现继承。就是如果父类是普通函数非虚函数，那么是强制实现继承，子类的行为就和父类的一样，如果是纯虚函数说明只是一个接口，父类必须实现。如果是非纯虚函数，即virtual void fun()=0;然后在类外定义它，这样子类必须实现，同时父类还有默认的行为。 35.考虑virtual函数以外的选择、 可以将virtual函数变为private和protected的，然后用puclic的函数调用它，提供给他人。NVI方法。 可以将virtual函数替换为函数指针成员变量。Strategy设计模式。 36.不要重新定义继承来的non-virtual函数 non-virtual在实现上是静态绑定的，调用父类还是子类的函数完全取决于指针或者对象的类型，不管A指针指向的是A的对象还是B的对象，总是调用A的方法，B指针总是B类的方法。 37.不要重新定义重写函数（virtual）的默认参数 默认参数都是静态绑定的，即你的指针是什么类型，默认参数就是什么类型。而virtual函数是动态绑定的，在运行期才决定调用哪个函数。所以如果你在父类class Father有一个virtual函数并带有默认参数，例如void p(int default = 100)，在子类重写这个函数，然后换了新的默认参数为default = 10，在你以多态的方式调用p的时候：Father* f = new Son; f-&gt;p();这种情况p的默认参数为100而非10。因为f指针的静态类型为Father，而动态类型为Son。所以如果你的函数必须包含默认参数，不要这样写，解决方法是将带有默认参数的函数改为non-virtual函数，内部再调用一个virtual函数。因为non-virtual函数是从来不应该被重写的（条款36，覆盖问题） 39.私有继承 子类继承父类的方式决定了在子类中父类函数的属性，一般规则就是所有属性都按照继承方式对其。比如采用protected继承方式，那么父类中的public成员在子类都升级为protected，其他保持不变。如果采用private继承方式，父类中的所有成员全部变为private，特殊之处之一是父类中原本就是private的成员不可继承，即在子类中也无法使用父类的private成员。 40.多重继承 会导致歧义性，需要虚继承。 41.隐式接口和编译器多态 class的继承和template都支持接口和多态。只不过class实现的接口是显示的，就是说一定能直接找到这个接口的实现代码。而template实现的接口，只能模糊的知道接口的特征，一般间接能找到实现的代码。比如我们用template函数T w，w.size(),表明w必须实现size（）接口。用不同的参数具体化模板会导致调用不同的函数，就是编译器多态。用继承实现的多态属于运行期多态、模板实现的多态则是编译期多态。 42.了解typename 1. 在声明template参数时，class和typename可互换。 2. typename的第二个用处是告诉编译期某一个嵌套从属类型是类型，最典型的就是STL中容器的迭代器类型，例如：T::iterator(T是个容器的类型，例如：vector&lt;int&gt;)，这个时候就要在T::iterator前面加一个typename，告诉编译器这是一个类型，否则编译器不能确定这是什么，因为有可能iterator是个静态变量或者某一namespace下的变量。 ③类的继承列表和初始化列表中的类型不需要typename指定类型，因为继承的一定是个类，而初始化列表一定是调用父类的构造或者初始化某个成员。 43.调用基类模板成员 当一个类的基类包含模板参数时，需要通过this-&gt;的方式调用基类内的函数，例如 class F: public S&lt;C&gt;，在F中的成员函数中调用S中的成员函数this-&gt;test()，而直接写test()无法通过编译，原因是因为C是个模板没有办法确定类S的具体长相，或者说无法确定S中一定有test函数，即使你写的所有C都包含test函数，但是在编译器看来它是不确定这个问题的，因此无法通过编译。 解决办法是：1. 使用this-&gt;test，这样做告诉编译器假设这个test已经被继承了。2. 使用using声明式：using S&lt;C&gt;::test告诉编译期这个test位于S内。相当于必须手动通知编译器这个函数是存在的。 44.将与template参数无关的代码抽离到模板外 原因是模板会根据具体类型具象化不同的代码，如果将与模板无关的代码也放入模板函数或者类中，那么就会生成重复的代码，就会导致代码膨胀的问题，函数模板中与参数无关的代码可以包装成单独的函数。类模板中与参数无关的模板可以放到父类中。 45.运用成员函数模板接受所有兼容类型 文中以shared_ptr为例讲解了使用成员函数模板实现智能指针不同类型间的转换，以及如何避免任意类型之间的相互转换，这种函数可称为泛化拷贝构造函数。另外泛化拷贝构造不同于默认拷贝构造函数。如果没有自己没有编写赋值构造函数和拷贝构造函数，那么泛化拷贝构造函数不会阻止编译器生成默认的赋值构造和拷贝构造。 46.需要类型转换时请为模板定义非成员函数 条款24中Rational函数仅以int为例，说明了隐士类型转换的合格参与者的条件，并提出了非成员函数的解决方法。现在将其扩展为template形式： template &lt;typename T&gt; const Rational&lt;T&gt; operator*(const Rational&lt;T&gt;&amp; lhs, const Rational&lt;T&gt;&amp; rhs) &#123;……&#125; 发现在调用的时候无法通过编译，即以下代码无法通过编译： Rational&lt;int&gt; oneHalf(1, 2); Rational&lt;int&gt; ret = oneHalf*2; 相比于条款24，换成模板之后为什么就无法通过编译了呢？原因在于模板的运行需要进行模板推算，即operator*函数的两个参数类型的T要根据传入的参数类型进行确认，第一个参数因为是oneHalf，其本身就是Rational&lt;int&gt;类型，因此第一个参数的类型中的T很容易进行推理，但是第二个传入的参数是int，如何根据这个int参数推导出第二个参数的类型T呢？显然编译器无法进行推理，条款24能推理的原因是进行了隐士类型转换，或者说Rational的构造函数中有一个以int为参数的构造函数，但是template在进行参数推到的过程中从不将隐士类型转换函数考虑在内，这也是合理的因为你没法根据参数类型推导出模板参数，这个Ratinal的例子貌似看起来可以，因为构造函数的参数类型是const T&amp; 但是假如其构造参数类型是个固定类型，比如说float，那么难道模板参数能永远是float么。因此编译器不考虑隐士类型转换也是有道理的。 那么这个问题怎么解决呢，该如何让这个模板函数的参数能进行隐式类型转换，答案就是：先具象化这个函数，相当于先确定T，然后就可以进行隐士类型转换了，做法是在类中声明一个非成员函数，这该如何做到呢，答案就是友元函数，在类中定义的友元函数都被视为非成员函数，对于本例该像如下方式声明： friend const Rational operator*(const Rational&amp; lhs, const Rational&amp; rhs) &#123; return (lhs.numrator()*rhs.numrator()/lhs.denominator()*rhs.denominator()); &#125; 由于此函数是在模板类的内部，因此当oneHalf对象生成之后，T就被确定为int，那么operator*函数的参数和返回值中的T也均是确定的了。 另外，由于此函数的功能过于简单，因此可直接将其实现放入类中（inline的），假如类的功能很复杂，那么一般都采用调用类外的某一个功能函数，这时候代码这样实现： friend const Rational&lt;T&gt; operator*(const Rational&lt;T&gt;&amp; lhs, const Rational&lt;T&gt;&amp; rhs) &#123; return DoMultiply&lt;T&gt;(lhs, rhs); &#125; 这样写实际和上面的写法是一样的，当T被确定为int时，会生成一份Rational&lt;int&gt;的类，具象化出里面的函数，这样就能确定调用的是T为int的operator*函数，然后在另一个模板函数内实现其操作，本例来说就是DoMultiply函数。 47.traits编程技巧 traits是用来获取参数类型信息，因为有时候需要根据参数类型信息做不同的处理，下面这篇博客中列举了两个简单的例子，https://blog.csdn.net/my_business/article/details/7891687（其实可以使用typeid进行简单的实现，但是这种做法效率低，因为typeid需要配个if使用，if是在运行期才决定的，而traits可以在编译器就进行类型的判别，效率更高），文中以STL迭代器相关函数中的advance为例，advance函数原型为： 看到这里大家可能都会发现这里 if (TypeTraits &lt;T&gt;::__IsPODType().Get()) 这句其实是最关键的，用这句来区别调用的是哪个方法。但是这句里面的 __IsPODType()和Get()是哪里来的呢？ struct __TrueType &#123; bool Get() &#123; return true; &#125; &#125;; struct __FalseType &#123; bool Get() &#123; return false; &#125; &#125;; 这个是TypeTraits的模板本体，默认__IsPODType为_FalseType.当它为内置类型的特化时 __IsPODType为_TureType template &lt;class _Tp&gt; struct TypeTraits &#123; typedef __FalseType __IsPODType; &#125;; //从这开始都是特化版本（类型萃取的开始） template &lt;&gt; struct TypeTraits&lt; char&gt; &#123; typedef __TrueType __IsPODType; &#125;; template &lt;&gt; struct TypeTraits&lt; unsigned char &gt; &#123; typedef __TrueType __IsPODType; &#125;; 为了类型萃取，我们把所有的内置类型进行特化， 当然这里我只是把内置类型特化的前两个拿了出来，当T为内置 类型 时 让 _IsPODType为_TureType，所以 if (TypeTraits &lt;T&gt;::__IsPODType().Get())表达为真，走的是realloc的方法 主要使用的是模板特化的方法。通过一个struct将不同的类型typedef定义成一个类型，然后使用模板特化编译的时候获取到真实的类型，然后调用实际的方法。 48.模板元编程 采用模板编程的好处是：1. 可将工作由运行期移动到编译器完成，造成更高的执行效率（占用内存小，运行速度快）和更早的侦测错误2. 编码更加简洁；坏处：1. 编译时间长2. 代码不易理解 八.定制new和delete（条款49~52） 这章讲了new和delete的一些高级用法：set_new_handler、operator new/delete的重载及应该遵循的规则、placement new。一般情况下较少会重载new，所以倒不如了解new/delete的基础知识更好","path":"2022/04/04/C++/effective C++笔记/"},{"title":"explicit","text":"explicit使用注意事项: 1、 explicit 关键字只能用于类内部的构造函数声明上。 2. 在C++中，explicit关键字用来修饰类的构造函数，被修饰的构造函数的类，不能发生相应的隐式类型转换 可以参考这篇文章","path":"2022/04/04/C++/explicit/"},{"title":"socket编程入门","text":"socket编程入门","path":"2022/04/04/计算机网络/socket编程入门/"},{"title":"GDB入门","text":"GDB打断点的方式 GDB入门","path":"2022/04/04/C++/GDB入门/"},{"title":"C++11新特性","text":"C++11新特性","path":"2022/04/04/C++/C++11新特性/"},{"title":"C++STL知识点整理","text":"C++STL知识点整理","path":"2022/04/04/C++/C++ STL知识点/"},{"title":"linux常用命令","text":"linux常用命令","path":"2022/04/04/操作系统/linux常用命令/"},{"title":"malloc new free delete 区别","text":"malloc/free和new/delete的区别 共同点： 都是从堆上申请空间。并且需要用户手动释放 不同点： malloc和free是函数，new和delete是操作符 malloc申请的空间不会初始化，new可以 malloc申请空间时，需要手动计算空间的大小并传递，new只需要在其后边跟上空间的类型即可 malloc的返回值是void*，在使用时必须强转，new不需要，因为new后跟的是空间的类型 malloc在申请失败后返回的是NULL,因此使用时必须判空，new不需要，但是new需要捕获异常 申请自定义类型对象时，malloc/free只会开辟空间，不会调用构造函数与析构函数，而new在申请空间后会调用构造函数完成对象的初始化，delete在释放空间前会调用析构函数完成空间中资源的清理 new/delete比malloc和free的效率稍微低点，因为new/delete的底层封装了malloc/free","path":"2022/04/04/C++/malloc new delete free区别/"},{"title":"c++单例设计模式","text":"最推荐的懒汉式单例(magic static )——局部静态变量#include &lt;iostream&gt; class Singleton &#123; public: static Singleton&amp; GetInstance() &#123; static Singleton intance; return intance; &#125; ~Singleton() = default; private: Singleton() = default; Singleton(const Singleton&amp;) = delete; Singleton&amp; operator=(const Singleton&amp;) = delete; &#125;; 非局部静态变量一般在main执行之前的静态初始化过程中分配内存并初始化，可以认为是线程安全的； 全局变量、文件域的静态变量和类的静态成员变量在main执行之前的静态初始化过程中分配内存并初始化；局部静态变量（一般为函数内的静态变量）在第一次使用时分配内存并初始化。这里的变量包含内置数据类型和自定义类型的对象。 局部静态变量在编译时，编译器的实现一般是在初始化语句之前设置一个局部静态变量的标识来判断是否已经初始化，运行的时候每次进行判断，如果需要初始化则执行初始化操作，否则不执行。这个过程本身不是线程安全的。 C++11标准针规定了局部静态变量初始化需要保证线程安全 如果当变量在初始化的时候，并发同时进入声明语句，并发线程将会阻塞等待初始化结束。 这样保证了并发线程在获取静态局部变量的时候一定是初始化过的，所以具有线程安全性。 这是最推荐的一种单例实现方式： 通过局部静态变量的特性保证了线程安全 (C++11, GCC &gt; 4.3, VS2015支持该特性); 不需要使用共享指针，代码简洁； 注意在使用的时候需要声明单例的引用 Single&amp; 才能获取对象。 饿汉式 using namespace std; class CSingleton &#123; private: CSingleton()&#123; cout &lt;&lt; &quot;单例对象创建！&quot; &lt;&lt; endl; &#125;; CSingleton(const CSingleton &amp;); CSingleton&amp; operator=(const CSingleton &amp;); ~CSingleton()&#123; cout &lt;&lt; &quot;单例对象销毁！&quot; &lt;&lt; endl; &#125;; static CSingleton myInstance; // 单例对象在这里！ public: static CSingleton* getInstance() &#123; return &amp;myInstance; &#125; &#125;; CSingleton CSingleton::myInstance; 只有一个对象创建，且线程安全。","path":"2022/04/04/C++/C++单例设计模式/"},{"title":"RAII","text":"RAIIResource Acquisition Is Initialization的缩写，即资源获取即初始化，当对象创建的时候获取资源，对象析构的时候释放资源","path":"2022/04/04/C++/RAII/"},{"title":"c++引用和指针区别","text":"引用和指针区别 引用 可以认为是T *const 指针 指向的地址是不可变的，在c++中认为是别名。在使用的时候会自动解引用。使用引用可以避免拷贝的问题，引用相比指针更容易使用，引用应该避免为空。 1. 都是地址的概念； 指针指向一块内存，它的内容是所指内存的地址；引用是某块内存的别名。 ★ 区别： 1. 指针是一个实体，而引用仅是个别名； 2. 引用使用时无需解引用（*），指针需要解引用； 3. 引用只能在定义时被初始化一次，之后不可变；指针可变； 引用“从一而终” ^_^ 4. 引用没有 const，指针有 const，const 的指针不可变； 5. 引用不能为空，指针可以为空； 6. “sizeof 引用”得到的是所指向的变量（对象）的大小，而“sizeof 指针”得到的是指针本身（所指向的变量或对象的地址）的大小； typeid（T） == typeid（T&amp;） 恒为真，sizeof（T） == sizeof（T&amp;） 恒为真，但是当引用作为成员时，其占用空间与指针相同（没找到标准的规定）。 7. 指针和引用的自增（++）运算意义不一样；","path":"2022/04/04/C++/C++引用和指针区别/"},{"title":"c++智能指针介绍shard_ptr,weakptr,unique_ptr","text":"智能指针主要有三种，shard_ptr,weakptr,unique_ptr 需要的情形主要是，防止new之后忘记delete，多次delete，使用以及释放的对象 Shard_ptr需要includeShard_ptr 表面是指针，实际上是对象，拥有对对象的指针，计数值，当计数值为0时候，会自动释放内存，但是会出现循环引用的问题 避免用一个原始指针初始化多个智能指针出现多次释放资源的情况，这个情况要么使用new在构造函数参数列表中，要么使用make_shard(); 但是当使用this指针的时候是可以获得裸指针的，这种在一定情况下也会有问题。 class A &#123; public: std::shared_ptr&lt;A&gt; getShared() &#123; return std::shared_ptr&lt;A&gt;(this); &#125; &#125;; int main() &#123; std::shared_ptr&lt;A&gt; pa = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;A&gt; pbad = pa-&gt;getShared(); return 0; &#125; pa,和pbad是分别有单独的计数器，也会导致delete两次。在C++中可以使用enable_shared_from_this来解决这个问题 enable_shared_from_this是标准库中提供的接口（一个基类啦）： template&lt;typename T&gt; class enable_shared_from_this &#123; public: shared_ptr&lt;T&gt; shared_from_this(); &#125; 如果想要一个由shared_ptr管理的类A对象能够在方法内部得到this指针的shared_ptr，且返回的shared_ptr和管理这个类的shared_ptr共享引用计数，只需让这个类派生自enable_shared_from_this&lt;A&gt;即可，之后调用shared_from_this()即可获得正确的 shared_ptr。 一般来说，这个接口是通过weak_ptr实现的：enable_shared_from_this中包含一个weak_ptr，在初始化shared_ptr时，构造函数会检测到这个该类派生于enable_shared_from_this（通过模版黑魔法很容易就能实现这个功能啦），于是将这个weak_ptr指向初始化的shared_ptr。调用shared_from_this，本质上就是weak_ptr的一个lock操作： class A : enable_shared_from_this&lt;A&gt; &#123; // ...... &#125;; int main() &#123; std::shared_ptr&lt;A&gt; pa = std::make_shared&lt;A&gt;(); std::shared_ptr&lt;A&gt; pgood = pa-&gt;shared_from_this(); return 0; &#125; Weak_ptrWeak_ptr可以用shard_ptr来初始化，他是弱引用，主要是用来协作shard_ptr来 进行的，没有重载operator*和-&gt;，不占计数值，在循环引用出现的情况中将一个初始化为weak_ptr可以避免循环引用的情况，在需要对象的所有权时，可以将其转换为shard_ptr来使用，获得对象的所有权 Unique_ptrUnique_ptr主要是获得对对象的独占权，不可以赋值，可以用移动语义，move转移所有权。","path":"2022/04/04/C++/C++智能指针介绍/"},{"title":"c++智能指针实现","text":"智能指针的C++实现 四种智能指针参考 实现参考1 实现参考2 实现参考3 智能指针实现： template&lt;typename T&gt; class Shard_Ptr &#123; private: size_t * pCount; T * pPtr; private: release()//这个是私有的，要注意 &#123; if(--(*pCount)==0) &#123; delete pCount; delete pPtr; &#125; &#125; public: explicit Shard_Ptr(T* ptr=nullptr): pCount(new size_t(1)),pPtr(ptr)&#123;&#125; ~Shard_Ptr() &#123; release(); &#125; Shard_Ptr(const Shard_Ptr&lt;T&gt;&amp; ptr): pCount(ptr.pCount),pPtr(ptr.pPtr) &#123; addRefCount(); &#125; void addRefCount() &#123; (*pCount)++; &#125; size_t useCount() &#123; return (*pCount); &#125; T* get() &#123; return pPtr; &#125; T&amp; operator *() &#123; return *pPtr; &#125; T* operator -&gt;() &#123; return pPtr; &#125; Shard_Ptr&lt;T&gt;&amp; operator=(const Shard_Ptr&lt;T&gt;&amp; ptr) &#123; if(pPtr!=ptr.pPtr) &#123; release(); pPtr=ptr.pPtr; pCount=ptr.pCount; addRefCount(); &#125; return *this; &#125; &#125;; template&lt;typename T&gt; class MyUniquePtr &#123; public: explicit MyUniquePtr(T* ptr = nullptr) :mPtr(ptr) &#123;&#125; ~MyUniquePtr() &#123; if(mPtr) &#123; delete mPtr; mptr=nullptr; &#125; &#125; MyUniquePtr(MyUniquePtr &amp;&amp;p) noexcept; MyUniquePtr&amp; operator=(MyUniquePtr &amp;&amp;p) noexcept; MyUniquePtr(const MyUniquePtr &amp;p) = delete; MyUniquePtr&amp; operator=(const MyUniquePtr &amp;p) = delete; T* operator*() const noexcept &#123;return mPtr;&#125; T&amp; operator-&gt;()const noexcept &#123;return *mPtr;&#125; explicit operator bool() const noexcept&#123;return mPtr;&#125; void reset(T* q = nullptr) noexcept &#123; if(q != mPtr)&#123; if(mPtr) delete mPtr; mPtr = q; &#125; &#125; T* release() noexcept//这个是公有的 &#123; T* res = mPtr; mPtr = nullptr; return res; &#125; T* get() const noexcept &#123;return mPtr;&#125; void swap(MyUniquePtr &amp;p) noexcept &#123; using std::swap; swap(mPtr, p.mPtr); &#125; private: T* mPtr; &#125;; template&lt;typename T&gt; MyUniquePtr&lt;T&gt;&amp; MyUniquePtr&lt;T&gt;::operator=(MyUniquePtr &amp;&amp;p) noexcept &#123; swap(*this, p); return *this; &#125; template&lt;typename T&gt; MyUniquePtr&lt;T&gt; :: MyUniquePtr(MyUniquePtr &amp;&amp;p) noexcept : mPtr(p.mPtr) &#123; p.mPtr == NULL; &#125;","path":"2022/04/04/C++/智能指针实现/"},{"title":"1705. 吃苹果的最大数目（可以用红黑树即map或者优先队列priority_queue实现）","text":"一般可以用优先队列的也可以用红黑树实现，可以比较一下。 优先队列实现&lt;!—hexoPostRenderEscape:int eatenApples(vector&lt;int&gt;&amp; apples, vector&lt;int&gt;&amp; days)&lt;/span&gt; &lt;/span&gt;&#123; &lt;span class=&quot;hljs-built_in&quot;&gt;priority_queue&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;, &lt;span class=&quot;hljs-built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;&amp;gt;, greater&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; pq; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; res = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;, n = apples.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;(); i &amp;lt; n || !pq.empty(); ++i) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (i &amp;lt; n &amp;amp;&amp;amp; apples[i] != &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &amp;#123; pq.emplace(i + days[i], apples[i]); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (!pq.empty() &amp;amp;&amp;amp; pq.top().first &amp;lt;= i) &amp;#123; pq.pop(); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!pq.empty()) &amp;#123; res++; &lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;,&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt; mypair = pq.top(); mypair.second--; pq.pop(); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (mypair.second&amp;gt;&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &amp;#123; pq.emplace(mypair); &amp;#125; &amp;#125; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; res; &#125;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;红黑树实现class Solution &#123; public: int eatenApples(vector&lt;int&gt;&amp; apples, vector&lt;int&gt;&amp; days) &#123; int n=apples.size(); map&lt;int,int&gt; m; int res=0; for(int i=0;i&lt;n||!m.empty();i++) &#123; m.erase(i); if(i&lt;n&amp;&amp;apples[i]!=0) m[i+days[i]]=apples[i]; if(!m.empty()) &#123; auto tmp=m.begin(); tmp-&gt;second--; if(tmp-&gt;second==0) m.erase(tmp); res++; &#125; &#125; return res; &#125; &#125;;","path":"2022/04/02/算法/树/优先队列和红黑树实现/"},{"title":"红黑树知识点","text":"一般来说红黑树有以下的知识点 根是黑色 叶节点是黑色的（即为空的黑色的哨兵节点） 从跟到叶子经过相同数目的黑色节点 红色节点的子节点一定是两个黑色的 节点为红色或者黑色 可以参考这个链接来使用30张图带你彻底理解红黑树 红黑树主要是通过左旋右旋和节点变色来实现的。这个左旋右旋和b树b+树的都是一样的。 红黑树查找与二叉搜索树差不多的，但是由于红黑树总是黑色平衡的，所以最坏是O(2lgN)，也即整颗树刚好红黑相隔的时候。能有这么好的查找效率得益于红黑树自平衡的特性 红黑树插入首先必须先找到插入位置，把插入结点放到正确的位置就可以啦，但插入结点是应该是什么颜色呢？答案是红色。理由很简单，红色在父结点（如果存在）为黑色结点时，红黑树的黑色平衡没被破坏，不需要做自平衡操作。但如果插入结点是黑色，那么插入位置所在的子树黑色结点总是多1，必须做自平衡。 一般来说加入红节点会破坏1或者4。 1. 如果此时树为空树，那么必须把插入的节点改成黑色。2. 如果插入的节点父节点为黑节点，那么可以直接插入。3. 如果插入的节点的父节点为红色节点，破坏了4，同时此时的爷爷节点一定为黑色，需要分三种情况讨论3.1 叔叔节点为红色，直接爷爷父亲叔叔变为红黑黑，如果爷爷层级颜色被破坏就还需要继续修改，没有就ok了。3.2 叔叔节点为黑色或者不存在，且父亲是爷爷的左节点3.2.1 自己插入的是父亲节点的左节点，将父亲改为黑色，爷爷改为红色，右旋。3.2.2 自己插入的是父亲节点的右节点，对父亲节点左旋变成3.2.13.3叔叔节点为黑色或者不存在（此时应该是不存在的，因为插入的地方是叶子节点的地方，如果叔叔节点存在且为黑色，那么自己的路径和叔叔路径的黑色数目就不一样了），且父亲是爷爷的右节点（是3.2的另外一个方向的版本） 3.3.1 自己插入的是父亲节点的左节点，右旋，变成3.3.2。3.3.2 自己插入的是父亲节点的右节点，对父亲节点左旋，然后将父亲改为黑色，爷爷改为红色。插入节点的key已经存在，那么此时更新节点的value。红黑树删除删除的情况主要有几个点 1.删除的节点没有子节点，直接删除。 删除的节点有一个子节点，用子节点代替删除的节点（可以认为是删除了子节点） 删除的节点有两个子节点，用后继节点代替删除的节点。（也可以用前驱节点代替，这里以后继节点为例）。把二叉树所有结点投射在X轴上，所有结点都是从左到右排好序的，所有目标结点的前后结点就是对应前继和后继结点。（即中序遍历的后面一个节点）这里可以认为是删除了后继节点，转成情况2或者通过情况2（不存在左节点）转情况1 我们目的都是可以把情况2，3认为是情况1 综上所述，删除操作删除的结点可以看作删除替代结点，而替代结点最后总是在树末。 替换节点是红色节点 我们把替换结点换到了删除结点的位置时，由于替换结点时红色，删除也了不会影响红黑树的平衡，只要把替换结点的颜色设为删除的结点的颜色即可重新平衡。 2.替换节点是黑色节点 2.1.1 替换结点是其父结点的左子结点，替换结点的兄弟结点是红结点，兄弟节点的父节点和子节点都是黑色。 此时把替换节点，父节点，兄弟节点变成黑红黑，然后左旋。 2.1.2 替换结点是其父结点的左子结点，替换结点的兄弟结点是红结点， 2.1.2.1替换结点的兄弟结点的右子结点是红结点，左子结点任意颜色 此时由于会删除黑色节点导致不平衡，所以兄弟节点改成父节点的颜色，将父节点改为黑色，兄弟节点的右节点改为黑色。然后左旋。 2.1.2.2 替换结点的兄弟结点的右子结点为黑结点，左子结点为红结点 删除黑色的替换节点会不平衡，所以将S设置为红色，对兄弟节点右旋，然后得到2.1.2.1的情况。 2.1.2.3 替换结点的兄弟结点的右子结点为黑结点，左子结点为黑结点 将兄弟节点设置为红色。将父节点作为新的替换节点。然后重新进行删除节点处理。 2.2：替换结点是其父结点的左子结点 这个情况和2.1相同，只是方向相反。","path":"2022/04/02/算法/树/红黑树知识点/"},{"title":"哈夫曼树压缩和解压缩","text":"主要是把字符串读到vector中，然后记录每个字符出现的次数，然后构建哈夫曼树，然后再生成哈夫曼编码，再写入。 #include &lt;iostream&gt; #include &lt;Windows.h&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include&lt;stdio.h&gt; #include &lt;algorithm&gt; #include &lt;cstring&gt; #include &lt;map&gt; #include &lt;bitset&gt; #include&lt;unordered_map&gt; using namespace std; long byteNum = 0; typedef struct &#123; int weight; int parent, lchild, rchild; &#125;HafuNode, * HufumanTree; typedef struct &#123; char* data; int* num; int length; &#125;TNode; typedef struct &#123; char* data; char** HM; &#125;Code; typedef char** HuffmanCode; class Hafuman &#123; private: HuffmanCode code; TNode tnod; HufumanTree hafutree; map&lt;string, char&gt; hafumanHash; //存文件内容 vector&lt;char&gt; str; public: void compression(string decomFile,string comFile) &#123; Read(comFile); TNodeCount(); CreateHuffmanTree(); CreatHuffmanCode(); int i, j, k; unsigned int tmp = 0; int bit = 0; ofstream outfile(&quot;compression.txt&quot;, ios::out); ofstream outComFile(decomFile, ios::out); if (!outfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; //写入编码 outComFile &lt;&lt; tnod.length &lt;&lt; &#x27; &#x27;; for (i = 0; i &lt; tnod.length; i++) &#123; outComFile &lt;&lt; tnod.data[i]; outComFile &lt;&lt; code[i + 1]; outComFile &lt;&lt; &#x27; &#x27;; &#125; for (i = 0; i &lt; str.size(); i++) &#123; for (j = 0; j &lt; tnod.length; j++) &#123; if (tnod.data[j] == str[i]) &#123; break; &#125; &#125; for (k = 0; code[j + 1][k] != &#x27;\\0&#x27;; k++) &#123; outfile &lt;&lt; code[j + 1][k]; if (code[j + 1][k] == &#x27;0&#x27;) &#123; tmp = tmp | 0; &#125; else &#123; tmp = (tmp | 1); &#125; bit = (bit + 1) % 32; if (!bit) &#123; outComFile &lt;&lt; tmp &lt;&lt; &#x27; &#x27;; tmp = 0; &#125; else tmp = tmp &lt;&lt; 1; byteNum++; &#125; &#125; tmp = tmp &lt;&lt; (32 - byteNum % 32 - 1); outComFile &lt;&lt; tmp &lt;&lt; &#x27; &#x27;; outComFile &lt;&lt; byteNum; cerr &lt;&lt; &quot;文件的总的字符数为 &quot; &lt;&lt; byteNum &lt;&lt; endl; outfile.close(); //写总共的位数 cerr &lt;&lt; &quot;压缩成功!,可以到compression.txt中查看具体二进制码，压缩文件为 &quot;&lt;&lt;decomFile &lt;&lt; endl; //outComFile.seekg(0, ios::beg); //streampos size = outComFile.tellg(); cout &lt;&lt; &quot;压缩文件大小为：&quot; &lt;&lt; byteNum/8 &lt;&lt; &quot; 字节&quot; &lt;&lt; endl; outComFile.close(); &#125; void decompression(string decomFilename, string comfilename) &#123; char a[30]; ofstream outfile(comfilename, ios::out); ifstream inComfile(decomFilename, ios::in); if (!outfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; if (!inComfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; int bytenum; inComfile.seekg(-2L, ios::end); inComfile &gt;&gt; bytenum; inComfile.seekg(0, ios::beg); int codeNum; inComfile &gt;&gt; codeNum; char* code = new char[100]; char ch; unordered_map&lt;string, char&gt; hash; for (int i = 0; i &lt; codeNum; i++) &#123; inComfile &gt;&gt; ch; inComfile &gt;&gt; code; string tmp = code; hash[tmp] = ch; &#125; unsigned int m; string mystr = &quot;&quot;; for (; bytenum &gt;= 32; bytenum -= 32) &#123; inComfile &gt;&gt; m; unsigned int mask = 0x80000000; int countForByte = 32; while (1) &#123; if (!(mask &amp; m)) mystr.append(&quot;0&quot;); else mystr.append(&quot;1&quot;); m = m &lt;&lt; 1; countForByte--; if (hash.count(mystr)) &#123; outfile &lt;&lt; hash[mystr]; mystr = &quot;&quot;; &#125; if (countForByte &lt;= 0) break; &#125; &#125; inComfile &gt;&gt; m; unsigned int mask = 0x80000000; int countForByte = bytenum; while (1) &#123; if (!(mask &amp; m)) mystr.append(&quot;0&quot;); else mystr.append(&quot;1&quot;); m = m &lt;&lt; 1; countForByte--; if (hash.count(mystr)) &#123; outfile &lt;&lt; hash[mystr]; mystr = &quot;&quot;; &#125; if (countForByte &lt;= 0) break; &#125; cout &lt;&lt; &quot;解压成功！解压文件为&quot; &lt;&lt; comfilename&lt;&lt;endl; delete code; code = nullptr; &#125; void CreatHuffmanCode() &#123; int n = tnod.length; int pare, child, start; code = new char* [n + 1]; char* cd = new char[n]; cd[n - 1] = &#x27;\\0&#x27;; for (int i = 1; i &lt;= n; i++) &#123; start = n - 1; child = i; pare = hafutree[i].parent; while (pare != 0) &#123; start--; if (child == hafutree[pare].lchild) &#123; cd[start] = &#x27;0&#x27;; &#125; else &#123; cd[start] = &#x27;1&#x27;; &#125; child = pare; pare = hafutree[child].parent; &#125; code[i] = new char[n - start]; strcpy(code[i], &amp;cd[start]); &#125; for (int i = 1; i &lt;= n; i++) &#123; cerr &lt;&lt; tnod.data[i-1] &lt;&lt; &quot;权重 : &quot; &lt;&lt; tnod.num[i-1]; cerr &lt;&lt;&quot;二进制编码为&quot;&lt;&lt; code[i] &lt;&lt; endl; &#125; delete cd; &#125; void initTnode() &#123; tnod.data = new char[256]; tnod.num = new int[256]; if (tnod.data == NULL || tnod.num == NULL) &#123; cout &lt;&lt; &quot;发生错误&quot; &lt;&lt; endl; exit(1); &#125; tnod.length = 0; &#125; void Read( string filename) &#123; char ch; ifstream infile(filename, ios::in); if (!infile) &#123; cout &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; while (infile.peek() != EOF) &#123; infile.get(ch); str.push_back(ch); &#125; infile.seekg(0, ios::end); streampos size = infile.tellg(); cout &lt;&lt; &quot;源文件大小为：&quot; &lt;&lt; size &lt;&lt; &quot; 字节&quot; &lt;&lt; endl; infile.close(); &#125; bool find(const char ch, TNode t) &#123; for (int i = 0; i &lt; t.length; i++) &#123; if (t.data[i] == ch) &#123; return true; &#125; &#125; return false; &#125; void TNodeCount() &#123; int m = str.size(), j = 0; char ch; for (int i = 0; i &lt; m; i++) &#123; ch = str[i]; if (!find(ch, tnod)) &#123; tnod.data[j] = ch; tnod.num[j] = count(str.begin(), str.end(), ch); tnod.length++; j++; &#125; &#125; &#125; void Select(HufumanTree&amp; tree, int a, int&amp; b, int&amp; c) &#123; int min1, min2, minweight = 10000; for (int i = 1; i &lt;= a; i++) &#123; if (tree[i].parent == 0) &#123; if (tree[i].weight &lt; minweight) &#123; minweight = tree[i].weight; min1 = i; &#125; &#125; &#125; tree[min1].parent = 1; minweight = 10000; for (int i = 1; i &lt;= a; i++) &#123; if (tree[i].parent == 0) &#123; if (tree[i].weight &lt; minweight) &#123; minweight = tree[i].weight; min2 = i; &#125; &#125; &#125; tree[min2].parent = 1; b = min1; c = min2; &#125; void CreateHuffmanTree() &#123; int n = tnod.length; if (n &lt;= 1) &#123; return; &#125; int m = 2 * n - 1; hafutree = new HafuNode[m + 1]; for (int i = 1; i &lt;= m; i++)//为0表示没有左右节点，父节点 &#123; hafutree[i].lchild = 0; hafutree[i].parent = 0; hafutree[i].rchild = 0; &#125; for (int i = 1; i &lt;= n; i++) &#123; hafutree[i].weight = tnod.num[i - 1]; &#125; int s1, s2; for (int i = n + 1; i &lt;= m; i++) &#123; Select(hafutree, i - 1, s1, s2); hafutree[s1].parent = i; hafutree[s2].parent = i; hafutree[i].lchild = s1; hafutree[i].rchild = s2; hafutree[i].weight = hafutree[s1].weight + hafutree[s2].weight; &#125; &#125; &#125;; int main() &#123; Hafuman hafumanClass; hafumanClass.initTnode(); string command; char commandOpt; string comFile, deComFile; while (1) &#123; cerr &lt;&lt; &quot;请输入选择的功能&quot; &lt;&lt; endl; cerr &lt;&lt; &quot;1.压缩文件（SZip A xx.haf test.txt（需要压缩的文件名）)&quot; &lt;&lt; endl; cerr &lt;&lt; &quot;2.解压文件（SZip X xx.haf test1.txt(解压的文件名))&quot; &lt;&lt; endl; cin &gt;&gt; command; cin &gt;&gt; commandOpt; if (command != &quot;SZip&quot;||(commandOpt!=&#x27;A&#x27;&amp;&amp; commandOpt != &#x27;X&#x27;)) &#123; cout &lt;&lt; &quot;命令输入错误，请重新输入 &quot; ; continue; &#125; cin &gt;&gt; deComFile &gt;&gt; comFile; switch (commandOpt) &#123; case &#x27;A&#x27;: hafumanClass.compression(deComFile, comFile); break; case &#x27;X&#x27;: hafumanClass.decompression(deComFile,comFile); break; default: cout &lt;&lt; &quot;输入错误！请重新输入&quot;; break; &#125; &#125; return 0; &#125;","path":"2022/04/02/算法/树/哈夫曼树/"},{"title":"二叉树的后序遍历，先序遍历和层次遍历，中序遍历","text":"方法后序遍历的麻烦之处在于不知道现在自己是父节点的左节点还是右节点，只有知道才能决定下一步是访问右节点还是根节点，不知道的情况下就不清楚下一步应该访问弹出的栈元素的本身还是它的右节点。而前序遍历和中序遍历是总是只需要弹出栈中的元素，然后访问其右节点即可或者先访问自己再访问其右节点。 所以方法有三种： 开始的话，也是不停的往左子树走，然后直到为 null ，然后如果集合中没有栈顶元素，并且右子树不为空，那么我们就访问栈顶元素的右节点，并把栈顶元素加入集合中，如果集合中有，那么直接访问栈顶元素即可。class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); Set&lt;TreeNode&gt; set=new HashSet&lt;TreeNode&gt;(); TreeNode treenode=root; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; stack.push(treenode); treenode=treenode.left; &#125; else &#123; TreeNode tmp=stack.peek(); if(!set.contains(tmp)&amp;&amp;tmp.right!=null) &#123; treenode=tmp.right; set.add(tmp); &#125; else &#123; res.add(tmp.val); stack.pop(); &#125; &#125; &#125; return res; &#125; &#125; 如果当前节点的右节点和上一次遍历的节点相同，那就表明当前是从右节点过来的了class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); TreeNode treenode=root; TreeNode last=null; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; stack.push(treenode); treenode=treenode.left; &#125; else &#123; TreeNode tmp=stack.peek(); if(tmp.right!=null&amp;&amp;tmp.right!=last) &#123; treenode=tmp.right; &#125; else &#123; res.add(tmp.val); last=tmp; stack.pop(); &#125; &#125; &#125; return res; &#125; &#125; 只需要把每个节点 push 两次，然后判断当前 pop 节点和栈顶节点是否相同。相同的话，就意味着是从左子树到的根节点。不同的话，就意味着是从右子树到的根节点，此时就可以把节点加入到 list 中。这个方法比较巧妙 public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if (root == null) &#123; return list; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); stack.push(root); while (!stack.isEmpty()) &#123; TreeNode cur = stack.pop(); if (cur == null) &#123; continue; &#125; if (!stack.isEmpty() &amp;&amp; cur == stack.peek()) &#123; stack.push(cur.right); stack.push(cur.right); stack.push(cur.left); stack.push(cur.left); &#125; else &#123; list.add(cur.val); &#125; &#125; return list; &#125; 可以转换成一个逆的前序遍历来实现public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); TreeNode treenode=root; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; res.add(treenode.val); stack.add(treenode); treenode=treenode.right; &#125; else &#123; treenode=stack.pop().left; &#125; &#125; Collections.reverse(res); return res; &#125;","path":"2022/04/02/算法/树/145. 二叉树的后序遍历/"},{"title":"Linux下 c/c++线程锁种类有哪些？如何理解互斥锁、条件变量、读写锁以及自旋锁,原子操作，无锁编程 以及异步编程？","text":"互斥锁是阻塞锁，当某线程无法获取互斥量时，该线程会被直接挂起，该线程不再消耗CPU时间，当其他线程释放互斥量后，操作系统会激活那个被挂起的线程，让其投入运行。 临界区：每个进程中访问临界资源的那段程序称为临界区，每次只允许一个进程进入临界区，进入后不允许其他进程进入。 信号量：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。 现象： （1）单线程无锁速度最快，但应用场合受限； （2）多线程无锁速度第二快，但结果不对，未保护临界代码段； （3）多线程原子锁第三快，且结果正确； （4）多线程互斥量较慢，慢与原子锁近10倍，结果正确； （5）多线程自旋锁最慢，慢与原子锁30倍，结果正确。 结论：原子锁速度最快，互斥量和自旋锁都用保护多线程共享资源。 线程之间的锁有：互斥锁、条件锁、自旋锁、读写锁、递归锁(可重入锁)。一般而言，锁的功能越强大，性能就会越低。 mutex(互斥锁)mutex（mutual exclusive）即互斥量（互斥体）。也便是常说的互斥锁。 尽管名称不含lock，但是称之为锁，也是没有太大问题的。mutex无疑是最常见的多线程同步方式。其思想简单粗暴，多线程共享一个互斥量，然后线程之间去竞争。得到锁的线程可以进入临界区执行代码。 mutex是睡眠等待（sleep waiting）类型的锁，当线程抢互斥锁失败的时候，线程会陷入休眠。优点就是节省CPU资源，缺点就是休眠唤醒会消耗一点时间。另外自从Linux 2.6版以后，mutex完全用futex的API实现了，内部系统调用的开销大大减小。 值得一提的是，pthread的锁一般都有一个trylock的函数，比如对于互斥量： pthread_mutex_trylock用于以非阻塞的模式来请求互斥量。就好比各种IO函数都有一个noblock的模式一样，对于加锁这件事也有类似的非阻塞模式。 当线程尝试加锁时，如果锁已经被其他线程锁定，该线程就会阻塞住，直到能成功acquire。但有时候我们不希望这样。 pthread_mutex_trylock在被其他线程锁定时，会返回特殊错误码。加锁成返回0，仅当成功但时候，我们才能解锁在后面进行解锁操作！ C++11开始引入了多线程库&lt;thread&gt;，其中也包含了互斥锁的API：std::muxtex 。 互斥锁可以分为可重入的以及不可重入的&lt;!—hexoPostRenderEscape:# 可重入锁此外，依据同一线程是否能多次加锁，把互斥锁又分为如下两类： 是：称为『递归互斥量』recursive mutex ，也称『可重入锁』reentrant lock否：即『非递归互斥量』non-recursive mute），也称『不可重入锁』non-reentrant mutex 若同一线程对非递归的互斥量多次加锁，可能会造成死锁。递归互斥量则无此风险。C++11中有递归互斥量的API：std::recursive_mutex。对于pthread则可以通过给mutex添加PTHREAD_MUTEX_RECURSIVE 属性的方式来使用递归互斥量 使用场景： 一个线程在执行一个带锁的方法，该方法中又调用了另一个需要相同锁的方法，则该线程可以直接执行调用的方法【即可重入】，而无需重新获得锁 比如，&lt;span class=&quot;hljs-keyword&quot;&gt;add&lt;/span&gt;操作将会获取锁，若一个事务当中多次&lt;span class=&quot;hljs-keyword&quot;&gt;add&lt;/span&gt;，就应该允许该线程多次进入该临界区。 可重入锁存在的问题递归锁必须配合临界区的语义使用，解锁操作不仅不能在别的线程，而且绝对不能在reschedule放弃线程并在重新获得线程之后解锁。举例说明： 假设有一个单服务线程，lock之后让出线程等待回调，线程此时服务于其它service，其它service也lock同一个mutex，此时本应互斥的操作就成了重入操作，在递归锁下不能互斥！换句话说，不同的服务，通过同一个线程实例获取到了同一个监视器资源。 这是非常刁钻的bug，实际可能会出现在线程池使用中，需要格外注意。 总结可重入锁的优点：支持线程进入多个同步代码块，不容易造成死锁。可重入锁的缺点：在非常刁钻的情况下，会出现监视器资源互斥失效的情况。&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; condition variable(条件变量)请注意条件变量不是锁，它是一种线程间的通讯机制，并且几乎总是和互斥量一起使用的。所以互斥量和条件变量二者一般是成套出现的。比如C++11中也有条件变量的API：std::condition_variable。 可以使用std::condition_variable cv read-write lock(读写锁)顾名思义『读写锁』就是对于临界区区分读和写。在读多写少的场景下，不加区分的使用互斥量显然是有点浪费的。此时便该上演读写锁的拿手好戏。但是在单读多写的情况，更为复杂的锁竞争，不在此章介绍，后面我会用单读的一章来介绍。 读写锁有一个别称叫『共享-独占锁』。不过单看『共享-独占锁』或者『读写锁』这两个名称，其实并未区分对于读和写，到底谁共享，谁独占。可能会让人误以为读写锁是一种更为泛化的称呼，其实不是。读写锁的含义是准确的：是一种 读共享，写独占的锁。 读写锁的特性： 当读写锁被加了写锁时，其他线程对该锁加读锁或者写锁都会阻塞（不是失败）。 当读写锁被加了读锁时，其他线程对该锁加写锁会阻塞，加读锁会成功。 因而适用于多读少写的场景。 在C++17中出现了一种读写锁：std::shared_mutex。用它可以模拟实现出读写锁。demo代码可以直接参考cppreference： https://en.cppreference.com/w/cpp/thread/shared_mutex spinlock(自旋锁) 自旋锁是一种非阻塞锁，也就是说，如果某线程需要获取自旋锁，但该锁已经被其他线程占用时，该线程不会被挂起，而是在不断的消耗CPU的时间，不停的试图获取自旋锁。 要了解自旋锁，首先了解自旋。什么是自旋（spin）呢？更为通俗的一个词是『忙等待』（busy waiting）。最最通俗的一个理解，其实就是死循环……。 单看使用方法和使用互斥量的代码是差不多的。只不过自旋锁不会引起线程休眠。当共享资源的状态不满足的时候，自旋锁会不停地循环检测状态。因为不会陷入休眠，而是忙等待的方式也就不需要条件变量。 这是优点也是缺点。不休眠就不会引起上下文切换，但是会比较浪费CPU。 在多处理器环境中对持有锁时间较短的程序来说使用自旋锁代替一般的互斥锁往往能提高程序的性能 pthread 自旋锁的使用 // 声明一个自旋锁变量 pthread_spinlock_t spinlock; // 初始化 pthread_spin_init(&amp;spinlock, 0); // 加锁 pthread_spin_lock(&amp;spinlock); // 解锁 pthread_spin_unlock(&amp;spinlock); // 销毁 pthread_spin_destroy(&amp;spinlock); 原子操作原子操作与无锁编程 果数据结构本身就带有排他性访问的特性，也就相当于该数据结构自带一个细粒度的锁，对该数据结构的并发访问就能更加简单高效，这就是C++11提供的原子数据类型&lt; atomic &gt;。下面解释两个概念： 原子操作：顾名思义就是不可分割的操作，该操作只存在未开始和已完成两种状态，不存在中间状态； 原子类型：原子库中定义的数据类型，对这些类型的所有操作都是原子的，包括通过原子类模板std::atomic&lt; T &gt;实例化的数据类型，也都是支持原子操作的。 比如std::atomic&lt;int&gt; a; 对原子类型的访问，最主要的就是读和写，但原子库提供的对应原子操作是load()与store(val) 原子操作中的内存访问模型 原子操作保证了对数据的访问只有未开始和已完成两种状态，不会访问到中间状态，但我们访问数据一般是需要特定顺序的，比如想读取写入后的最新数据，原子操作函数是支持控制读写顺序的，即带有一个数据同步内存模型参数std::memory_order，用于对同一时间的读写操作进行排序。C++11定义的6种类型如下： memory_order_relaxed: 宽松操作，没有同步或顺序制约，仅对此操作要求原子性； memory_order_release &amp; memory_order_acquire: 两个线程A&amp;B，A线程Release后，B线程Acquire能保证一定读到的是最新被修改过的值；这种模型更强大的地方在于它能保证发生在A-Release前的所有写操作，在B-Acquire后都能读到最新值； memory_order_release &amp; memory_order_consume: 上一个模型的同步是针对所有对象的，这种模型只针对依赖于该操作涉及的对象：比如这个操作发生在变量a上，而s = a + b; 那s依赖于a，但b不依赖于a; 当然这里也有循环依赖的问题，例如：t = s + 1，因为s依赖于a，那t其实也是依赖于a的； memory_order_seq_cst: 顺序一致性模型，这是C++11原子操作的默认模型；大概行为为对每一个变量都进行Release-Acquire操作，当然这也是一个最慢的同步模型； 使用原子操作实现无锁编程原子操作与无锁编程 详细示例可以参考链接&lt;!—hexoPostRenderEscape:无锁编程是基于原子操作的，对基本原子类型的共享访问由load()与store(val)即可保证其并发同步，对抽象复杂类型的共享访问则需要更复杂的CAS来保证其并发同步，并发访问过程只是不使用锁机制了，但还是可以理解为有锁止行为的，其粒度很小，性能更高。对于某个无法实现为一个原子操作的并发访问过程还是需要借助锁机制来实现。 CAS原子操作实现无锁编程CAS原子操作主要是通过函数a.compare_exchange(expected,desired)实现的，其语义为“我认为V的值应该为A，如果是，那么将V的值更新为B，否则不修改并告诉V的值实际为多少” CAS 看起来很厉害，但也有缺点，最著名的就是 ABA 问题，假设一个变量 A ，修改为 B之后又修改为 A，CAS 的机制是无法察觉的，但实际上已经被修改过了。如果在基本类型上是没有问题的，但是如果是引用类型呢？这个对象中有多个变量，我怎么知道有没有被改过？聪明的你一定想到了，加个版本号啊。每次修改就检查版本号，如果版本号变了，说明改过，就算你还是 A，也不行。 上面的例子节点指针也属于引用类型，自然也存在ABA问题，比如在线程2执行pop操作，将A,B都删掉，然后创建一个新元素push进去，因为操作系统的内存分配机制会重复使用之前释放的内存，恰好push进去的内存地址和A一样，我们记为A’，这时候切换到线程1，CAS操作检查到A没变化成功将B设为栈顶，但B是一个已经被释放的内存块。该问题的解决方案就是上面说的通过打标签标识A和A’为不同的指针。&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 异步编程多线程（四）-异步编程 同步：就是在发出一个调用时，在没有得到结果之前，该调用就不返回。但是一旦调用返回，就得到返回值了。换句话说，就是由调用者主动等待这个调用的结果。 异步：调用在发出之后，这个调用就直接返回了，所以没有返回结果。换句话说，当一个异步过程调用发出后，调用者不会立刻得到结果。而是在调用发出后，被调用者通过状态、通知来通知调用者，或通过回调函数处理这个调用。 方法1： 使用全局变量与条件变量传递结果，即mutex 和条件变量 条件变量具有“通知–唤醒”功能，可以把执行结果或执行状态放入一个全局变量中，当被调用者执行完任务后，通过条件变量通知调用者结果或状态已更新，可以使用了。 方法2： 使用promise与future传递结果 线程间传递的返回值或抛出的异常都是在共享状态中交流的。我们知道多线程间并发访问共享数据是需要保持同步的，这里的共享状态是保证返回值或异常在线程间正确传递的关键，被调用线程可以通过改变共享状态通知调用线程返回值或异常已写入完毕，可以访问或操作了。future的状态（future_status）有以下三种： deferred：异步操作还没开始； ready：异步操作已经完成； timeout：异步操作超时。 既然线程间传递返回值或异常是通过共享状态进行的，就涉及到共享状态的提供方与获取方，只有该任务或线程拥有包含共享状态的对象，其他任务或线程才能够通过共享状态的通知机制同步获取到该任务或线程的返回值或异常。我们通常使用的&lt; thread &gt;创建线程并不拥有共享状态，我们需要为该线程提供一个共享状态，以便后续对其返回值或异常的访问。那么，怎么为一个线程提供一个包含共享状态的对象呢？这就需要借助std::promise&lt; T &gt;类模板实现了， std::promise&lt; T &gt;构造时，产生一个未就绪的共享状态（包含存储的T值和是否就绪的状态）。可设置T值，并让状态变为ready。也可以通过产生一个future对象获取到已就绪的共享状态中的T值。继续使用上面的程序示例，改为使用promise传递结果， 值得注意的是，std::future&lt; T &gt;在多个线程等待时，只有一个线程能获取等待结果。当需要多个线程等待相同的事件的结果(即多处访问同一个共享状态)，需要用std::shared_future&lt; T &gt;来替代std::future &lt; T &gt;，std::future&lt; T &gt;也提供了一个将future转换为shared_future的方法f.share()，但转换后原future状态失效。这有点类似于智能指针std::unique_ptr&lt; T &gt;与std::shared_ptr&lt; T &gt;的关系，使用时需要留心。 使用packaged_task与future传递结果 除了为一个任务或线程提供一个包含共享状态的变量，还可以直接把共享状态包装进一个任务或线程中。这就需要借助std::packaged_task&lt; Func &gt;来实现了， std::packaged_task&lt; Func &gt;构造时绑定一个函数对象，也产生一个未就绪的共享状态。通过thread启动或者仿函数形式启动该函数对象。但是相比promise，没有提供set_value()公用接口，而是当执行完绑定的函数对象，其执行结果返回值或所抛异常被存储于能通过 std::future 对象访问的共享状态中。继续使用上面的程序示例，改为使用packaged_task传递结果， 使用async传递结果 前面介绍的std::promise&lt; T &gt;与std::packaged_task&lt; Func &gt;已经提供了较丰富的异步编程工具，但在使用时既需要创建提供共享状态的对象(promise与packaged_task)，又需要创建访问共享状态的对象(future与shared_future)，还是觉得使用起来不够方便。有没有更简单的异步编程工具呢？future头文件也确实封装了更高级别的函数std::async，其具体用法如下： std::future std::async(std::launch policy, Func, Args…) std::async是一个函数而非类模板，其函数执行完后的返回值绑定给使用std::async的std::futrue对象（std::async其实是封装了thread,packged_task的功能，使异步执行一个任务更为方便）。Func是要调用的可调用对象(function, member function, function object, lambda)，Args是传递给Func的参数，std::launch policy是启动策略，它控制std::async的异步行为，我们可以用三种不同的启动策略来创建std::async： std::launch::async参数 保证异步行为，即传递函数将在单独的线程中执行； std::launch::deferred参数 当其他线程调用get()/wait()来访问共享状态时，将调用非异步行为； std::launch::async | std::launch::deferred参数 是默认行为(可省略)。有了这个启动策略，它可以异步运行或不运行，这取决于系统的负载。 继续使用上面的程序示例，改为使用std::async传递结果 从上面的代码可以看出使用std::async能在很大程度上简少编程工作量，使我们不用关注线程创建内部细节，就能方便的获取异步执行状态和结果，还可以指定线程创建策略。所以，我们可以使用std::async替代线程的创建，让它成为我们做异步操作的首选。 可重入锁参考 Linux下 c/c++线程锁种类有哪些？如何理解互斥锁、条件变量、读写锁以及自旋锁？ 条件变量和信号量的区别 条件变量和信号量的区别 并发编程参考书籍","path":"2022/04/01/C++/C++并发编程/自旋锁和互斥锁可重入锁等的区别/"},{"title":"C++类的内存大小计算","text":"C++类的内存大小计算","path":"2022/04/01/C++/C++类的内存大小计算/"},{"title":"Git rebase 和git merge的区别","text":"【Git】：git rebase和git merge有什么区别？ 一个学习git的游戏网站","path":"2022/04/01/Git/Git rebase 和Git merge的区别/"},{"title":"zookeeper脑裂","text":"Zookeeper集群”脑裂”问题 - 运维总结","path":"2022/03/31/Zookeeper/zookeeper脑裂/"},{"title":"C++常见的面试题","text":"c++ 后端开发面试题 师兄面试题","path":"2022/03/31/C++/C++常见的一些面试题/"},{"title":"kafka 介绍和基本原理","text":"kafka的基本原理，介绍以及应用场景 kafka概念与原理","path":"2022/03/31/Kafka/Kafka介绍和基本原理/"},{"title":"线性一致性-顺序一致性-最终一致性","text":"共识、线性一致性与顺序一致性","path":"2022/03/31/分布式/线性一致性-顺序一致性-最终一致性/"},{"title":"C++ 堆和栈哪个运行速度快","text":"栈快为什么&lt;!—hexoPostRenderEscape:栈由系统自动分配，速度较快。但程序员是无法控制的。堆是由new分配的内存，一般速度比较慢，而且容易产生内存碎片,不过用起来最方便。 而且栈使用的是一级缓存， 他们通常都是被调用时处于存储空间中，调用完毕立即释放堆则是存放在二级缓存中，生命周期由虚拟机的垃圾回收算法来决定 &lt;span class=&quot;hljs-number&quot;&gt;1.&lt;/span&gt;分配和释放，堆在分配和释放时都要调用函数（MALLOC,FREE)，比如分配时会到堆空间去寻找足够大小的空间（因为多次分配释放后会造成空洞），这些都会花费一定的时间，具体可以看看MALLOC和FREE的源代码，他们做了很多额外的工作，而栈却不需要这些。 &lt;span class=&quot;hljs-number&quot;&gt;2.&lt;/span&gt;访问时间，访问堆的一个具体单元，需要两次访问内存，第一次得取得指针，第二次才是真正得数据，而栈只需访问一次。另外，堆的内容被操作系统交换到外存的概率比栈大，栈一般是不会被交换出去的。 &lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape--&gt;","path":"2022/03/30/C++/堆和栈运行速度哪个快/"},{"title":"raft算法的几种情况以及问题","text":"关于Raft的一些面试题Q: raft算法保证了CAP的哪两点保证了分区容错性，以及一致性，但是不保证可用性 Q: 节点故障后为何不重置为Candidate，而是Follower?正常来说，一个节点在挂了之后重新加入集群，是以Follower的身份，需要等待一定时间才能开始选举。但是为什么不设计成挂了之后以Candidate的身份，一加入就开始选举投票呢？从正确性的角度上来说，这不会影响Raft的正确性：如果新加入的节点立刻开始选举，选举成功即为Leader，失败即为Follower。同时假设Leader挂了，那么这个时候相当于群龙无首，就算立刻把Leader拉起来，也要等待一定的选举时间才能选举出新Leader，开始处理业务。如果拉起来就能立刻选举的话，能有效减少等待选举的时间。既然这种设计不会带来错误，同时又在某些Corner Case上表现不错，为什么工业上不这么设计呢？ A: 主要是从工业实际运行的稳定性上考虑的。虽然分布式系统，crash是常态，但是正常运行的时间始终是占大多数的。如果挂了的节点拉起来之后重置为Candidate，那么会比原来多出很多Leader无缘无故切换的情况，扰乱系统稳定性。因此不推荐这种做法。 Q：多个节点同时选举，能否成功？ 选举时不首先投给自己呢？在Raft中，虽然采取了随机时间选举，但是假设一下现在多个节点同时开始选举，那么选举是不可能成功的，因为每个节点都会首先把票投给了自己。那么我们突发奇想一下，假设所有节点发起投票时，不首先把票投给自己呢？这样的话，还是有可能选举失败（三节点：A投给B，B投给C，C投给A，每个节点各一票）。同时在其他场景中，如果出现网络分区（分为多数派和少数派），假设多数派节点数为３，少数派为２。那么理论上来说多数派节点可以选举出Leader对外提供服务，但如果选举的时候不投给自己，可能就因为这一票永远无法选举出Leader，因此这种做法不可选。 Q：Ｍaster在准备Commit某条Log的时候挂了，Raft如何保证一致性？因为Master在Commit某条Log的时候，这个Log已经被复制到集群中半数以上节点了。根据Raft的选举性质，那么之后再选举出来的Leader，一定会包含这条Log。对于这条Log，是上一个Term的，那么当前Leader不能直接commit，而是要发送AppendEntries RPC来commit这条log。具体原因见论文图８。 Q: 假设某个Follower节点出现网络分区，由于接收不到Leader的心跳包，所以会不断选举，Term会一直增加。加入原集群后会把原Leader降级为Follower，导致重新选举。但实际上它并不能成为Leader(没有最新日志)，造成disruption。如何解决？Raft作者博士论文《CONSENSUS: BRIDGING THEORY AND PRACTICE》的第9.6节 “Preventing disruptions when a server rejoins the cluster”提到了PreVote算法的大概实现思路。 主要就是Prevote的思想。把选举也拆成一个两阶段提交的方式，先进行一轮prevote，这一轮prevote并不会更改自己的Term＋１，但是Vote请求里的Term是＋１的。如果收到大多数的赞成票，那么发起真正选举。否则继续等待下一轮。（好奇的是Etcd的Raft应该对Prevote票和Vote票做区分？如果Prevote投过这个Term就不能再投了，那就非常奇怪了。所以应该是区别对待的） Q: 假设Ａ, B, C三节点，A为Leader。A和B之间出现分区，但是A, C和B, C之间连接不受影响，会导致Leader频繁切换，有什么方法优化？A, B, C三节点，只有A和B之间的网络不通，而C是可以和A, B 连通的，有什么办法优化？ 由于Leader A和B无法连通，B会选举成为新Leader (C 会投给它，这个时候只有当C的日志没有比B更新的情况才会投票，如果在每次任期开始，插入一段no-op的log就可以避免这个问题)。同时Leader A的心跳包会被拒绝，降级为Follower(因为Term的原因)。过一段时间后，A也会经历一样的过程，选举成为Leader，B降级为Follower，如此反复。 raft prevote这个可以避免因为分区导致某个节点的任期一直增加，然后重新加入节点后导致重新发起选举扰乱集群，因为它的任期不是最新，不可能成为leader，此时可以引入prevote Prevote（预投票）是一个类似于两阶段提交的协议，第一阶段先征求其他节点是否同意选举，如果同意选举则发起真正的选举操作，否则降为Follower角色。这样就避免了网络分区节点重新加入集群，触发不必要的选举操作。 、Raft分为哪几个部分？ 主要是分为leader选举、日志复制、日志压缩、成员变更等。 Raft中任何节点都可以发起选举吗？ Raft发起选举的情况有如下几种： 刚启动时，所有节点都是follower，这个时候发起选举，选出一个leader； 当leader挂掉后，时钟最先跑完的follower发起重新选举操作，选出一个新的leader。 成员变更的时候会发起选举操作。 Raft中选举中给候选人投票的前提？ Raft确保新当选的Leader包含所有已提交（集群中大多数成员中已提交）的日志条目。这个保证是在RequestVoteRPC阶段做的，candidate在发送RequestVoteRPC时，会带上自己的last log entry的term_id和index，follower在接收到RequestVoteRPC消息时，如果发现自己的日志比RPC中的更新，就拒绝投票。日志比较的原则是，如果本地的最后一条log entry的term id更大，则更新，如果term id一样大，则日志更多的更大(index更大)。 Raft网络分区下的数据一致性怎么解决？ 发生了网络分区或者网络通信故障，使得Leader不能访问大多数Follwer了，那么Leader只能正常更新它能访问的那些Follower，而大多数的Follower因为没有了Leader，他们重新选出一个Leader，然后这个 Leader来接受客户端的请求，如果客户端要求其添加新的日志，这个新的Leader会通知大多数Follower。如果这时网络故障修复 了，那么原先的Leader就变成Follower，在失联阶段这个老Leader的任何更新都不能算commit（因为没有同步到大多数达成共识），都回滚，接受新的Leader的新的更新（递减查询匹配日志）。 为 Raft 引入 leader lease 机制解决集群脑裂时的 stale read 问题当 raft group 发生脑裂的情况下，老的 raft leader 可能在一段时间内并不知道新的 leader 已经被选举出来，这时候客户端在老的 leader 上可能会读取出陈旧的数据（stale read）。比如，我们假想一个拥有 5 个节点的 raft group: 其中 Node 5 是当前的 raft leader，当出现网络分区时，在 Node 5 的 raft lease 任期还没结束的一段时间内，Node 5 仍然认为自己是当前 term 的 leader，但是此时，另外一边分区已经在新的 term 中选出了新的 leader。 如果此时，客户端在新的 leader 上更新了某个值 x，此时是可以更新成功的（因为还是可以复制到多数派）。但是在分区的另一端，此时一个客户端去读取 x 的值，Node 5 还会返回老的值，这样就发生了 stale read。 解决方案引入一个新的概念, region leader。region leader 是一个逻辑上的概念, 任意时刻对于某一个 region 来说, 一定只拥有一个 region leader, 每个 region leader 在任期之内尝试每隔 t 时间间隔, 在 raft group 内部更新一下 region leader 的 lease. 所有的读写请求都必须通过 region leader 完成，但是值得注意的是， region leader 和 raft leader 可能不是一个节点，当 region leader 和 raft leader 不重合的时候，region leader 会将请求转发给当前的 raft leader，当网络出现分区时，会出现以下几种情况： region leader 落在多数派，老 raft leader 在多数派这边region leader 落在多数派，老 raft leader 在少数派这边region leader 落在少数派，老 raft leader 在多数派这边region leader 落在少数派，老 raft leader 在少数派这边用开篇的例子来分情况讨论： 对于第一种情况，region leader 的 lease 不会过期，因为 region leader 的心跳仍然能更新到多数派的节点上，老的 raft leader 仍然能同步到大多数节点上，少数派这边也不会选举出新的 leader， 这种情况下不会出现 stale read。 第二种情况，就是开篇提到会出现 stale read 的典型情况，老的 raft leader 被分到了少数派这边，多数派这边选举出了新的 raft leader ，如果此时的 region leader 在多数派这边。 因为所有的读写请求都会找到 region leader 进行，即使在原来没有出现网络分区的情况下，客户端的请求也都是要走 node 1 ，经由 node 1 转发给 node 5，客户端不会直接访问 node 5，所以此时即使网络出现分区，新 leader 也正好在多数派这边，读写直接就打到 node 1 上，皆大欢喜，没有 stale read。 第三种情况，region leader 落在少数派这边，老 raft leader 在多数派这边，这种情况客户端的请求找到 region leader，他发现的无法联系到 leader（因为在少数派这边没有办法选举出新的 leader），请求会失败，直到本次 region leader 的 lease 过期，同时新的 region leader 会在多数派那边产生（因为新的 region leader 需要尝试走一遍 raft 流程）。因为老的 region leader 没办法成功的写入，所以也不会出现 stale read。但是付出的代价是在 region leader lease 期间的系统的可用性。 第四种情况和第三种情况类似，多数派这边会产生新的 raft leader 和 region leader。这个时候如果多数派的region还没产生，那么只能联系到少数派的，读写数据不会不一致。如果一段时间之后旧的region leader超时，同时多数派中出现region，那么就只能读到多数派中的数据，只要不同时出现新旧区域都有region leader，就不会出现stale read的问题，而因为旧的region总是每隔t时间续租，联系不到大多数的时候就会过期，这个过期的之前只要多数派还没选出region就可以，这个只要把选region的时间间隔设置得大一点就可以。 而在raft中写总是一致的，因为要收到大多数的ack，才会commit，用region leader可以解决读不一致得问题。 raft并不是线性一致性得这里可以看一下etcd的保持线性一致性的方法（因为脑裂中可能出现两个leader，同时如何旧leader在少数派，新leader写入了数据，此时可能从旧leader那里读到旧数据） mit6.824是线性一致性的，因为写肯定是一致性的，读也是要通过状态机提交之后才能返回的，如果脑裂了，那么也是一致性的 etcd-raft (7): Raft线性一致读 etcd-raft的线性一致读方法二：LeaseRead 基于raft的etcd的一些问题关于 etcd 的一些谣言 Raft 常见的一些问题Raft中 几种特殊情况分析（持续更新）（1-26日勘误） Raft算法相关工程问题以及解释","path":"2022/03/29/分布式/raft算法的几种情况以及问题/"},{"title":"磁盘调度策略","text":"磁盘调度策略","path":"2022/03/29/操作系统/磁盘调度策略/"},{"title":"pageCache 以及刷盘","text":"MySQL · 性能优化 · PageCache优化管理","path":"2022/03/29/数据库/pageCache/"},{"title":"mmap","text":"mmap内存映射流程 mmap文件映射过程","path":"2022/03/29/操作系统/mmap/"},{"title":"redis 分布式方案以及一致性hash算法","text":"redis 分布式方案以及一致性hash算法","path":"2022/03/29/Redis/redis分布式方案与一致性hash算法/"},{"title":"cap理论","text":"分布式之CAP原则详解 一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域，这个时候就分区了。数据就散布在了这些不连通的区域中。这就叫分区。当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里。容忍性就提高了。然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，而这等待又会带来可用性的问题。总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。 链接：https://www.zhihu.com/question/54105974/answer/139037688 https://matt33.com/2018/07/08/distribute-system-consistency-protocol/","path":"2022/03/29/分布式/CAP理论/"},{"title":"进程间8种通信方式详解","text":"进程间8种通信方式详解","path":"2022/03/28/操作系统/进程通信方式/"},{"title":"进程线程协程调度","text":"一文读懂什么是进程、线程、协程 图解Go协程调度原理，小白都能理解","path":"2022/03/28/操作系统/进程线程协程调度/"},{"title":"interface 如何判断类型","text":"interface.(type)可以判断类型 可以参考的文章","path":"2022/03/24/GO/Interface以及如何判断它的类型/"},{"title":"日志型key/value存储模型 Bitcask","text":"日志型key/value存储模型 Bitcask参考文章","path":"2022/03/24/分布式/日志型keyvalue存储模型 Bitcask/"},{"title":"GO的并发安全吗","text":"不是安全的，可以用Sync.Map来替换，或者使用同步机制，加sync.RWLock读的时候加读锁，写的时候加写锁。 详细内容可以参考这篇文章","path":"2022/03/24/GO/GO 的map并发安全吗/"},{"title":"RPC相关","text":"golang中的net/rpc包使用概述 RPC的基本的原理可以看这里","path":"2022/03/24/分布式/RPC相关/"},{"title":"mysql redo log undo log binlog 区别","text":"参考文章 参考文章 redo log 是InnoDB 引擎特有的,undo log 是引擎层面特有的，binlog 是MySQL 的Server 层实现的，所有引擎都可以使用。 redo log 是物理日志，记录的是“在某个数据页上做了什么修改”，主要可以解决崩溃宕机之后恢复的问题；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给ID=2 这一行的c 字段加1 ”，可以让数据库恢复到任何一个时刻，undo log 是逻辑日志，记录的是相反的操作，可用于MVCC多版本快照管理。 一、redo log 重做日志 作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启 mysql 服务的时候，根据 redo log 进行重做，从而达到事务的持久性这一特性。 内容：物理格式的日志，记录的是物理数据页面的修改的信息，其 redo log 是顺序写入 redo log file 的物理文件中去的。 redo log总是先写redo log的缓冲区，然后再写到操作系统的缓冲器，再写入磁盘的redo log file。 这种刷盘有三种策略，一种是每次都写到磁盘中，实时的，性能很差，不会丢失数据。 一种是每秒刷到磁盘，会丢失一秒的数据，但是性能相对比较好。 一种是实时的刷到os缓冲区中，然后每秒刷到磁盘中。 redo log内容是一个环形的大小的，有两个指针一个是写的位置，一个是数据页刷盘的位置checkpoint。当数据页不断刷盘的时候，checkpoint向前移动，redolog不断增加的时候，写位置向前移动，两者中间是还可以写的空间。 二、bin log 归档日志（二进制日志），以二进制形式保存 作用：用于复制，在主从复制中，从库利用主库上的 binlog 进行重播，实现主从同步。 用于数据库的基于时间点的还原。，数据恢复也会使用binlog，比如让数据库恢复到某个状态 内容：逻辑格式的日志，可以简单认为就是执行过的事务中的 sql 语句。但又不完全是 sql 语句这么简单，而是包括了执行的 sql 语句（增删改）反向的信息，也就意味着 delete 对应着 delete 本身和其反向的 insert；update 对应着 update 执行前后的版本的信息；insert 对应着 delete 和 insert 本身的信息。 binlog 有三种模式：Statement（基于 SQL 语句的复制）、Row（基于行的复制） 以及 Mixed（混合模式） 基于sql的就是每次把会影响sql的语句记录下来。缺点在某些情况下数据会不一致。 基于行的是，每次记录哪个行被修改了，可能会导致记录的信息多很多。 混合的，一般的复制使用 STATEMENT 模式保存 binlog ，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog。 两阶段协议: 为了报纸redo log和bin log的一致性，通常还要通过两阶段协议来维持，比如某个事务，先写内存，然后写redo log，进行prepare状态，然后写bin log，提交事务。 三、undo log 回滚日志 作用：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读 内容：逻辑格式的日志，在执行 undo 的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于 redo log 的。","path":"2022/03/24/数据库/mysql_redo_undo_binlog区别/"},{"title":"mysql一行是如何存储的","text":"参考文章","path":"2022/03/24/数据库/mysql一行是如何存储的/"},{"title":"mysql写入数据的流程","text":"参考文章 参考文章2 MySQL 中Redo与Binlog顺序一致性问题 这个必须用二阶段提交是为了防止redolog成功写了，但是binlog写了之后没有提交，然后导致从机器拿到了binlog的数据，但是如果这个时候崩溃，主机器就会回滚，这个从机器和主机器就会有不一致的问题。 如果用了二阶段提交，prepare阶段，先写redolog，然后redolog刷盘，然后进入提交阶段，然后写binlog同时binlog刷盘，然后提交，这个时候如果redolog写之后宕机了，会回滚，如果binlog写完刷盘之后提交了，宕机之后重启检查binlog的这个事务，会重新提交 InnoDB双写缓冲技术双写主要是先写到共享表空间的一个buffer 里面，然后再从这个共享表空间的部分写到磁盘上，可以解决写到磁盘上数据出错的问题。","path":"2022/03/24/数据库/mysql写入数据的流程/"},{"title":"mysql各种锁和MVCC","text":"MySQL中的锁主要分为三类 表锁： 读锁：多个读可并发 写锁：当前写未提交事务之前，会阻塞其他写和读的进程 行锁： 共享锁：允许一个事务读一行，而阻止其他事务获得相同的排他锁 排他锁：允许获得排他锁的事务更新数据，阻止其他事务获得共享锁和排他锁 意向共享锁（IS）：一个事务给一个数据行加共享锁时，必须先获得表的意向共享锁 意向排他锁(IX)：一个事务给一个数据行加排他锁时，必须先获得表的意向排他锁 页锁: 提到锁到种类,需要提一下MySQL到存储引擎,MySQL常用引擎有MyISAM和InnoDB，而InnoDB是mysql默认的引擎。MyISAM是不支持行锁的，而InnoDB支持行锁和表锁。 MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁,读锁会阻塞对同一张表对写操作,而写锁既会阻塞对同一张表对写操作,也会阻塞读操作. 对于InnoDB来说,大家都知道InnoDB相对与MyISAM,支持了事务和行锁.而行锁顾名思义,就是针对具体某一行数据上的锁,更切确的说是针对索引加的锁(这个会在下文锁的实现中讲到). 排他锁,通常我们在InnoDB中执行一个更新操作,针对这一行数据会持有排他锁,持有排他锁时,不允许再在数据行上添加写锁与读锁,其他事务对此行数据的读、写操作都会被阻塞,只有当前事务提交了,锁释放了才允许其他事务进行读写,达到避免 脏读 的效果共享锁,主要是为了支持并发的读取数据而出现的，当一个事务持有某一数据行的共享锁时,允许其它事务再获取共享锁,但不允许其它事务获取排他锁，也就是说,在持有共享锁时,多个事务可以读取当前数据,但不不允许任何事务对当前数据进行修改操作，从而避免 不可重复 的问题 意向锁,首先需要明白一点,意向锁的作用是在表上的,当一个事务需要获取共享锁或排他锁时,首先要获取对应的意向锁,为什么要这样做呢,举个例子,假设在事务A中,某一行数据持有共享锁,这一行只能读,不能写.此时事务B申请获得表的写锁,假如加锁成功,那么事务B将能够对整个表的数据进行读写,与事务A冲突.这种操作肯定是不允许的,所以MySQL会在申请共享锁或者排他锁的时候,先获取对应的意向锁,也就是说,你要操作表中的某一行锁数据,先要看看整个表能不能被操作.意向锁的申请是有数据库完成的,不需要人为申请. 行锁的3种实现上文对几种锁类型进行了分析,其实平时开发中接触到最多的还是行锁,行锁的实现有以下几种行锁分为： Record Lock记录锁：针对单个行记录得锁 Gap Lock间隙锁：锁定一个范围 Next-Key Lock：Record Lock和Gap Lock的并集在InnoDB中,锁的实现是基于索引的 Record Lock(记录锁),会锁住索引记录,比如 update table where id = 1;,会是这种实现 Gap Lock(间隙锁),实质上是对索引前后的间隙上锁，不对索引本身上锁,目的是为了防止幻读.当使用范围条件而不是相等条件检索数据并请求排他锁、或共享锁时,对于该范围内不存在的记录,不允许其修改插入.举个例子,当表中只有一条id=101的记录,一个事务执行select * from user where user_id &gt; 100 for update;,此时另一个事务执行插入一条id=102的数据是会阻塞的,必须等待第一个事务提交后才能完成.间隙锁是针对事务隔离级别为可重复读或以上级别 Next-Key Lock,是记录锁和间隙锁对结合,会同时锁住记录与间隙.在可重复读(Repeatable Read)隔离级别下，会以Next-Key Lock的方式对数据行进行加锁 MVCC锁机制可以控制并发操作,来保证一致性,但是系统开销会很大.在RC、RR的隔离级别下,MySQL InnoDB通过MVCC (多版本并发控制)机制来解决幻读,使事务在并发过程中,SELECT 操作不用加锁，读写不冲突从而提高性能.其原理是通过保存数据在某个时间点的快照来实现的.通过在每行记录后面保存隐藏列来存放事务ID,这样每一个事务,都会对应一个递增的事务ID.假设三个事务同时更新来同一行数据,那么就会对应三个数据版本,但实际上版本1、版本2并不是物理存在的,而是通过关联记录在undo log中,这样就可以通过undo log找回数据的历史版本,比如回滚的操作,会使用上一个版本的数据覆盖数据页上的数据 下面举例一个RR隔离级别下快照读的 例子1:开启事务A按条件A查询到两条数据,此时事务B再插入1条数据满足条件A的数据,并提交事务,此时事务A再按条件A进行查询,查询到的依然是两条数据,也就是说,事务A查询到的并不是当前最新的数据版本,而是通过MVCC实现的历史快照版本.这也是可重复读的实现.快照读 上面的例子介绍了读操作,那么写操作呢,也是如此事务之间互不干扰吗.再举例一个RR隔离级别下更新操作的 例子2:假设事务A执行一个更新语句,满足更新条件A的的数据是2条,更新成功后不提交事务,此时事务B插入一条新的满足条件A的数据,此时事务A再按条件A去更新数据,实验发现事务B新插入的数据也被更新了.出现了幻读,这就是当前读,即对数据修改的操作(update、insert、delete)都会读到已提交事务的最新数据. 那么当前读的幻读问题如何解决呢?MVCC不能解决的问题当然是交给锁来解决了.上文提到的Next-Key Lock正是解决这个问题的方法,还以上面的例子2为例,给条件A字段非唯一索引,事务B进行插入数据的时候就会被阻塞,原因是事务A持有了Gap Lock,只有事务A提交了,事务B才能成功插入数据.这就解决了当前读操作下的幻读问题. 所以MVCC机制可防止快照读引起的幻读，next-key锁可防止当前读引起的幻读.需要说明的是,MVCC只在RC和RR两个隔离级别下工作。其他两个隔离级别和MVCC不兼容, 因为 RU总是读取最新的数据行, 而不是符合当前事务版本的数据行.而SERIALIZABLE 则会对所有读取的行都加锁. 锁的触发和升级以默认的InnoDB引擎RR级别说明,表锁可以理解为每一行记录都持有Record Lock,更新记录时,当更新字段没有走索引时,无法获取对应记录的Record Lock,行锁便会升级为表锁,这一点可以结合MySQL Explain去分析.需要注意的是当普通索引值区分度低时，此时观察Explain显示是走了索引的,但当另一个事务并发操作不同数据时,依然发现第二个事务会阻塞,这是因为MySQL的执行优化器认为给多行记录一次一次当加锁不如表锁来的高效,所以不会把这个普通索引当做索引,而当区分度高时,则认为是高效的,不会升级为表锁.所以,创建合适的索引很重要,区分度低的字段不建议创建索引.","path":"2022/03/24/数据库/mysql各种锁和MVCC/"},{"title":"mysql数据大量写入的问题","text":"今天这里主要给大家介绍，在有大量写入的场景，进行优化的方案。 总的来说MYSQL数据库写入性能主要受限于数据库自身的配置，以及操作系统的性能，磁盘IO的性能。主要的优化手段包括以下几点： 1、调整数据库参数（1） innodb_flush_log_at_trx_commit默认为1，这是数据库的事务提交设置参数，可选值如下： 0: 日志缓冲每秒一次地被写到日志文件，并且对日志文件做到磁盘操作的刷新，但是在一个事务提交不做任何操作。 1：在每个事务提交时，日志缓冲被写到日志文件，对日志文件做到磁盘操作的刷新。 2：在每个提交，日志缓冲被写到文件，但不对日志文件做到磁盘操作的刷新。对日志文件每秒刷新一次。 有人会说如果改为不是1的值会不会不安全呢？ 安全性比较如下： 在 mysql 的手册中，为了确保事务的持久性和一致性，都是建议将这个参数设置为 1 。出厂默认值是 1，也是最安全的设置。 当innodb_flush_log_at_trx_commit和sync_binlog 都为 1 时是最安全的，在mysqld 服务崩溃或者服务器主机crash的情况下，binary log 只有可能丢失最多一个语句 或者一个事务。 但是这种情况下，会导致频繁的io操作，因此该模式也是最慢的一种方式。 当innodb_flush_log_at_trx_commit设置为0，mysqld进程的崩溃会导致上一秒钟所有事务数据的丢失。当innodb_flush_log_at_trx_commit设置为2，只有在操作系统崩溃或者系统掉电的情况下，上一秒钟所有事务数据才可能丢失。针对同一个表通过c#代码按照系统业务流程进行批量插入，性能比较如下所示： （a.相同条件下：innodb_flush_log_at_trx_commit=0，插入50W行数据所花时间25.08秒;（b.相同条件下：innodb_flush_log_at_trx_commit=1，插入50W行数据所花时间17分21.91秒;（c.相同条件下：innodb_flush_log_at_trx_commit=2，插入50W行数据所花时间1分0.35秒。结论：设置为0的情况下，数据写入是最快的，能迅速提升数据库的写入性能， 但有可能丢失上1秒的数据。 （2) temp_table_size,heap_table_size这两个参数主要影响临时表temporary table 以及内存数据库引擎memory engine表的写入，设置太小，甚至会出现table is full的报错信息. 要根据实际业务情况设置大于需要写入的数据量占用空间大小才行。 （3) max_allowed_packet=256M,net_buffer_length=16M，set autocommit=0备份和恢复时如果设置好这三个参数,可以让你的备份恢复速度飞起来哦！ （4) innodb_data_file_path=ibdata1:1G;ibdata2:64M:autoextend很显然表空间后面的autoextend就是让表空间自动扩展，不够默认情况下只有10M，而在大批量数据写入的场景，不妨把这个参数调大； 让表空间增长时一次尽可能分配更多的表空间，避免在大批量写入时频繁的进行文件扩容 （5) innodb_log_file_size,innodb_log_files_in_group,innodb_log_buffer_size设置事务日志的大小，日志组数，以及日志缓存。默认值很小，innodb_log_file_size默认值才几十M，innodb_log_files_in_group默认为2。 然而在innodb中，数据通常都是先写缓存，再写事务日志，再写入数据文件。设置太小，在大批量数据写入的场景，必然会导致频繁的触发数据库的检查点，去把 日志中的数据写入磁盘数据文件。频繁的刷新buffer以及切换日志，就会导致大批量写入数据性能的降低。 当然，也不宜设置过大。过大会导致数据库异常宕机时，数据库重启时会去读取日志中未写入数据文件的脏数据，进行redo，恢复数据库，太大就会导致恢复的时间变的更长。当恢复时间远远超出用户的预期接受的恢复时间，必然会引起用户的抱怨。 这方面的设置倒可以参考华为云的数据库默认设置,在华为云2核4G的环境，貌似默认配置的buffer:16M,log_file_size:1G——差不多按照mysql官方建议达到总内存的25%了；而日志组files_in_group则设置为4组。 2核4G这么低的硬件配置，由于参数设置的合理性，已经能抗住每秒数千次，每分钟8万多次的读写请求了。 而假如在写入数据量远大于读的场景，或者说方便随便改动参数的场景，可以针对大批量的数据导入，再做调整，把log_file_size调整的更大，可以达到innodb_buffer_pool_size的25%~100%。 （6) innodb_buffer_pool_size设置MySQL Innodb的可用缓存大小。理论上最大可以设置为服务器总内存的80%.设置越大的值，当然比设置小的值的写入性能更好。比如上面的参数innodb_log_file_size就是参考innodb_buffer_pool_size的大小来设置的。 （7) innodb_thread_concurrency=16故名思意，控制并发线程数，理论上线程数越多当然会写入越快。当然也不能设置过大官方建议是CPU核数的两倍左右最合适。 （8) write_buffer_size控制单个会话单次写入的缓存大小，默认值4K左右，一般可以不用调整。然而在频繁大批量写入场景，可以尝试调整为2M，你会发现写入速度会有一定的提升。 （9) innodb_buffer_pool_instance默认为1，主要设置内存缓冲池的个数，简单一点来说，是控制并发读写innodb_buffer_pool的个数。 在大批量写入的场景，同样可以调大该参数，也会带来显著的性能提升。 （10) bin_log二进制日志，通常会记录数据库的所有增删改操作。然而在大量导数据，比如数据库还原的时候不妨临时关闭bin_log,关掉对二进制日志的写入，让数据只写入数据文件，迅速完成数据恢复，完了再开启吧。 2、减少磁盘IO，提高磁盘读写效率包括如下方法： （1)：数据库系统架构优化a：做主从复制； 比如部署一个双主从，双主从模式部署是为了相互备份，能保证数据安全，不同的业务系统连接不同的数据库服务器，结合ngnix或者keepalive自动切换的功能实现负载均衡以及故障时自动切换。 通过这种架构优化，分散业务系统的并发读写IO从一台服务器到多台服务器，同样能提高单台数据库的写入速度。 b：做读写分离 和1中要考虑的问题一样，可以减轻单台服务器的磁盘IO，还可以把在服务器上的备份操作移到备服务器，减轻主服务器的IO压力，从而提升写入性能。 （2)：硬件优化a: 在资源有限的情况下，安装部署的时候，操作系统中应有多个磁盘，把应用程序，数据库文件，日志文件等分散到不同的磁盘存储，减轻每个磁盘的IO，从而提升单个磁盘的写入性能。 b：采用固态硬盘SSD 如果资源足够可以采用SSD存储，SSD具有高速写入的特性，同样也能显著提升所有的磁盘IO操作。 当然还有更多的硬件或者软件优化方法，这里就不一一列举了。 参考链接","path":"2022/03/24/数据库/mysql数据大量写入的问题/"},{"title":"间隙锁","text":"间隙锁当我们用范围条件而不是相等条件索引数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项枷锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”。 InnoDB也会对这个“间隙”枷锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。 间隙锁的危害因为Query执行过程中通过范围查找的话，他会锁定整个范围内所有的索引键值，即使这个键值并不存在。间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，也造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害。 间隙锁与死锁最近用户反馈说系统老是出现insert时，等待超时了，最后发现是insert间隙锁！间隙锁是innodb中行锁的一种， 但是这种锁锁住的却不止一行数据，他锁住的是多行，是一个数据范围。间隙锁的主要作用是为了防止出现幻读，但是它会把锁定范围扩大， 有时候也会给我们带来麻烦，我们就遇到了。 在数据库参数中， 控制间隙锁的参数是： innodb_locks_unsafe_for_binlog， 这个参数默认值是OFF， 也就是启用间隙锁， 他是一个bool值， 当值为true时表示disable间隙锁。 那为了防止间隙锁是不是直接将innodb_locaks_unsafe_for_binlog设置为true就可以了呢？ 不一定！ 而且这个参数会影响到主从复制及灾难恢复， 这个方法还尚待商量。 间隙锁的出现主要集中在同一个事务中先delete后 insert的情况下， 当我们通过一个参数去删除一条记录的时候， 如果参数在数据库中存在，那么这个时候产生的是普通行锁，锁住这个记录， 然后删除， 然后释放锁。如果这条记录不存在， 问题就来了， 数据库会扫描索引，发现这个记录不存在， 这个时候的delete语句获取到的就是一个间隙锁，然后数据库会向左扫描扫到第一个比给定参数小的值，向右扫描扫描到第一个比给定参数大的值， 然后以此为界，构建一个区间， 锁住整个区间内的数据， 一个特别容易出现死锁的间隙锁诞生了。","path":"2022/03/24/数据库/间隙锁/"},{"title":"事务的隔离级别","text":"事务并发可能出现的情况脏读（Dirty Read）一个事务读到了另一个未提交事务修改过的数据 会话B开启一个事务，把id=1的name为武汉市修改成温州市，此时另外一个会话A也开启一个事务，读取id=1的name，此时的查询结果为温州市，会话B的事务最后回滚了刚才修改的记录，这样会话A读到的数据是不存在的，这个现象就是脏读。（脏读只在读未提交隔离级别才会出现） 不可重复读（Non-Repeatable Read）一个事务只能读到另一个已经提交的事务修改过的数据，并且其他事务每对该数据进行一次修改并提交后，该事务都能查询得到最新值。（不可重复读在读未提交和读已提交隔离级别都可能会出现）会话A开启一个事务，查询id=1的结果，此时查询的结果name为武汉市。接着会话B把id=1的name修改为温州市（隐式事务，因为此时的autocommit为1，每条SQL语句执行完自动提交），此时会话A的事务再一次查询id=1的结果，读取的结果name为温州市。会话B再此修改id=1的name为杭州市，会话A的事务再次查询id=1，结果name的值为杭州市，这种现象就是不可重复读。 幻读（Phantom）一个事务先根据某些条件查询出一些记录，之后另一个事务又向表中插入或者删除了符合这些条件的记录，原先的事务再次按照该条件查询时，能把另一个事务插入的记录也读出来。（幻读在读未提交、读已提交、可重复读隔离级别都可能会出现） 会话A开启一个事务，查询id&gt;0的记录，此时会查到name=武汉市的记录。接着会话B插入一条name=温州市的数据（隐式事务，因为此时的autocommit为1，每条SQL语句执行完自动提交），这时会话A的事务再以刚才的查询条件（id&gt;0）再一次查询，此时会出现两条记录（name为武汉市和温州市的记录），这种现象就是幻读。 不可重复读出现多是因为修改；幻读重点是新增、删除。mysql中的REPEATABLE_READ模式引入了间隙锁（GAP），解决了幻读的问题。 事务的隔离级别MySQL的事务隔离级别一共有四个，分别是读未提交、读已提交、可重复读以及可串行化。 MySQL的隔离级别的作用就是让事务之间互相隔离，互不影响，这样可以保证事务的一致性。 隔离级别比较：可串行化&gt;可重复读&gt;读已提交&gt;读未提交 隔离级别对性能的影响比较：可串行化&gt;可重复读&gt;读已提交&gt;读未提交 由此看出，隔离级别越高，所需要消耗的MySQL性能越大（如事务并发严重性），为了平衡二者，一般建议设置的隔离级别为可重复读，MySQL默认的隔离级别也是可重复读。 读未提交（READ UNCOMMITTED）在读未提交隔离级别下，事务A可以读取到事务B修改过但未提交的数据。 可能发生脏读、不可重复读和幻读问题，一般很少使用此隔离级别。 读已提交（READ COMMITTED）在读已提交隔离级别下，事务B只能在事务A修改过并且已提交后才能读取到事务B修改的数据。 读已提交隔离级别解决了脏读的问题，但可能发生不可重复读和幻读问题，一般很少使用此隔离级别。 可重复读（REPEATABLE READ）在可重复读隔离级别下，事务B只能在事务A修改过数据并提交后，自己也提交事务后，才能读取到事务B修改的数据。 可重复读隔离级别解决了脏读和不可重复读的问题，但可能发生幻读问题。 为什么解决了不可重复读呢，因为如果自己的事务没提交就算对方事务提交了，也不能读到对方修改的数据。 但是为什么没解决幻读的问题呢，因为 幻读出现的场景： 1、如果事务中都是用快照读，那么不会产生幻读的问题 2、快照读和当前读一起使用的时候就会产生幻读 而正常采用的不是快照读 提问：为什么上了写锁（写操作），别的事务还可以读操作？ 因为InnoDB有MVCC机制（多版本并发控制），可以使用快照读，而不会被阻塞。 使用间隙锁可以避免当前读情况下的幻读 可串行化（SERIALIZABLE）各种问题（脏读、不可重复读、幻读）都不会发生，通过加锁实现（读锁和写锁）。 隔离级别的实现原理 使用MySQL的默认隔离级别（可重复读）来进行说明。 每条记录在更新的时候都会同时记录一条回滚操作（回滚操作日志undo log）。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（MVCC）。即通过回滚（rollback操作），可以回到前一个状态的值。 假设一个值从 1 被按顺序改成了 2、3、4，在回滚日志里面就会有类似下面的记录。 当前值是 4，但是在查询这条记录的时候，不同时刻启动的事务会有不同的 read-view。如图中看到的，在视图 A、B、C 里面，这一个记录的值分别是 1、2、4，同一条记录在系统中可以存在多个版本，就是数据库的多版本并发控制（MVCC）。对于 read-view A，要得到 1，就必须将当前值依次执行图中所有的回滚操作得到。 同时你会发现，即使现在有另外一个事务正在将 4 改成 5，这个事务跟 read-view A、B、C 对应的事务是不会冲突的。 提问：回滚操作日志（undo log）什么时候删除？ MySQL会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。 提问：什么时候不需要了？ 当系统里么有比这个回滚日志更早的read-view的时候。 参考文章","path":"2022/03/23/数据库/事务的隔离级别/"},{"title":"io read/write on closed pipe","text":"这个的主要原因在于客户端和主机的时间不同步，因此需要安装chronyd，然后进行时间校正 date可以查看服务器的时间，如果不对就安装chronyd。 yum install chronyd可能会出现问题 CentOS-8中“Failed to download metadata for repo ‘AppStream“ 问题原因：原因是：CentOS-8于2021年12月31日停止了源的服务 可以命令查看一下系统是不是8： cat /etc/redhat-release （1）打开/etc/yum.repos.d文件夹： cd /etc/yum.repos.d （2）新建bak文件夹并将文件拷贝进其中： mkdir bakcp * bak/ 可能会出现cp: -r not specified; omitting directory ‘bak’提示，无影响，无视就好。 （3）使用以下命令进行内容的替换： sed -i ‘s/$releasever/8-stream/‘ CentOS*repo 问题解决！ 输入以上命令之后，就可以接着运行你的install命令了 安装完这个chronyd之后，然后 vim /etc/chrony.conf 然后再上面的ntp server 换成下面的国内的地址，接着地址就和国内同步了 cn.pool.ntp.org # 最常用的国内NTP服务器，参考：https://www.ntppool.org/zh/use.html cn.ntp.org.cn # 中国 edu.ntp.org.cn # 中国教育网 ntp1.aliyun.com # 阿里云 ntp2.aliyun.com # 阿里云 ntp.sjtu.edu.cn # 上海交通大学 s1a.time.edu.cn # 北京邮电大学 s1b.time.edu.cn # 清华大学 s1c.time.edu.cn # 北京大学 s1d.time.edu.cn # 东南大学 s1e.time.edu.cn # 清华大学 s2a.time.edu.cn # 清华大学 s2b.time.edu.cn # 清华大学 s2c.time.edu.cn # 北京邮电大学 s2d.time.edu.cn # 西南地区网络中心 s2e.time.edu.cn # 西北地区网络中心 s2f.time.edu.cn # 东北地区网络中心 s2g.time.edu.cn # 华东南地区网络中心 s2h.time.edu.cn # 四川大学网络管理中心 s2j.time.edu.cn # 大连理工大学网络中心 s2k.time.edu.cn # CERNET桂林主节点然后重启时间服务 systemctl restart chronyd 然后重启v2ray服务 systemctl restart v2ray","path":"2022/03/23/服务器配置/io read write on closed pipe/"},{"title":"慢查询","text":"慢查询就是那些查询时间过长的语句 show variables like &#x27;%slow_qurey%&#x27; set global slow_query_log = ON; 开启慢查询日志功能,最好在配置环境直接配置保证重启时也生效 set global long_query_time = 1; 慢查询阈值 执行计划是指一条SQL 语句在经过MySQL 查询优化器的优化会后，具体的执行方式。 思路1.开启慢查询日志，设置超过几秒为慢sql语句，抓取慢sq语句。l2.通过explain查看执行计划，对慢sql语句分析。3.创建索引并调整语句，再查看执行计划，对比优化结果。 比如说explain select *from single where name like &quot;%解%&quot;&lt;!—hexoPostRenderEscape:得到的结果为id selectType table patition type possiable_key key key_len ref rows fitered Extra 1 simple single null range idx_single_name idx_single_name 137 null 1 100 using index condition&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 先看type：All全表扫描，没有用到索引 再看key：Null没有使用索引列 然后看rows：数值越多耗时越长 最后看Extra：避免Using temporary和Using Filesort id:选择标识符，代表执行顺序 select_type:表示查询的类型。 simple:简单的select查询，不包含联合查询和子查询 primary:查询中包含子查询 subquery:select 或者where中包含子查询 derived：from中包含子查询 union：联合查询 union result：union后的结果集 table:查询的表名partitions:匹配的分区type:表示表的连接类型All：全表扫描 Index：只遍历索引树，索引树上就有要查询的结果，不需要IO Range：索引范围扫描 Ref：非唯一性索引扫描 Eq_ref：唯一索引扫描 Const：通过一次索引就能查询到，通常是Primary Key或者Unique System：Const特例，表数据只有一行 Null：不用访问索引就可以直接查询到结果 Possible_key：能使用哪个索引找到数据行，单并不一定会被使用到Key：Possible_key中决定使用的索引Key_len:显示索引中使用的字节数ref:上述表的连接匹配条件，即哪些列或常量被用于查找索引上的值Rows:找到所需记录要读取的行数Extra:Using Where：仅通过索引就可以过滤所需数据 Using temporary：需要使用临时表来存储结果集 Using Filesort：order by操作无法利用索引完成导致的“文件排序” Using join buffer：连接使用了缓存，可以通过添加索引来解决 Using Index：索引树中包含要查询的所有信息 Using Index Condition:根据辅助索引过滤数据，减少Server和磁盘的IO次数 索引创建原则表一定要有业务无关的主键 适合添加索引的列：经常被查询、经常用于表链接，经常排序或者分组 索引列尽量都是不重复的数据 组合索引一般不超过5列，选择性高的放在前面 合理利用索引覆盖，禁止select * explain 判断sql是否合理利用索引 单表索引控制在5个以内 不建议在频繁更新的字段上添加索引 where条件中的索引列不能是表达式的一部分，避免对索引列进行函数计算 join类型的字段必须类型一致且都建立索引 索引失效隐式的类型转换会导致索引失效，导致全表扫描 对索引列进行函数或者数学计算，例如日期格式化 模糊匹配未使用前缀匹配 使用了负方向查询，not，!=，not in等 Sql规范按需查询避免 select * 无法使用覆盖索引，回表，增加IO 多查询的列，会有多余的IO和网络开销 避免大事务，将大事务拆成小事务。防止出现锁阻塞，导致的雪崩效应 少用多表join，禁止大表join，小表驱动大表，join列必须字符集一致，且有索引 尽量避免多层子查询嵌套 定期对慢sql优化 总的优化1、索引优化为搜索字段（where中的条件）、排序字段、select查询列，创建合适的索引，不过要考虑数据的 业务场景：查询多还是增删多？ 尽量建立组合索引并注意组合索引的创建顺序，按照顺序组织查询条件、尽量将筛选粒度大的查询 条件放到最左边。 尽量使用覆盖索引，SELECT语句中尽量不要使用*。 order by、group by语句要尽量使用到索引 索引长度尽量短，短索引可以节省索引空间，使查找的速度得到提升，同时内存中也可以装载更多 的索引键值。太长的列，可以选择建立前缀索引 索引更新不能频繁，更新非常频繁的数据不适宜建索引，因为维护索引的成本。 order by的索引生效，order by排序应该遵循最佳左前缀查询，如果是使用多个索引字段进行排 序，那么排序的规则必须相同（同是升序或者降序），否则索引同样会失效。 (最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。) 2. LIMIT优化如果预计SELECT语句的查询结果是一条，最好使用 LIMIT 1，可以停止全表扫描 处理分页会使用到 LIMIT ，当翻页到非常靠后的页面的时候，偏移量会非常大，这时LIMIT的效率 会非常差。LIMIT OFFSET , SIZE； LIMIT的优化问题，其实是 OFFSET 的问题，它会导致MySql扫描大量不需要的行然后再抛弃掉。解决方案：单表分页时，使用自增主键排序之后，先使用where条件 id &gt; offset值，limit后面只写 rows 3. 其他查询优化小表驱动大表, 在 left join 时, 小的表应该为基准表, 外联大表 避免全表扫描, mysql在使用不等于(!=或者&lt;&gt;)的时候无法使用索引导致全表扫描。 尽量使用count（主键） JOIN条件的两表的字段最好加上索引 WHERE条件中尽量不要使用not in语句（建议使用not exists） 参考的文章1 参考的文章2","path":"2022/03/22/数据库/慢查询/"},{"title":"2pc 和3pc 协议","text":"2pc主要分为两阶段 设计出发点为了允许任何一个参与者自行放弃他自己的那部分事务。 第一阶段：参与者投票表决事务放弃还是提交事务T（就是准没准备好提交事务）。如果提交事务，就回复协调者YES T,否则，就回复 abort，同时记录到日志中。同时为了保证提交，必须将事务所有日志记录保存到持久性存储中。 第二阶段：协调者决定是否提交事务，如果有一个参与者放弃事务，那么最终放弃事务。如果所有参与者投票提交事务，那么最终提交事务，同时将结果保存到持久性存储中。 如果参与者发生故障，会检查参与者发生故障的时期。 1.如果在回答YES T消息之前进入故障，那么协调者假定参与者回答的是abort T. 2.如果在回答YES T消息之后进入故障，那么协调者就按照通常方式执行协议的剩余部分，忽略该站点故障。 如果参与者S从故障中恢复，那么就检查日志来决定 1）如果包含commit T,参与者执行redo（T） 2）如果包含abort T,参与者执行undo（T） 3）如果包含YES T,就询问协调者事务T的最终结果，如果协调者故障，那么就向其他参与者询问T是否提交或者放弃。如果没有得到信息，那么就定期询问其他参与者，会占据大量资源。 如果协调者发生故障，就必须检查参与者来决定事务T的结果 1.如果活跃的参与者日志中包含commit T，那么事务T提交。 2.如果活跃的参与者日志中包含abort T，那么事务T放弃。 3.如果有活跃参与者日志中没有YES T,那么就放弃T。 如果均不成立，那么就必须等待协调者恢复，因此事务T会占据大量资源，这种情况被成为阻塞问题。 引入 超时机制 和 互询机制 在很大程度上予以解决。 协调者来说如果在指定时间内没有收到所有参与者的应答，则可以自动退出 等待 状态，并向所有参与者发送 放弃事务 通知。对于参与者来说如果位于 READY 状态，但是在指定时间内没有收到协调者的第二阶段通知，则不能武断地执行 放弃事务 操作，因为协调者可能发送的是 commit 通知，这个时候执行 放弃事务 就会导致数据不一致。此时，我们可以介入互询机制，让参与者 A 去询问其他参与者 B 的执行情况。如果 B 执行了 放弃事务 或 commit 操作，则 A 可以大胆的与 B 执行相同的操作；如果 B 此时还没有到达 准备 状态，则可以进行放弃事务；如果 B 同样位于 准备 状态，则 A 可以继续询问另外的参与者。只有当所有的参与者都位于 准备 状态时，此时两阶段提交协议无法处理，将陷入长时间的阻塞状态。 3pc针对两阶段提交存在的问题，三阶段提交协议通过引入一个 预询盘 阶段，以及超时策略来减少整个集群的阻塞时间，提升系统性能。 第一阶段：CanCommit协调者向各个参与者发送事务询问通知，询问是否可以执行事务操作，并等待回复；各个参与者依据自身状况回复一个预估值，如果预估自己能够正常执行事务就返回确定信息，并进入预备状态，否则返回否定信息。 第二阶段 预提交 precommit执行事务预提交：如果 协调者 接收到各参与者反馈都是Yes，那么执行事务预提交： 1.发送预提交请求：协调者 向各参与者发送 preCommit 请求，并进入 prepared 阶段； 2.事务预提交：参与者接收到 preCommit 请求后，会执行事务操作，但不提交； 3.各参与者向协调者反馈事务执行的响应：如果各参与者都成功执行了事务操作，那么反馈给协调者 ACK 响应，同时等待最终指令，提交 commit 或者终止 abort，结束流程； 第二阶段 预提交中断事务：如果任何一个参与者向 协调者 反馈了 No 响应，或者在等待超时后，协调者 无法接收到所有参与者的反馈，那么就会中断事务。发送中断请求：协调者 向所有参与者发送 abort 请求；中断事务：无论是收到来自 协调者 的 abort 请求，还是等待超时，参与者都中断事务。 第三阶段事务提交 docommit如果第二阶段事务未中断，那么本阶段协调者将会依据事务执行返回的结果来决定提交或回滚事务，分为 3 种情况： 所有的参与者都能正常执行事务。 一个或多个参与者执行事务失败。 协调者等待超时。 针对第 1 种情况，协调者向各个参与者发起事务提交请求，具体步骤如下：协调者向所有参与者发送事务 commit 通知；所有参与者在收到通知之后执行 commit 操作，并释放占有的资源；参与者向协调者反馈事务提交结果。 针对第 2 和第 3 种情况，协调者认为事务无法成功执行，于是向各个参与者发送事务回滚请求，具体步骤如下：协调者向所有参与者发送事务 rollback 通知；所有参与者在收到通知之后执行 rollback 操作，并释放占有的资源；参与者向协调者反馈事务回滚结果。 3PC最关键要解决的就是2PC中协调者和参与者同时挂掉的问题在本阶段如果因为协调者或网络问题，导致参与者迟迟不能收到来自协调者的 commit 或 rollback 请求，那么参与者将不会如两阶段提交中那样陷入阻塞，而是等待超时后继续 commit，相对于两阶段提交虽然降低了同步阻塞，但仍然无法完全避免数据的不一致。 当进入第三阶段时，说明参与者在第二阶段已经收到了PreCommit请求，那么Coordinator产生PreCommit请求的前提条件是他在第二阶段开始之前，收到所有参与者的CanCommit响应都是Yes。一旦参与者收到了PreCommit，意味他知道大家其实都同意修改了。 3PC存在的问题在doCommit阶段，如果参与者无法及时接收到来自协调者的doCommit或者rebort请求时，会在等待超时之后，会继续进行事务的提交。所以，由于网络原因，协调者发送的abort响应没有及时被参与者接收到，那么参与者在等待超时之后执行了commit操作。这样就和其他接到abort命令并执行回滚的参与者之间存在数据不一致的情况。 如果在precommit过程中协调者和部分参与者宕机了，大可以回滚事务，不会造成不一致的问题，但是在docommit过程中，还是有可能不一致的，只是说我们一开始cancommit问了，大家认为可以做，大概率是可以的，但是实际上还是有可能发生的是abort，同时协调者宕机，参与者一部分宕机，产生不一致问题。 TCCTCC 指的就是 Try、Confirm、Cancel 三个操作，基本类似两阶段提交。由事务管理方发起向所有参与者发起 try 请求，根据 try 请求的结果决定全部 confirm 或是全部 cancel。 Try阶段： 完成所有业务逻辑的检查，预留必要的业务资源（比如下单操作先在库存服务中冻结预留需要的数量）并提交事务 Confirm阶段： 执行真正业务，不做任何业务检查，Confirm 阶段应该满足幂等性，Confirm 失败后应该需要进行重试（对预处理的数据做正式处理） Cancel阶段： 取消执行，释放 Try 阶段预留的业务资源，该阶段也应该满足幂等性（回滚预留资源） 有点类似2PC任务 https://matt33.com/2018/07/08/distribute-system-consistency-protocol/","path":"2022/03/22/分布式/2pc3pc协议/"},{"title":"lsm树","text":"日志结构合并树LSM树（Log-Structured Merge Tree）存储引擎代表数据库：nessDB、leveldb、hbase等 核心思想的核心就是放弃部分读能力，换取写入的最大化能力。LSM Tree ，这个概念就是结构化合并树的意思，它的核心思路其实非常简单，就是假定内存足够大，因此不需要每次有数据更新就必须将数据写入到磁盘中，而可以先将最新的数据驻留在磁盘中，等到积累到最后多之后，再使用归并排序的方式将内存内的数据合并追加到磁盘队尾(因为所有待排序的树都是有序的，可以通过合并排序的方式快速合并到一起)。 日志结构的合并树（LSM-tree）是一种基于硬盘的数据结构，与B-tree相比，能显著地减少硬盘磁盘臂的开销，并能在较长的时间提供对文件的高速插入（删除）。然而LSM-tree在某些情况下，特别是在查询需要快速响应时性能不佳。通常LSM-tree适用于索引插入比检索更频繁的应用系统。Bigtable在提供Tablet服务时，使用GFS来存储日志和SSTable，而GFS的设计初衷就是希望通过添加新数据的方式而不是通过重写旧数据的方式来修改文件。而LSM-tree通过滚动合并和多页块的方法推迟和批量进行索引更新，充分利用内存来存储近期或常用数据以降低查找代价，利用硬盘来存储不常用数据以减少存储代价。 磁盘的技术特性:对磁盘来说，能够最大化的发挥磁盘技术特性的使用方式是:一次性的读取或写入固定大小的一块数据，并尽可能的减少随机寻道这个操作的次数。 1 B+树相信大家对B+树已经非常的熟悉，比如Oracle的普通索引就是采用B+树的方式，下面是一个B+树的例子： 根节点和枝节点很简单，分别记录每个叶子节点的最小值，并用一个指针指向叶子节点。 叶子节点里每个键值都指向真正的数据块（如Oracle里的RowID），每个叶子节点都有前指针和后指针，这是为了做范围查询时，叶子节点间可以直接跳转，从而避免再去回溯至枝和跟节点。 B+树最大的性能问题是会产生大量的随机IO，随着新数据的插入，叶子节点会慢慢分裂，逻辑上连续的叶子节点在物理上往往不连续，甚至分离的很远，但做范围查询时，会产生大量读随机IO。 对于大量的随机写也一样，举一个插入key跨度很大的例子，如7-&gt;1000-&gt;3-&gt;2000 … 新插入的数据存储在磁盘上相隔很远，会产生大量的随机写IO. 从上面可以看出，低下的磁盘寻道速度严重影响性能（近些年来，磁盘寻道速度的发展几乎处于停滞的状态）。 2 LSM树为了克服B+树的弱点，HBase引入了LSM树的概念，即Log-Structured Merge-Trees。 为了更好的说明LSM树的原理，下面举个比较极端的例子： 现在假设有1000个节点的随机key，对于磁盘来说，肯定是把这1000个节点顺序写入磁盘最快，但是这样一来，读就悲剧了，因为key在磁盘中完全无序，每次读取都要全扫描； 那么，为了让读性能尽量高，数据在磁盘中必须得有序，这就是B+树的原理，但是写就悲剧了，因为会产生大量的随机IO，磁盘寻道速度跟不上。 LSM树本质上就是在读写之间取得平衡，和B+树相比，它牺牲了部分读性能，用来大幅提高写性能。 它的原理是把一颗大树拆分成N棵小树， 它首先写入到内存中（内存没有寻道速度的问题，随机写的性能得到大幅提升），在内存中构建一颗有序小树，随着小树越来越大，内存的小树会flush到磁盘上。当读时，由于不知道数据在哪棵小树上，因此必须遍历所有的小树，但在每颗小树内部数据是有序的。 以上就是LSM树最本质的原理，有了原理，再看具体的技术就很简单了。1）首先说说为什么要有WAL（Write Ahead Log），很简单，因为数据是先写到内存中，如果断电，内存中的数据会丢失，因此为了保护内存中的数据，需要在磁盘上先记录logfile，当内存中的数据flush到磁盘上时，就可以抛弃相应的Logfile。 2）什么是memstore, storefile？很简单，上面说过，LSM树就是一堆小树，在内存中的小树即memstore，每次flush，内存中的memstore变成磁盘上一个新的storefile。 3）为什么会有compact？很简单，随着小树越来越多，读的性能会越来越差，因此需要在适当的时候，对磁盘中的小树进行merge，多棵小树变成一颗大树。 关于LSM Tree，对于最简单的二层LSM Tree而言，下面说说详细例子: LSM Tree弄了很多个小的有序结构，比如每m个数据，在内存里排序一次，下面100个数据，再排序一次……这样依次做下去，就可以获得N/m个有序的小的有序结构。 在查询的时候，因为不知道这个数据到底是在哪里，所以就从最新的一个小的有序结构里做二分查找，找得到就返回，找不到就继续找下一个小有序结构，一直到找到为止。 很容易可以看出，这样的模式，读取的时间复杂度是(N/m)*log2N 。读取效率是会下降的。 这就是最本来意义上的LSM tree的思路。那么这样做，性能还是比较慢的，于是需要再做些事情来提升，怎么做才好呢？ LSM Tree优化方式：a、Bloom filter: 就是个带随即概率的bitmap,可以快速的告诉你，某一个小的有序结构里有没有指定的那个数据的。于是就可以不用二分查找，而只需简单的计算几次就能知道数据是否在某个小集合里啦。效率得到了提升，但付出的是空间代价。 b、compact:小树合并为大树:因为小树他性能有问题，所以要有个进程不断地将小树合并到大树上，这样大部分的老数据查询也可以直接使用log2N的方式找到，不需要再进行(N/m)*log2n的查询了 可以参考github这篇文章lsm树 可以参考博客园这篇文章lsm树 都看下差不多就懂了","path":"2022/03/21/数据库/lsm树/"},{"title":"C++并发编程（如何使用thread）","text":"参考链接http://shouce.jb51.net/cpp_concurrency_in_action/content/chapter2/2.4-chinese.html 创建线程#include&lt;thread&gt; void fun()&#123;&#125;; std::thread m(fun); 线程分为加入式，或者分离式 加入是join（） m.join();阻塞线程，直到线程返回 m.detach() detach 在主线程结束但是分线程没结束得时候可能会导致引用不存在得变量得情况。 如果线程产生异常可以使用 try &#123; do_something_in_current_thread(); &#125; catch(...) &#123; t.join(); // 1 throw; &#125; t.join(); // 2 如果使用RAII得方式 class thread_guard &#123; std::thread&amp; t; public: explicit thread_guard(std::thread&amp; t_): t(t_) &#123;&#125; ~thread_guard() &#123; if(t.joinable()) // 1 &#123; t.join(); // 2 &#125; &#125; thread_guard(thread_guard const&amp;)=delete; // 3 thread_guard&amp; operator=(thread_guard const&amp;)=delete; &#125;; 在thread_guard的析构函数的测试中，首先判断线程是否已加入1，如果没有会调用join()2进行加入。这很重要，因为join()只能对给定的对象调用一次，所以对给已加入的线程再次进行加入操作时，将会导致错误。 线程传参thread 在向线程传递参数得时候，默认是拷贝到线程中得，即使它是引用传递。传递给函数的参数是data变量内部拷贝的引用，而非数据本身的引用。 如果一定要使用引用，使用std::ref 每个实例都负责管理一个执行线程。执行线程的所有权可以在多个std::thread实例中互相转移，这是依赖于std::thread实例的可移动且不可复制性。不可复制保性证了在同一时间点，一个std::thread实例只能关联一个执行线程；可移动性使得程序员可以自己决定，哪个实例拥有实际执行线程的所有权。 这个与unique_prt相似 std::thread t1(some_function); // 1 std::thread t2=std::move(t1); // 2 产生一批线程，然后等待void f() &#123; std::vector&lt;std::thread&gt; threads; for(unsigned i=0; i &lt; 20; ++i) &#123; threads.push_back(std::thread(do_work,i)); // 产生线程 &#125; std::for_each(threads.begin(),threads.end(), std::mem_fn(&amp;std::thread::join)); // 对每个线程调用join() //mem_fn把成员函数转为函数对象，使用对象指针进行绑定 &#125; 获取支持得线程数目std::thread::hardware_concurrency()在新版C++标准库中是一个很有用的函数。这个函数将返回能同时并发在一个程序中的线程数量。 获取线程IDstd::thread::id std::this_thread::get_id() 或者thread.get_id() 线程间共享数据使用互斥量std::mutex创建互斥量 lock()进行上锁，unlock()进行解锁 C++标准库为互斥量提供了一个RAII语法的模板类std::lock_guard，其会在构造的时候提供已锁的互斥量，并在析构的时候进行解锁 要避免成员函数通过返回值或者输出参数的形式向其调用者返回指向受保护数据的指针或引用 std::lock——可以一次性锁住多个(两个以上)的互斥量，并且没有副作用(死锁风险) std::unique_lock——灵活的锁&lt;!—hexoPostRenderEscape:简单地讲，unique_lock 是 lock_guard 的升级加强版，它具有 lock_guard 的所有功能，同时又具有其他很多方法，使用起来更强灵活方便，能够应对更复杂的锁定需要。 特点如下： 创建时可以不锁定（通过指定第二个参数为std::defer_lock），而在需要时再锁定可以随时加锁解锁作用域规则同 lock_grard，析构时自动释放锁不可复制，可移动条件变量需要该类型的锁作为参数（此时必须使用unique_lock）&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; lock_guard&lt;!—hexoPostRenderEscape:lock_guard是一个互斥量包装程序，它提供了一种方便的RAII（Resource acquisition is initialization ）风格的机制来在作用域块的持续时间内拥有一个互斥量。 创建lock_guard对象时，它将尝试获取提供给它的互斥锁的所有权。当控制流离开lock_guard对象的作用域时，lock_guard析构并释放互斥量。 它的特点如下： 创建即加锁，作用域结束自动析构并解锁，无需手工解锁不能中途解锁，必须等作用域结束才解锁不能复制&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2022/03/11/C++/C++并发编程/并发编程c++/"},{"title":"C++并发编程","text":"在leetcode里面最常用得就是mutex，互斥量加锁，C++11要求由同一个线程来对一个 mutex 对象进行 lock 和 unlock 操作，不然是未定义得行为 然后还有一种是需要A线程做了某事情，然后b需要某些条件才可以做，可以使用互斥量加条件变量 class H2O &#123; private: std::mutex m; std::condition_variable cv; int h=0; public: H2O() &#123; &#125; void hydrogen(function&lt;void()&gt; releaseHydrogen) &#123; unique_lock&lt;mutex&gt; lk(m); cv.wait(lk,[&amp;]&#123;return h&lt;2;&#125;);//这个是当h&lt;2，返回true，继续执行，如果返回得是false，那么释放锁，阻塞，直到被唤醒 releaseHydrogen(); h++; cv.notify_all(); // releaseHydrogen() outputs &quot;H&quot;. Do not change or remove this line. &#125; void oxygen(function&lt;void()&gt; releaseOxygen) &#123; unique_lock&lt;mutex&gt; lk(m); cv.wait(lk,[&amp;]&#123;return h==2;&#125;); releaseOxygen(); h=0; cv.notify_all(); // releaseOxygen() outputs &quot;O&quot;. Do not change or remove this line. &#125; &#125;; 还有一种是信号量得写法 #include &lt;semaphore.h&gt; class H2O &#123; sem_t s1, s2; int state = 0; public: H2O() &#123; sem_init(&amp;s1, 0, 2);//0代表共享，2为初始值 sem_init(&amp;s2, 0, 0); // sem_post(&amp;s1); &#125; void hydrogen(function&lt;void()&gt; releaseHydrogen) &#123; sem_wait(&amp;s1);//信号量-1，如果小于等于0就阻塞 state++; // releaseHydrogen() outputs &quot;H&quot;. Do not change or remove this line. releaseHydrogen(); if (state == 2) &#123; sem_post(&amp;s2);//信号量+1 &#125; &#125; void oxygen(function&lt;void()&gt; releaseOxygen) &#123; sem_wait(&amp;s2); // releaseOxygen() outputs &quot;O&quot;. Do not change or remove this line. releaseOxygen(); state = 0; sem_post(&amp;s1); sem_post(&amp;s1); &#125; &#125;; 使用原子操作&lt;!—hexoPostRenderEscape:class Foo &lt;/span&gt;&#123; std::atomic&lt;bool&gt; a&#123; false &#125;; std::atomic&lt;bool&gt; b&#123; false &#125;;public: void first(function&lt;void(&lt;/span&gt;)&gt; printFirst) &lt;/span&gt;&#123; printFirst(); a = true; &#125; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; second(&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;function&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;void&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;/span&gt;)&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;printSecond&lt;/span&gt;) &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (!a) this_thread::sleep_for(chrono::milliseconds(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)); printSecond(); b = &lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; third(&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;function&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;void&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;/span&gt;)&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;printThird&lt;/span&gt;) &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (!b) this_thread::sleep_for(chrono::milliseconds(&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)); printThird(); &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;future 使用&lt;!—hexoPostRenderEscape:class Foo &lt;/span&gt;&#123; promise&lt;void&gt; pro1, pro2; public: void first(function&lt;void(&lt;/span&gt;)&gt; printFirst) &lt;/span&gt;&#123; printFirst(); pro1.set_value(); &#125; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; second(&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;function&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;void&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;/span&gt;)&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;printSecond&lt;/span&gt;) &lt;/span&gt;&amp;#123; pro1.get_future().wait();&lt;span class=&quot;hljs-comment&quot;&gt;//等待set传入得数，否则阻塞&lt;/span&gt; printSecond(); pro2.set_value(); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; third(&lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;function&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-title&quot;&gt;void&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;/span&gt;)&amp;gt; &lt;span class=&quot;hljs-title&quot;&gt;printThird&lt;/span&gt;) &lt;/span&gt;&amp;#123; pro2.get_future().wait(); printThird(); &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2022/03/11/C++/C++并发编程/并发编程leetcode/"},{"title":"并发编程（读者写者问题，生产者消费者问题，哲学家进餐问题代码及思路）","text":"信号量、原子变量、条件变量、异步可以参考写法 信号量C++的信号量在c++20才有，但是我们可以使用c++的条件变量和锁实现信号量。 class semaphore &#123; private: int count; mutex mu; condition_variable cv; public: semaphore(int val) :count(val) &#123;&#125; //想去获取一把锁，计数值减一之后如果还小于0，说明之前为0，数量不够，等待。 void P() &#123; unique_lock&lt;mutex&gt; lck(mu); count--; if (count &lt; 0) &#123; cv.wait(lck); &#125; &#125; //添加一把锁，如果添加之后总数小于等于0，说明有人等待锁，唤醒一个 void V() &#123; unique_lock&lt;mutex&gt; lck(mu); count++; if (count &lt;= 0) &#123; cv.notify_one(); &#125; &#125; //注意这两种主要在于P操作是while或者if，这是取决于一次通知一个还是一次全部唤醒 void P() &#123; unique_lock&lt;mutex&gt; lck(mu); while (count&lt;=0) &#123; cv.wait(lck); &#125; count--; &#125; //添加一把锁，如果添加之后总数小于等于0，说明有人等待锁，唤醒一个 void V() &#123; unique_lock&lt;mutex&gt; lck(mu); count++; if (count&lt;=0) &#123; cv.notify_all(); &#125; &#125; &#125;; 基于并发进程的并发编程当父进程接受客户端的连接请求的时候,创建新的子进程为客户服务,这个需要注意的是,子进程会继承父进程文件描述符的副本,因此都指向同一个文件表的表项,因此需要父进程关闭他的连接描述符的副本,然后子进程需要关闭listen socket的副本,然后开始服务,服务完了关闭连接描述符的副本. 在linux中文件表是引用计数的,因此父进程关闭文件描述符,不会影响子进程 IO多路复用技术可以参考select,poll,epoll那一篇. 基于线程的并发线程有自己的栈,寄存器,程序计数器,线程ID,与其他线程共享虚拟地址空间. 主要区别是join和detach的区别. join会阻塞直到线程返回,需要被其他线程回收. detach不能被其他线程回收,内存资源在终止的时候由系统自动释放. 多线程的共享变量需要同步互斥,使用信号量. 经典的比如说是生产者消费者问题它由三个信号量,一个mutex用来设置互斥访问的,一个是itemm,empty,分别是有多少东西,有多少空位 该类问题要注意对缓冲区大小为n的处理，当缓冲区中有空时便可对empty变量执行P 操作，一旦取走一个产品便要执行V操作以释放空闲区。对empty和full变量的P操作必须放在对mutex的P操作之前。如果生产者进程先执行P(mutex)，然后执行P(empty)，消费者执行P(mutex),然后执行P(fall),这样可不可以？答案是否定的。设想生产者进程已经将缓冲区放满，消费者进程并没有取产品，即empty = 0，当下次仍然是生产者进程运行时，它先执行P(mutex)封锁信号量，再执行P(empty)时将被阻塞，希望消费者取出产品后将其唤醒。轮到消费者进程运行时，它先执行P(mutex)，然而由于生产者进程已经封锁mutex信号量，消费者进程也会被阻塞，这样一来生产者、消费者进程都将阻塞，都指望对方唤醒自己，陷入了无休止的等待。同理，如果消费者进程已经将缓冲区取空，即 full = 0,下次如果还是消费者先运行，也会出现类似的死锁。不过生产者释放信号量时，mutex、full先释放哪一个无所谓，消费者先释放mutex还是empty都可以。 生产者: while(1) &#123; P(empty); P(mutex); 插入 V(mutex); V(itemm); &#125; -- 消费者: while(1) &#123; P(itemm) P(mutex); 删除 V(mutex); V(empty); &#125; 读者写者问题-读者优先:算法中，读进程是优先的，也就是说，当存在读进程时，写操作将被延迟，并且只要有一个读进程活跃，随后而来的读进程都将被允许访问文件。int count=0; //用于记录当前的读者数量 semaphore mutex=1; //用于保护更新count变量时的互斥 semaphore rw=1; //用于保证读者和写者互斥地访问文件 writer () &#123; //写者进程 while (1)&#123; P(rw); // 互斥访问共享文件 Writing; //写入 V(rw) ; //释放共享文件 &#125; &#125; reader () &#123; // 读者进程 while(1)&#123; P (mutex) ; //互斥访问count变量 if (count==0) //当第一个读进程读共享文件时 P(rw); //阻止写进程写 count++; //读者计数器加1 V (mutex) ; //释放互斥变量count reading; //读取 P (mutex) ; //互斥访问count变量 count--; //读者计数器减1 if (count==0) //当最后一个读进程读完共享文件 V(rw) ; //允许写进程写 V (mutex) ; //释放互斥变量 count &#125; &#125; 读者写者问题-写者优先如果希望写进程优先，即当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等待到已在共享文件的读进程执行完毕则立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。&lt;!—hexoPostRenderEscape:int count = 0; //用于记录当前的读者数量semaphore mutex = 1; //用于保护更新count变量时的互斥semaphore rw=1; //用于保证读者和写者互斥地访问文件semaphore w=1; //用于实现“写优先”writer()&#123; while(1)&#123; P(w_wait)&lt;/span&gt;; if(w_wait_num==0) &#123; P(read_mu)&lt;/span&gt;; &#125; w_wait_num++; V(w_wait)&lt;/span&gt;; &lt;span class=&quot;hljs-constructor&quot;&gt;P(&lt;span class=&quot;hljs-params&quot;&gt;write_mmu&lt;/span&gt;)&lt;/span&gt;; 写。。。 &lt;span class=&quot;hljs-constructor&quot;&gt;V(&lt;span class=&quot;hljs-params&quot;&gt;write_mu&lt;/span&gt;)&lt;/span&gt;; &lt;span class=&quot;hljs-constructor&quot;&gt;P(&lt;span class=&quot;hljs-params&quot;&gt;w_wait&lt;/span&gt;)&lt;/span&gt;; w_wait_num--; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(w_wait_num==&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &amp;#123; &lt;span class=&quot;hljs-constructor&quot;&gt;V(&lt;span class=&quot;hljs-params&quot;&gt;read_mu&lt;/span&gt;)&lt;/span&gt;; &amp;#125; &lt;span class=&quot;hljs-constructor&quot;&gt;V(&lt;span class=&quot;hljs-params&quot;&gt;w_wait&lt;/span&gt;)&lt;/span&gt;; &amp;#125; &#125;reader () &#123; //读者进程 while (1)&#123; P(read_mu)&lt;/span&gt;; 读。。。。 V(read_mu)&lt;/span&gt;; &#125;&#125;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 哲学家进餐问题为了防止死锁的发生，可以对哲学家进程施加一些限制条件，比如至多允许四个哲学家同时进餐;仅当一个哲学家左右两边的筷子都可用时才允许他抓起筷子;对哲学家顺序编号，要求奇数号哲学家先抓左边的筷子，然后再转他右边的筷子，而偶数号哲学家刚好相反。正解制定规则如下：假设釆用第二种方法，当一个哲学家左右两边的筷子都可用时，才允许他抓起筷子。semaphore chopstick[5] = &#123;1,1,1,1,1&#125;; //初始化信号量 semaphore mutex=l; //设置取筷子的信号量 Pi()&#123; //i号哲学家的进程 do&#123; P (mutex) ; //在取筷子前获得互斥量 P (chopstick [i]) ; //取左边筷子 P (chopstick[ (i+1) %5]) ; //取右边筷子 V (mutex) ; //释放取筷子的信号量 eat; //进餐 V(chopstick[i] ) ; //放回左边筷子 V(chopstick[ (i+l)%5]) ; //放回右边筷子 think; // 思考 &#125;while(1); &#125; 注意rand函数是线程不安全的,因为它依赖于之前一次的调用结果. 可重入性:当其被多个线程调用的时候,不会引用共享数据.可重入函数是线程安全函数的真子集. 死锁也需要注意生产者消费者问题的写法#include&lt;iostream&gt; #include&lt;thread&gt; #include&lt;mutex&gt; #include&lt;condition_variable&gt; #include&lt;semaphore&gt; #include&lt;queue&gt; using namespace std; mutex mu; condition_variable cv_empty, cv_full; int PV_empty = 5,PV_full=0; mutex mu_empty, mu_full; queue&lt;int&gt; qu; void cosume() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu_full); while (PV_full &lt;= 0) &#123; cv_full.wait(lck); &#125; PV_full--; unique_lock&lt;mutex&gt; lck_mu(mu); qu.pop(); cout &lt;&lt; &quot;consume &quot; &lt;&lt; qu.size() &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; lck_mu.unlock(); PV_empty++; if (PV_empty &lt;= 0) &#123; cv_empty.notify_all(); &#125; &#125; &#125; void produce() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu_empty); while (PV_empty &lt;= 0) &#123; cv_empty.wait(lck); &#125; PV_empty--; unique_lock&lt;mutex&gt; lck_mu(mu); qu.push(1); cout &lt;&lt; &quot;produce &quot; &lt;&lt; qu.size() &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; lck_mu.unlock(); PV_full++; if (PV_full &lt;= 0) &#123; cv_full.notify_all(); &#125; &#125; &#125; int main() &#123; const int maxConsumNum = 2; thread consumer[maxConsumNum], producer[maxConsumNum]; for (int i = 0; i &lt; maxConsumNum; ++i) &#123; consumer[i] = thread(cosume); producer[i] = thread(produce); &#125; for (int i = 0; i &lt; maxConsumNum; ++i) &#123; consumer[i].join(); producer[i].join(); &#125; cout &lt;&lt; &quot;end\\n&quot;; getchar(); getchar(); return 0; &#125; 读者写者问题-读者优先#include&lt;iostream&gt; #include&lt;thread&gt; #include&lt;mutex&gt; #include&lt;condition_variable&gt; #include&lt;semaphore&gt; #include&lt;queue&gt; using namespace std; mutex mu; mutex w_mu; condition_variable cv_write; int readcount = 0; int writecount = 0; int PVcount = 1; queue&lt;int&gt; qu; void write() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(w_mu); cout &lt;&lt; &quot;start write &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; PVcount--; if (PVcount &lt; 0) &#123; cv_write.wait(lck); &#125; PVcount++; if (PVcount &lt;= 0) &#123; cv_write.notify_one(); &#125; cout &lt;&lt; &quot;write &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; lck.unlock(); &#125; &#125; void read() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu); cout &lt;&lt; &quot;start read &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; if (readcount == 0) &#123; PVcount--; if (PVcount &lt; 0) &#123; cv_write.wait(lck); &#125; &#125; readcount++; lck.unlock(); cout&lt;&lt;&quot;read &quot;&lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; lck.lock(); readcount--; if (readcount == 0) &#123; PVcount++; if (PVcount &lt;=0) &#123; cv_write.notify_one(); &#125; &#125; lck.unlock(); &#125; &#125; int main() &#123; const int maxNum = 2; thread writer[maxNum], reader[maxNum]; for (int i = 0; i &lt; maxNum; ++i) &#123; writer[i] = thread(write); reader[i] = thread(read); &#125; for (int i = 0; i &lt; maxNum; ++i) &#123; writer[i].join(); reader[i].join(); &#125; cout &lt;&lt; &quot;end\\n&quot;; getchar(); getchar(); return 0; &#125; 读者写者问题-写者优先#include&lt;iostream&gt; #include&lt;thread&gt; #include&lt;mutex&gt; #include&lt;condition_variable&gt; #include&lt;semaphore&gt; #include&lt;queue&gt; using namespace std; mutex mu; mutex w_mu; condition_variable cv_read, cv_write; int readcount = 0; int writecount = 0; mutex mu_wait_write; int waitWrite = 0; int PVcount = 1;//用于和条件变量互斥量当信号量使用 void write() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu_wait_write); cout &lt;&lt; &quot; start write &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; if (waitWrite == 0) &#123; PVcount--; if (PVcount &lt; 0) &#123; cv_read.wait(lck); &#125; &#125; waitWrite++; lck.unlock(); unique_lock&lt;mutex&gt; lck_w(w_mu); cout &lt;&lt; &quot; write &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; lck_w.unlock(); lck.lock(); waitWrite--; if (waitWrite == 0) &#123; PVcount++; if (PVcount &lt;= 0) &#123; cv_read.notify_one(); &#125; &#125; lck.unlock(); &#125; &#125; void read() &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu); cout &lt;&lt; &quot; start read &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; PVcount--; if (PVcount &lt; 0) &#123; cv_read.wait(lck); &#125; cout &lt;&lt; &quot;read &quot; &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; &quot;\\n&quot;; PVcount++; if (PVcount &lt;= 0) &#123; cv_read.notify_one(); &#125; &#125; &#125; 哲学家进餐问题#include&lt;iostream&gt; #include&lt;thread&gt; #include&lt;mutex&gt; #include&lt;condition_variable&gt; #include&lt;semaphore&gt; #include&lt;queue&gt; using namespace std; mutex chopstick[5]; int PVcount[5] &#123; 1,1,1,1,1 &#125;; condition_variable cv_pho[5]; mutex mu; void eat(int i) &#123; while (true) &#123; this_thread::sleep_for(chrono::milliseconds(900)); unique_lock&lt;mutex&gt; lck(mu); cout &lt;&lt; &quot; start eat &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; while (PVcount[i] &lt;= 0) &#123; cv_pho[i].wait(lck); &#125; PVcount[i]--; while (PVcount[(i + 1)%5] &lt;= 0) &#123; cv_pho[(i + 1) % 5].wait(lck); &#125; PVcount[(i + 1) % 5]--; lck.unlock(); cout &lt;&lt; &quot; eat &quot; &lt;&lt; i &lt;&lt; &quot; &quot; &lt;&lt; this_thread::get_id() &lt;&lt; endl; lck.lock(); PVcount[i]++; if (PVcount[i] &lt;= 0) &#123; cv_pho[i].notify_all(); &#125; PVcount[(i + 1) % 5]++; while (PVcount[(i + 1) % 5] &lt;= 0) &#123; cv_pho[(i + 1) % 5].notify_all(); &#125; lck.unlock(); &#125; &#125; int main() &#123; const int maxNum =5; thread phisopher[maxNum]; for (int i = 0; i &lt; maxNum; ++i) &#123; phisopher[i] = thread(eat,i); &#125; for (int i = 0; i &lt; maxNum; ++i) &#123; phisopher[i].join(); &#125; cout &lt;&lt; &quot;end\\n&quot;; getchar(); getchar(); return 0; &#125;","path":"2022/03/07/操作系统/并发编程/"},{"title":"异常控制流","text":"当有异常发生的时候，会通过一张异常表的跳转表来进行一个间接异常调用，到操作系统专门用来处理这种异常的异常处理程序中。 异常表的起始地址放在一个叫做异常表基址寄存器的特殊CPU寄存器中。 异常处理程序运行在内核模式下，因此对所有资源都有完全的访问权限。 异常的类别：中断，陷阱，故障，终止 中断 来自IO设备的信号，异步处理，总是返回下一条指令 陷阱，有意的异常，同步，总是返回下一条指令，陷阱的重要用途在于系统调用，与普通函数调用的区别在于，他是运行在内核模式下的。 故障，潜在可恢复的错误，同步，可能返回当前指令，经典的是缺页异常 终止，不可恢复的错误，同步，不会返回 内核模式与用户模式处理器通常用某个控制寄存器的模式位来提供进入内核模式的功能 从用户态变为内核态的唯一方法是异常 上下文切换操作系统使用上下文切换的异常控制流来实现多任务 上下文信息包括，程序计数器，寄存器，内核栈，内核数据结构，比如地址空间的页表，当前进程信息的进程表，已打开文件的文件表。 fork创建新的子进程，不完全与父进程相同，他们有相同的堆栈，代码段数据段，相同的打开文件描述符的副本，因此子进程可以读写父进程的任何文件，但是他们有不同的PID。 fork调用一次，返回两次，返回0，说明在子进程中，在父进程中返回子进程的PID。 父进程和子进程是并发执行的，相同的但是独立的地址空间，因为继承了文件描述符的副本，如果父进程写stdout，那么子进程也可以输出。 注意fork与execve的区别，fork创建父进程的复制品，有不同的pid，execve加载执行程序，他们有着相同的PID，新程序会覆盖当前进程的地址空间，没有创建新的进程。 回收子进程进程终止的时候是由父进程回收的，父进程是由内核指定的init进程（PID=1）回收的。 当父进程回收子进程时，内核将子进程的退出状态传给父进程，然后子进程被完全抛弃。 终止了但是还没回收的进程为僵尸进程。 waitpid可以等待子进程终止或者停止。 非本地跳转C语言提供的用户级的异常控制流形式，称为非本地跳转。通过setjmp和longjmp实现。 两者是配合使用的，setjmp在env缓冲区中保存当前调用环境吗，供longjmp使用。返回0，调用环境包括程序计数器，栈指针，通用目的寄存器。其返回值不能被赋值给变量。不过可以用在switch和if中。 longjmp从env缓冲区恢复调用环境，然后触发一次最近的初始化env的setjmp的返回 注意setjmp调用一次返回多次,longjmp从不返回. C++和java的异常机制是setjmp和longjmp更加结构化的版本,可以将catch认为setjmp,throw认为是longjmp. linux的几个命令ps,列出当前系统的进程 top,打印当前进程资源的使用PMAP 显示进程的内存映射. /proc 一个虚拟文件系统,以ASCII输出大量内核数据结构内容,用户可以读取这些内容,比如cat /proc/loadavg 信号linux信号允许进程和内核中断其他的进程, 信号使用主要分为发送信号和接收信号 发送信号:内核检测到上下文信息发送信号给目的进程 接收信号,目的进程被内核强迫对信号的发送做出反应,就接收了信号.如果忽略这个信号或者终止或者执行信号处理程序的用户层函数捕捉信号. 发出而没有被接收的称为待处理的信号,任何情况,一种类型都只会有一个待处理的信号.超过1的都会被丢弃. 如果进程阻塞某个信号,那么发送过来的不会被接收,只有阻塞解除之后才会被接收. 内核为每个进程在pending位向量中维护着待处理信号的集合,在blocked位向量中维护着被阻塞的信号的集合. 具体内容可以参考csapp第八章,关于代码的比较多.","path":"2022/03/06/操作系统/异常控制流/"},{"title":"虚拟内存","text":"内存映射将虚拟内存区域与磁盘中的对象关联起来叫做内存映射。 可以映射两种对象 linux的普通文件，内存中映射文件的连续的一块，如果这一块区域比较小，那么就补0， 匿名文件，也叫请求二进制0的页面，他是由内核创建的全是二进制0的。要么从物理内存中换一个页面出来，并且覆盖0，注意没有磁盘与内存没有数据传送。 在使用内存映射的时候，对象可分为共享的，或者私有的，如果是共享对象，那么对对象的任意修改都会反映到磁盘上，如果是私有的对象，不会反映到磁盘上，而是使用写时复制的思想来处理。就是说只有对私有对象写的时候才复制，之前都是共享的，只保留一个物理副本，是只读的，如果写了，就会复制一个新的页面，然后指向新页面，让其可写。 fork函数就使用了写时复制的方法。 使用execve的时候，bss，堆栈是使用映射匿名文件，全0的 mmap函数就是为了创建一个新的虚拟内存区域，使其映射到一个文件的chunk，同时给定偏移量，长度。 虚拟内存参考文章 虚拟地址的整个想法是这样的：把程序给出的地址看做是一种虚拟地址（Virtual Address），然后通过某些映射的方法，将这个虚拟地址转换成实际的物理地址。这样，只要我们能够妥善地控制这个虚拟地址到物理地址的映射过程，就可以保证程序每次运行时都可以使用相同的地址。 除了在编程时可以使用固定的内存地址，给程序员带来方便外，使用虚拟地址还能够使不同程序的地址空间相互隔离，提高内存使用效率。 使不同程序的地址空间相互隔离 如果所有程序都直接使用物理内存，那么程序所使用的地址空间不是相互隔离的。恶意程序可以很容易改写其他程序的内存数据，以达到破坏的目的；有些非恶意、但是有 Bug 的程序也可能会不小心修改其他程序的数据，导致其他程序崩溃。 这对于需要安全稳定的计算机环境的用户来说是不能容忍的，用户希望他在使用计算机的时候，其中一个任务失败了，至少不会影响其他任务。 使用了虚拟地址后，程序A和程序B虽然都可以访问同一个地址，但它们对应的物理地址是不同的，无论如何操作，都不会修改对方的内存。 提高内存使用效率 使用虚拟地址后，操作系统会更多地介入到内存管理工作中，这使得控制内存权限成为可能。例如，我们希望保存数据的内存没有执行权限，保存代码的内存没有修改权限，操作系统占用的内存普通程序没有读取权限等。 另外，当物理内存不足时，操作系统能够更加灵活地控制换入换出的粒度，磁盘 I/O 是非常耗时的工作，这能够从很大程度上提高程序性能。","path":"2022/03/06/操作系统/虚拟内存/"},{"title":"静态链接和动态链接，库打桩，位置无关代码","text":"主要是为了将一些可重定位目标文件链接为可执行的目标文件。 目标文件主要包括三种： 可重定位目标文件，可执行目标文件，共享目标文件链接的主要完成的有两点，符号解析和地址重定位 符号解析主要是为了解析函数符号，全局变量的符号，static的符号，主要是为了将符号引用与符号定义关联起来。为什么不需要对局部变量进行符号解析呢，因为在文件内部可以找到，不需要链接。 符号解析主要是通过将每个引用同输入的可重定位目标文件的符号表中的一个条目对应起来局部变量的符号解析比较简单，静态局部变量会有本地链接器的符号，编译器需要确保有唯一的名字， 如果碰到当前模块没有定义的符号，会假设是其他某个模块定义的，然后生成一个链接器符号表条目，交给链接器处理，然后去其他模块中找，没找到就会报错。 如果出现重名的全局符号，要么选出一个抛弃其他的，要么报错。重名时根据符号强弱来选择，已经初始化的为强符号，没有初始化的为弱符号。 多个强符号报错，一个强多个弱，选强，如果多个弱，任意选一个 对于函数C++和JAVA都会用方法和参数列表组合出一个对链接器唯一的名字，叫函数重整。 地址重定位汇编器生成的是从0开始的代码和数据节，链接器通过把每个符号同一个内存位置关联起来，重定位这些节，然后修改对这些符号的引用，使其指向这个位置，链接器使用汇编器产生的重定位条目。 主要包含两个，重定位节和符号定义，重定位节中的符号引用 重定位节和符号定义(确定符号和节的地址)将所有相同类型的节合并成聚合的节，然后将运行时的内存地址赋给新的聚合节，赋给输入模块的定义每个符号，此时全局变量和每条指令都有唯一的运行地址了。 重定位节中的符号引用（确定每个符号引用的地址）修改代码节和数据节中对每个符号的引用，使其指向正确的运行时地址，这一个步骤依赖于重定位条目。 重定位条目是由于目标模块不知道函数和代码具体存放在内存的位置。也不知道外部定义的函数和全局变量的位置，所以生成重定位条目用来后面生成可执行文件时的修改。 重定位条目包含 offset 被修改的引用的节偏移 type 告诉链接器如何修改新的引用 主要有两种常用类型，R_X86_64_PC32,,重定位一个32位PC相对地址的引用，例如当进行PC相对寻址的时候，这个数加上PC值得到有效地址，例如call的地址。 R_X86_64_32，重定位一个使用32位绝对地址的引用，CPU直接使用这个绝对地址作为有效地址，不需要进一步修改。 addend 有符号常熟，对一些类型的重定位需要使用其对被修改引用的值做偏移调整 symbol 表示被修改的引用应该指向的符号 重定位符号引用 可重定位目标文件包含的内容 ELF头 .text 已经编译的机器代码 .rodata 只读数据，例如printf的格式串 .data 已经初始化的全局数据和静态数据 .bss 未初始化的全局数据和静态数据,不占实际空间,分配在符号表中以及段表中,实际运行才会分配空间. .systab 符号表，存放文件引用的全局变量和函数信息（不包含局部变量），静态变量也在符号表中，局部变量放在栈中管理。 符号表的每个条目由一个结构体表示，包含name，type，section(目标文件的哪个节)，其中有三个特殊的伪节（只在可重定位目标文件才有，可执行文件中没有），UNDEF（未定义的符号），ABS(不该被重定位的符号)，COMMON(未被分配位置的未初始化的数据目标)，value，size。 COMMON主要代表未初始化的全局变量，bss主要代表未初始化的静态变量以及初始化未0的全局和静态变量 .rel.text .text 节中位置的列表，当链接器将这个文件和其他文件组合的时候需要修改，即任何调用外部函数时候都需要修改这些位置，调用本地文件不需要 .rel.data 被模块引用的全局变量的重定位信息。 .debug 调试符号表，文件中定义的局部变量，以及其类型 .line .text中的行号和对应的机器指令的映射 .strtab 字符串表 节头部表 静态链接当与静态库进行链接的时候，构建出的可执行文件实际上只复制静态库中引用的目标模块， 它只需要包含较少的模块。linux中静态库以存档的形式放在磁盘中，是一组连接起来的可重定位目标文件的集合，有头部描述每个文件的大小和位置，存档文件为.a文件。 假设有可重定位目标文件集合E，未解析的符号U，前面输入文件定义的符号集合D。 静态链接的时候是从左到右扫描，添加符号，如果文件是目标文件，那么就会添加到E中，然后修改U，D。 如果是静态库中的每个可重定位目标文件，那么就会比较U中的符号这个文件中有没有，有就添加到E，然后修改U，D，如果没有那么直接丢弃。 但是如果定义的符号的库出现在引用符号的库之前，那么就会链接失败，所以顺序很重要。 所以我们一般把库都放在链接命令的末尾，如果各个库之间没有相互引用，那么顺序是任意的，如果有相互引用，那么需要按照一定的顺序 可执行目标文件ELF头 描述总体格式，程序的入口点 段头部表 .init 初始化代码时调用的 .text .rodata .data .bss 其他的像符号表可重定位条目都没了 加载器加载可执行目标文件时在linux中使用execve函数来调用，在程序头部表的引导下，然后将可执行目标文件的片（chunk）代码和数据复制到内存，然后跳转到第一个入口点（_start）运行该程序。这个入口是在系统目标文件ctrl.o中定义的，然后_start调用__libc_start_main,此函数定义在libc.o中，它初始化环境，调用用户的main函数，处理返回值，需要时将控制返回给内核。 实际上当父shell进程生成一个子进程的时候，foke继承父进程的所有内容，然后删除子进程的虚拟内存段，然后创建新的代码数据，堆栈段，并用虚拟地址空间的页映射可执行目标文件的片（chunk），代码段和数据段初始化为可执行文件的内容。然后跳到_start，执行main 代码段总是从0x400000开始，然后地址从低到高分别是数据段，堆，栈，内核内存。 数据段要求内存对齐，因此有间隙， 动态链接共享库静态链接的缺点在于每次需要复制静态库中的模块到最终的文件中，同时如果静态库更新了，需要重新链接。使用动态共享库使得每次运行或者加载的时候才将文件加载到内存中，进行连接，重定位符号引用，不需要复制模块，只复制一些符号表和重定位信息，而且只有一个副本，由不同的进程共享 linux 中dlopen函数用来在运行的时候加载和链接共享库 JAVA JNI(java native interface)java本地接口他是将本地的C函数foo编译到一个共享库中，然后当正在运行的java程序试图调用foo时，会使用dlopen动态链接和加载foo.so，然后调用foo 位置无关代码（PIC)可以加载而无需重定位的代码称为PIC，使用-fpic，生成pic代码，共享库的生成总是需要这个选项，对于共享文件内部，是不需要做什么的，因为进行引用的时候直接用PC相对寻址就好，但是外部过程和全局变量需要特殊的技巧。 PIC数据引用有一个事实是这样的：无论在内存的哪里加载目标模块（包括共享目标模块），数据段和代码段的距离总是不变的。 同时在数据段中会有一个全局偏移量表GOT，每个被这个模块引用的全局数据目标都有一个条目，动态链接器会重定位每个条目，使其包含正确的地址，比如说调用一个A，是在其他模块定义的，然后它就会去通过GOT间接访问。 PIC函数调用使用了延迟绑定技术，即将过程地址的绑定推迟到第一次调用该过程时候。优点在于当一个共享库的函数太多的时候，将地址绑定推迟到第一次调用时，可以减少很多不需要的重定位，虽然第一次很慢，但是后面都很快，只需要一条指令和一个间接的内存引用。 他是通过GOT和过程链接表PLT实现的，GOT属于数据段，PLT数据代码段。 第一次的时候，会先跳到PLT，然后跳到对应的GOT，然后跳到PLT，然后在栈中压入一些参数，然后跳到动态链接器，使用栈中的条目确定函数地址，然后重写GOT的内容，再调用函数。 后面每次就直接会先跳到PLT，然后跳到对应的GOT，然后跳到对应函数。 库打桩机制它可以截获对共享库函数的调用，转而执行我们自己的代码。 可以在编译时，运行时，或者加载和链接时刻。 编译时打桩在编译的时候的命令行参数加入-I. ，此时会进行打桩，在搜索系统目录的时候优先搜索当前目录。 链接时打桩例如使用—wrap f 标志进行链接时打桩，这个会将f符号解释为wrap_f，将real_f的符号解释为f。 运行时打桩编译时打桩需要访问程序的源代码，链接时打桩需要访问程序的可重定位对象文件。运行时打桩只需要访问可执行目标文件。 它基于动态链接器的LD_PRELOAD.将LD_PRELOAD设置为一个路径，然后当加载和执行一个程序的时候，需要解析其他未定义的引用的时候，会优先搜索LD_PRELOAD库，然后才搜索其他的库。","path":"2022/03/06/操作系统/静态链接和动态链接/"},{"title":"C++运行时的内存映像","text":"主要分为这几个部分， 地址从高到低 系统内核的内存 栈的内存，由高地址向低地址延申（这里有一个rsp，栈指针） 共享库的内存映射区域 堆内存，由低地址向高地址延申（这里有一个brk指针） 已经初始化全局数据段和静态变量区data，以及未初始化的全局变量区和静态变量bss 只读数据段和代码段 - 常量区(只读数据段，rodata) ，虚函数表就放在这个位置 - 代码段(.text),虚函数放在这个位置","path":"2022/03/05/C++/C++运行时的内存映像/"},{"title":"cookie和session的区别","text":"1、由于HTTP协议是无状态的协议，所以服务端需要记录用户的状态时，就需要用某种机制来识具体的用户，这个机制就是Session.典型的场景比如购物车。 当你点击下单按钮时，由于HTTP协议无状态，所以并不知道是哪个用户操作的，所以服务端要为特定的用户创建了特定的Session，用用于标识这个用户，并且跟踪用户，这样才知道购物车里面有几本书。 这个Session是保存在服务端的，有一个唯一标识。在服务端保存Session的方法很多，内存、数据库、文件都有。集群的时候也要考虑Session的转移，在大型的网站，一般会有专门的Session服务器集群，用来保存用户会话，这个时候 Session 信息都是放在内存的，使用一些缓存服务比如Memcached之类的来放 Session。 2、思考一下服务端如何识别特定的客户？这个时候Cookie就登场了。每次HTTP请求的时候，客户端都会发送相应的Cookie信息到服务端。实际上大多数的应用都是用 Cookie 来实现Session跟踪的，第一次创建Session的时候，服务端会在HTTP协议中告诉客户端，需要在 Cookie 里面记录一个Session ID，以后每次请求把这个会话ID发送到服务器，我就知道你是谁了。 有人问，如果客户端的浏览器禁用了 Cookie 怎么办？一般这种情况下，会使用一种叫做URL重写的技术来进行会话跟踪，即每次HTTP交互，URL后面都会被附加上一个诸如 sid=xxxxx 这样的参数，服务端据此来识别用户。 3、Cookie其实还可以用在一些方便用户的场景下，设想你某次登陆过一个网站，下次登录的时候不想再次输入账号了，怎么办？这个信息可以写到Cookie里面，访问网站的时候，网站页面的脚本可以读取这个信息，就自动帮你把用户名给填了，能够方便一下用户。这也是Cookie名称的由来，给用户的一点甜头。 所以，总结一下： Session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式。","path":"2022/03/05/计算机网络/cookie和session的区别/"},{"title":"如何实现DNS劫持","text":"DNS 劫持即域名劫持，是通过将原域名对应的 IP 地址进行替换从而使得用户访问到错误的网站或者使得用户无法正常访问网站的一种攻击方式。域名劫持往往只能在特定的网络范围内进行，范围外的 DNS 服务器能够返回正常的 IP 地址。攻击者可以冒充原域名所属机构，通过电子邮件的方式修改组织机构的域名注册信息，或者将域名转让给其它组织，并将新的域名信息保存在所指定的 DNS 服务器中，从而使得用户无法通过对原域名进行解析来访问目的网址。具体实施步骤如下：1.获取要劫持的域名信息：攻击者首先会访问域名查询站点查询要劫持的域名信息。 2.控制域名相应的 E-MAIL 账号：在获取到域名信息后，攻击者通过暴力破解或者专门的方法破解公司注册域名时使用的 E-mail 账号所对应的密码。更高级的攻击者甚至能够直接对 E-mail 进行信息窃取。 3.修改注册信息：当攻击者破解了 E-MAIL 后，会利用相关的更改功能修改该域名的注册信息，包括域名拥有者信息，DNS 服务器信息等。 4.使用 E-MAIL 收发确认函：在修改完注册信息后，攻击者在 E-mail 真正拥有者之前收到修改域名注册信息的相关确认信息，并回复确认修改文件，待网络公司恢复已成功修改信件后，攻击者便成功完成 DNS 劫持。 用户端的一些预防手段：直接通过 IP 地址访问网站，避开 DNS 劫持。由于域名劫持往往只能在特定的网络范围内进行，因此一些高级用户可以通过网络设置让 DNS 指向正常的域名服务器以实现对目的网址的正常访问，例如将计算机首选 DNS 服务器的地址固定为 8.8.8.8。","path":"2022/03/05/计算机网络/如何实现DNS劫持/"},{"title":"DNS为什么使用UDP","text":"其实 DNS 的整个过程是既使用 TCP 又使用 UDP。 当进行区域传送（主域名服务器向辅助域名服务器传送变化的那部分数据）时会使用 TCP，因为数据同步传送的数据量比一个请求和应答的数据量要多，而 TCP 允许的报文长度更长，因此为了保证数据的正确性，会使用基于可靠连接的 TCP。 当客户端向 DNS 服务器查询域名 ( 域名解析) 的时候，一般返回的内容不会超过 UDP 报文的最大长度，即 512 字节。用 UDP 传输时，不需要经过 TCP 三次握手的过程，从而大大提高了响应速度，但这要求域名解析器和域名服务器都必须自己处理超时和重传从而保证可靠性。","path":"2022/03/04/计算机网络/DNS为什么使用UDP/"},{"title":"TCP的最大连接数目","text":"如何标识一个TCP连接在确定最大连接数之前，先来看看系统如何标识一个tcp连接。系统用一个4四元组来唯一标识一个TCP连接：{local ip, local port,remote ip,remote port}。 client最大tcp连接数client每次发起tcp连接请求时，除非绑定端口，通常会让系统选取一个空闲的本地端口（local port），该端口是独占的，不能和其他tcp连接共享。tcp端口的数据类型是unsigned short，因此本地端口个数最大只有65536，端口0有特殊含义，不能使用，这样可用端口最多只有65535，所以在全部作为client端的情况下，最大tcp连接数为65535，这些连接可以连到不同的server ip。 server最大tcp连接数server通常固定在某个本地端口上监听，等待client的连接请求。不考虑地址重用（unix的SO_REUSEADDR选项）的情况下，即使server端有多个ip，本地监听端口也是独占的，因此server端tcp连接4元组中只有remote ip（也就是client ip）和remote port（客户端port）是可变的，因此最大tcp连接为客户端ip数×客户端port数，对IPV4，不考虑ip地址分类等因素，最大tcp连接数约为2的32次方（ip数）×2的16次方（port数），也就是server端单机最大tcp连接数约为2的48次方。 实际的tcp连接数上面给出的是理论上的单机最大连接数，在实际环境中，受到机器资源、操作系统等的限制，特别是sever端，其最大并发tcp连接数远不能达到理论上限。在unix/linux下限制连接数的主要因素是内存和允许的文件描述符个数（每个tcp连接都要占用一定内存，每个socket就是一个文件描述符），另外1024以下的端口通常为保留端口。在默认2.6内核配置下，经过试验，每个socket占用内存在15~20k之间。 对server端，通过增加内存、修改最大文件描述符个数等参数，单机最大并发TCP连接数超过10万 是没问题的，国外 Urban Airship 公司在产品环境中已做到 50 万并发 。在实际应用中，对大规模网络应用，还需要考虑C10K 问题。","path":"2022/03/04/计算机网络/TCP的最大连接数目/"},{"title":"IP地址和MAC地址作用的区别","text":"简单着说，IP 地址主要用来网络寻址用的，就是大致定位你在哪里，而 MAC 地址，则是身份的唯一象征，通过 MAC 来唯一确认这人是不是就是你，MAC 地址不具备寻址的功能。 IP 地址是基于逻辑的，比较灵活，不受硬件的限制，也容易记忆。而 MAC地址在一定程度上与硬件一致，是基于物理的，能够标识具体的网络节点。这两种地址各有优点，使用时也因条件不同而采取不同的地址 [6] 。 大多数接入Internet的方式是把主机通过局域网组织在一起，然后再通过交换机或路由器等设备和 Internet 相连接。这样一来就出现了如何区分具体用户，防止 IP地址被盗用的问题。由于IP地址只是逻辑上的标识，任何人都能随意修改，因此不能用来具体标识一个用户。而 MAC地址则不然，它是固化在网卡里面的。从理论上讲，除非盗来硬件即网卡，否则一般是不能被冒名顶替的。基于 MAC 地址的这种特点，因此局域网采用了用MAC地址来标识具体用户的方法 。 在具体的通信过程中，通过交换机内部的交换表把 MAC地址和 IP 地址一一对应。当有发送给本地局域网内一台主机的数据包时，交换机首先将数据包接收下来，然后把数据包中的 IP 地址按照交换表中的对应关系映射成 MAC地址，然后将数据包转发到对应的 MAC地址的主机上去。这样一来，即使某台主机盗用了这个 IP 地址，但由于此主机没有对应的 MAC地址，因此也不能收到数据包，发送过程和接收过程类似 。 所以，无论是局域网，还是广域网中的计算机之间进行通信时，最终都表现为将数据包从某种形式的链路上的一个初始节点出发，从一个节点传递到另一个节点，最终传送到目的节点。数据包在这些节点之间的传递都是由 ARP（Address Resolution Protocol：地址解析协议）负责将IP地址映射到 MAC地址上来完成的 。 身份证就是用来证明一个人的身份。平日身份证的作用并不是很大，但是到了有的关键时刻，必须有身份证来说明一个人的一切。那么，IP地址与MAC地址绑定，就如同在日常生活中一个人与身份证的关系。因为，IP地址可以随意的，但MAC地址是唯一说明IP地址身份的。 从上面看如果没有ip地址，只用mac地址，那么很难进行网络寻址，不知道目标主机在哪个区域，但是mac地址就是在局域网中映射成mac地址，然后转发给那个主机，确保是你，没有被冒用。","path":"2022/03/04/计算机网络/IP地址和MAC地址的区别是什么/"},{"title":"IPV4不够如何解决","text":"目前主要有以下两种方式： 1、其实我们平时上网，电脑的 IP 地址都是属于私有地址，我无法出网关，我们的数据都是通过网关来中转的，这个其实 NAT 协议，可以用来暂缓 IPV4 地址不够，关于 NAT，具体可以看我写的这篇文章：什么是 NAT 网络地址转换协议？ 2、IPv6 ：作为接替 IPv4 的下一代互联网协议，其可以实现 2 的 128 次方个地址，而这个数量级，即使是给地球上每一颗沙子都分配一个IP地址，该协议能够从根本上解决 IPv4 地址不够用的问题。 NAT协议：在私有地址和全局地址之间转换的协议。 就是使得私有ip通过转换成网关的地址和ip去访问东西，然后返回结果时再映射为私有地址。 首先什么是私有地址？私有地址是不能用在Internet上(路由器将丢弃寻址这种地址的包)的内部地址。这些地址是不能够在公网上面用的，只能用在局域网的内部。私有地址有三种：①10.0.0.0~10.255.255.255/8 ②172.16.0.0~172.31.255.255/12 ③192.168.0.0~192.168.255.255/16 这些IP地址是用于私有的网络。与之对应的是全局地址，就是正规的自己电脑的地址，全网络承认。比如说，每个人都有自己的大名，走到哪里都能被承认，这就是自己的全局地址；但是在班级里面的外号，就是私有地址，只有班级里面的人知道，在外面别人都不知道这个外号对应的是谁。 、","path":"2022/03/04/计算机网络/IPV4不够如何解决/"},{"title":"ICMP以及相关应用","text":"ICMP 主要有两个应用，一个是 Ping，一个是 Traceroute。 1. PingPing 是 ICMP 的一个重要应用，主要用来测试两台主机之间的连通性。 Ping 的原理是通过向目的主机发送 ICMP Echo 请求报文，目的主机收到之后会发送 Echo 回答报文。Ping 会根据时间和成功响应的次数估算出数据包往返时间以及丢包率。 2. TracerouteTraceroute 是 ICMP 的另一个应用，用来跟踪一个分组从源点到终点的路径。 Traceroute 发送的 IP 数据报封装的是无法交付的 UDP 用户数据报，并由目的主机发送终点不可达差错报告报文。 源主机向目的主机发送一连串的 IP 数据报。第一个数据报 P1 的生存时间 TTL 设置为 1，当 P1 到达路径上的第一个路由器 R1 时，R1 收下它并把 TTL 减 1，此时 TTL 等于 0，R1 就把 P1 丢弃，并向源主机发送一个 ICMP 时间超过差错报告报文； 源主机接着发送第二个数据报 P2，并把 TTL 设置为 2。P2 先到达 R1，R1 收下后把 TTL 减 1 再转发给 R2，R2 收下后也把 TTL 减 1，由于此时 TTL 等于 0，R2 就丢弃 P2，并向源主机发送一个 ICMP 时间超过差错报文。 不断执行这样的步骤，直到最后一个数据报刚刚到达目的主机，主机不转发数据报，也不把 TTL 值减 1。但是因为数据报封装的是无法交付的 UDP，因此目的主机要向源主机发送 ICMP 终点不可达差错报告报文。 之后源主机知道了到达目的主机所经过的路由器 IP 地址以及到达每个路由器的往返时间。","path":"2022/03/04/计算机网络/ICMP以及相关的应用/"},{"title":"SYN洪水攻击","text":"SYN Flood 又称 SYN 洪水攻击，也是拒绝服务攻击的一种，是一种曾经很经典的攻击方式。攻击者利用TCP协议的安全缺陷，不断发送一系列的SYN请求到目标系统，消耗服务器系统的资源，从而导致目标服务器不响应合法流量请求。 在谈SYN flood 之前，我们先了解一下一次正常的网络请求都有哪些步骤，从而更清晰的了解SYN Flood的攻击方式。 一般一次正常的网络请求分以下几个步骤： 域名解析 TCP握手建立链接 客户端发起请求 服务器响应请求 客户端解析并且渲染页面 至此一次请求结束。 而此种攻击正是发生在TCP握手的阶段。TCP握手一般分为三步。客户端发送SYN请求数据包。服务器回复（ACK）确认包。客户端再次回复（ACK）确认包。至此，TCP握手阶段结束。 SYN Flood / SYN 洪水攻击原理为了创建拒绝服务，攻击者利用的正是TCP协议的安全缺陷。在接收到初始SYN数据包之后，服务器用一个或多个SYN / ACK数据包进行响应，并等待握手中的最后一步。这是它的工作原理。 此种攻击是攻击者向目标服务器发送大量的SYN数据包，服务器会响应每一个请求然后返回ACK确认包，并且等待客户端的最终响应。 因为攻击者通常会采用虚拟ip，所以也就意味着服务器永远不可能接收到最终的确认包。这种情况下当服务器未接收到最终ACK数据包的时候，服务端一般会重试（再次发送SYN+ACK给客户端）并等待一段时间后丢弃这个未完成的连接。 这段时间的长度我们称为SYN Timeout，一般来说这个时间是分钟的数量级（大约为30秒-2分钟）；一个用户出现异常导致服务器的一个线程等待1分钟并不是什么很大的问题，但如果有一个恶意的攻击者大量模拟这种情况（伪造IP地址），那么服务器端将为了维护一个非常大的半连接列表而消耗非常多的资源。从而造成服务器的崩溃，即使你的服务器系统资源够强大，服务端也将忙于处理攻击者伪造的TCP连接请求而无暇理睬客户的正常请求（毕竟客户端的正常请求比率非常之小）。 此时，正常用户就会觉得服务器失去响应，这种情况就叫做，服务端收到了SYN Flood攻击（SYN 洪水攻击）","path":"2022/03/04/计算机网络/SYN洪水攻击/"},{"title":"TIME_WAIT 状态会导致什么问题，怎么解决","text":"我们考虑高并发短连接的业务场景，在高并发短连接的 TCP 服务器上，当服务器处理完请求后主动请求关闭连接，这样服务器上会有大量的连接处于 TIME_WAIT 状态，服务器维护每一个连接需要一个 socket，也就是每个连接会占用一个文件描述符，而文件描述符的使用是有上限的，如果持续高并发，会导致一些正常的 连接失败。 解决方案：修改配置或设置 SO_REUSEADDR 套接字，使得服务器处于 TIME-WAIT 状态下的端口能够快速回收和重用。 下面是读者提供的具体操作 修改配置文件：/etc/sysctl.conf net.ipv4.tcp_tw_reuse = 1 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭 也可以采用长连接的方式减少 TCP 的连接与断开，在长连接的业务中往往不需要考虑 TIME-WAIT 状态，但其实在长连接的业务中并发量一般不会太高。","path":"2022/03/04/计算机网络/过多的TIME_WAIT 状态会导致什么问题，怎么解决/"},{"title":"HTTP 长连接短连接使用场景是什么","text":"长连接多用于操作频繁，点对点的通讯，而且连接数不能太多情况。每个 TCP 连接都需要三步握手，这需要时间，如果每个操作都是先连接，再操作的话那么处理速度会降低很多， 所以每个操作完后都不断开，下次处理时直接发送数据包就 OK 了，不用建立 TCP 连接。例如： 数据库的连接用长连接， 如果用短连接频繁的通信会造成 socket 错误，而且频繁的 socket创建也是对资源的浪费。 而像 WEB 网站的 http 服务一般都用短链接，因为长连接对于服务端来说会耗费一定的 资源，而像 WEB 网站这么频繁的成千上万甚至上亿客户端的连接用短连接会更省一些资源， 如果用长连接，而且同时有成千上万的用户，如果每个用户都占用一个连接的话，那可想而知吧。所以并发量大，但每个用户无需频繁操作情况下需用短连接。","path":"2022/03/04/计算机网络/HTTP长连接和短连接的场景区别/"},{"title":"DNS的解析过程","text":"主机向本地域名服务器的查询一般都是采用递归查询。所谓递归查询就是：如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。 本地域名服务器向根域名服务器的查询的迭代查询。迭代查询的特点：当根域名服务器收到本地域名服务器发出的迭代查询请求报文时，要么给出所要查询的 IP 地址，要么告诉本地服务器：“你下一步应当向哪一个域名服务器进行查询”。然后让本地服务器进行后续的查询。根域名服务器通常是把自己知道的顶级域名服务器的 IP 地址告诉本地域名服务器，让本地域名服务器再向顶级域名服务器查询。顶级域名服务器在收到本地域名服务器的查询请求后，要么给出所要查询的 IP 地址，要么告诉本地服务器下一步应当向哪一个权限域名服务器进行查询。最后，本地域名服务器得到了所要解析的 IP 地址或报错，然后把这个结果返回给发起查询的主机。 域名缓存为了提升域名查询效率，设计了域名缓存机制，当访问过某个网站并得到其IP后，会将其域名和IP缓存下来，下一次访问的时候，就不需要再请求域名服务器获取IP，直接使用缓存中的IP，提高了响应的速度。当然缓存是有有效时间（即TTL值）的，当过了有效时间后，再次请求网站，还是需要先请求域名解析。 目前，除了传统的递归DNS服务器（如运营商的Local DNS, 114dns,Google public DNS等）外，计算机中DNS记录在本地也有两种缓存方式：浏览器缓存和操作系统(OS)缓存。在浏览器中访问的时候，会优先访问浏览器缓存，如果未命中则访问OS缓存，最后再访问递归DNS服务器，然后递归DNS服务器会递归式的查找域名记录，然后返回结果。那么浏览器DNS缓存和操作系统DNS缓存又是怎样的呢？ 浏览器DNS缓存：首先，浏览器DNS缓存的时间跟DNS服务器返回的TTL值无关。浏览器在获取网站域名的实际IP地址后会对其IP进行缓存，减少网络请求的损耗。每种浏览器都有一个固定的DNS缓存时间，如Chrome的过期时间是1分钟，在这个期限内不会重新请求DNS。常用的浏览器的DNS缓存时间如下：Chrome：为了加快访问速度，Google Chrome浏览器采用了预提DNS记录，在本地建立DNS缓存的方法，加快网站的连接速度。在Chrome地址栏中输入chrome://net-internals/#dns 就可以看各域名的DNS 缓存时间。默认，Chrome对每个域名会默认缓存60s： 操作系统DNS缓存：OS缓存会参考DNS服务器响应的TTL值，但是不完全等于TTL值。 Linux：Linux系统的nscd服务可以实现DNS缓存的功能。nscd会缓存三种服务passwd,group,hosts，所以它会记录三个库，分别对应源/etc/passwd, /etc/hosts 和/etc/resolv.conf每个库保存两份缓存，一份是找到记录的，一份是没有找到记录的。每一种缓存都保存有生存时间（TTL）。其作用就是增加cache ，加快如DNS的解析等的速度。配置文件为/etc/nscd.conf 默认该服务在redhat或centos下是关闭的，可以通过services nscd start开启。缓存DB文件在/var/db/nscd下。可以通过nscd -g查看统计的信息 清除缓存 nscd -i passwd nscd -i group nscd -i hosts除了上面的方法，重启nscd服务同样可以达到清理cache的目的。","path":"2022/03/04/计算机网络/DNS的解析过程/"},{"title":"在浏览器中输入 URL 地址到显示主页的过程？","text":"DNS 解析：浏览器查询 DNS，获取域名对应的 IP 地址：具体过程包括浏览器搜索自身的 DNS 缓存、搜索操作系统的 DNS 缓存、读取本地的 Host 文件和向本地 DNS 服务器进行查询等。对于向本地 DNS 服务器进行查询，如果要查询的域名包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析(此解析具有权威性)；如果要查询的域名不由本地 DNS 服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个 IP 地址映射，完成域名解析（此解析不具有权威性）。如果本地域名服务器并未缓存该网址映射关系，那么将根据其设置发起递归查询或者迭代查询； TCP 连接：浏览器获得域名对应的 IP 地址以后，浏览器向服务器请求建立链接，发起三次握手； 发送 HTTP 请求：TCP 连接建立起来后，浏览器向服务器发送 HTTP 请求； 服务器处理请求并返回 HTTP 报文：服务器接收到这个请求，并根据路径参数映射到特定的请求处理器进行处理，并将处理结果及相应的视图返回给浏览器； 浏览器解析渲染页面：浏览器解析并渲染视图，若遇到对 js 文件、css 文件及图片等静态资源的引用，则重复上述步骤并向服务器请求这些资源；浏览器根据其请求到的资源、数据渲染页面，最终向用户呈现一个完整的页面。 连接结束。","path":"2022/03/04/计算机网络/浏览器输入网址到显示的过程/"},{"title":"什么是粘包以及如何解决","text":"在进行 Java NIO 学习时，可能会发现：如果客户端连续不断的向服务端发送数据包时，服务端接收的数据会出现两个数据包粘在一起的情况。 TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 把这些数据块仅仅看成一连串无结构的字节流，没有边界； 从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段。 基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。 接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。拆包和粘包的问题导致接收端在处理的时候会非常困难，因为无法区分一个完整的数据包。 发送方产生粘包 采用 TCP 协议传输数据的客户端与服务器经常是保持一个长连接的状态（一次连接发一次数据不存在粘包），双方在连接不断开的情况下，可以一直传输数据。但当发送的数据包过于的小时，那么 TCP 协议默认的会启用 Nagle 算法，将这些较小的数据包进行合并发送（缓冲区数据发送是一个堆压的过程）；这个合并过程就是在发送缓冲区中进行的，也就是说数据发送出来它已经是粘包的状态了。 接收方产生粘包 接收方采用 TCP 协议接收数据时的过程是这样的：数据到接收方，从网络模型的下方传递至传输层，传输层的 TCP 协议处理是将其放置接收缓冲区，然后由应用层来主动获取（C 语言用 recv、read 等函数）；这时会出现一个问题，就是我们在程序中调用的读取数据函数不能及时的把缓冲区中的数据拿出来，而下一个数据又到来并有一部分放入的缓冲区末尾，等我们读取数据时就是一个粘包。（放数据的速度 &gt; 应用层拿数据速度） 分包机制一般有两个通用的解决方法： 特殊字符控制； 在包头首都添加数据包的长度。 如果使用 netty 的话，就有专门的编码器和解码器解决拆包和粘包问题了。 tips：UDP 没有粘包问题，但是有丢包和乱序。不完整的包是不会有的，收到的都是完全正确的包。传送的数据单位协议是 UDP 报文或用户数据报，发送的时候既不合并，也不拆分。","path":"2022/03/04/计算机网络/粘包是什么以及如何解决/"},{"title":"ARQ协议和停止等待协议","text":"停止等待协议停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认。在收到确认后再发下一个分组；在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认。主要包括以下几种情况：无差错情况、出现差错情况（超时重传）、确认丢失和确认收到。 自动重传请求 ARQ 协议停止等待协议中超时重传是指只要超过一段时间仍然没有收到确认，就重传前面发送过的分组（认为刚才发送过的分组丢失了）。因此每发送完一个分组需要设置一个超时计时器，其重传时间应比数据在分组传输的平均往返时间更长一些。这种自动重传方式常称为自动重传请求 ARQ。 连续 ARQ 协议连续 ARQ 协议可提高信道利用率。发送方维持一个发送窗口，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组都已经正确收到了。","path":"2022/03/04/计算机网络/ARQ协议/"},{"title":"TCP协议是如何保证可靠传输的。","text":"数据包校验：目的是检测数据在传输过程中的任何变化，若校验出包有错，则丢弃报文段并且不给出响应，这时 TCP 发送数据端超时后会重发数据； 对失序数据包重排序：既然 TCP 报文段作为 IP 数据报来传输，而 IP 数据报的到达可能会失序，因此 TCP 报文段的到达也可能会失序。 TCP 将对失序数据进行重新排序，然后才交给应用层； 丢弃重复数据：对于重复数据，能够丢弃重复数据； 应答机制：当 TCP 收到发自 TCP 连接另一端的数据，它将发送一个确认。这个确认不是立即发送，通常将推迟几分之一秒； 超时重发：当 TCP 发出一个段后，它启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段； 流量控制：TCP 连接的每一方都有固定大小的缓冲空间。TCP 的接收端只允许另一端发送接收端缓冲区所能接纳的数据，这可以防止较快主机致使较慢主机的缓冲区溢出，这就是流量控制。TCP 使用的流量控制协议是可变大小的滑动窗口协议。","path":"2022/03/04/计算机网络/TCP 协议是如何保证可靠传输的？/"},{"title":"HTTP和HTTPS的区别","text":"Http协议运行在TCP之上，明文传输，客户端与服务器端都无法验证对方的身份； Https是身披SSL(Secure Socket Layer)外壳的Http，运行于SSL上，SSL运行于TCP之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同： 1、端口不同：Http与Http使用不同的连接方式，用的端口也不一样，前者是80，后者是443； 2、资源消耗：和HTTP通信相比，Https通信会由于加减密处理消耗更多的CPU和内存资源； 3、开销：Https通信需要证书，而证书一般需要向认证机构购买； Https的加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制。 一般http中存在如下问题：请求信息明文传输，容易被窃听截取。 数据的完整性未校验，容易被篡改 没有验证对方身份，存在冒充危险 HTTPS 协议过程SSL握手协议的过程 握手阶段分成以下五步： 第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。 第二步，服务器确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数（Server random）。 第三步，客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务器。 第四步，服务器使用自己的私钥，获取客户端发来的随机数（即Premaster secret）。 第五步，客户端和服务器根据约定的加密方法，使用前面的三个随机数，生成&quot;对话密钥&quot;（session key），用来加密接下来的整个对话过程。 为什么非得这么麻烦，非要三个随机数呢？这就必须说 TLS 的设计者考虑得非常周到了，他们不信任客户端或服务器伪随机数的可靠性，为了保证真正的“完全随机”“不可预测”，把三个不可靠的随机数混合起来，那么“随机”的程度就非常高了，足够让黑客难以猜测 客户端是没有证书的，也就没有公钥和私钥。SSL握手阶段，服务器把证书传输给客户端，同时也就传输了公钥（公钥是证书的一部分）。 有一个问题？如何保证公钥传输正确，如何防止中间人攻击？ 找到一个拥有公信力、大家都认可的认证中心(CA)。 服务器在给客户端传输公钥的过程中，会把公钥以及服务器的个人信息通过Hash算法生成信息摘要 为了防止信息摘要被人调换，服务器还会用CA提供的私钥对信息摘要进行加密来形成数字签名。 并且，最后还会把原来没Hash算法之前的个人信息以及公钥 和 数字签名合并在一起，形成数字证书 当客户端拿到这份数字证书之后，就会用CA提供的公钥来对数字证书里面的数字签名进行解密来得到信息摘要，然后对数字证书里服务器的公钥以及个人信息进行Hash得到另外一份信息摘要。最后把两份信息摘要进行对比，如果一样，则证明这个人是服务器，否则就不是。 这样，就可以保证服务器的公钥安全着交给客户端了。从而防止了中间人攻击。 由客户端来对这个证书进行有效性认可，再由这个客户端来生成对称密钥。对称密钥用服务器证书中的公钥加密后，传回给服务器。只有服务器才能解密这个信息，也就只有服务器才知道你的对称密钥。只要这个SSL连接没有关闭，后续的所有数据，无论是客户端发出的还是服务器发出的，均会使用这个对称密钥加密。对称加密算法中，依赖的是密钥的保密性，只要密钥没有被泄露，对称加密的结果被截获也没有什么意义。而密钥是用公钥加密的，只能由服务器解开。 HTTPS的缺点HTTPS协议多次握手，导致页面的加载时间延长近50%； HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗； 申请SSL证书需要钱，功能越强大的证书费用越高。 SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。","path":"2022/03/04/计算机网络/HTTP和HTTPS的区别/"},{"title":"讲一下网络五层模型，每一层的职责？","text":"天各一方的两台计算机是如何通信的呢？ 在成千上万的计算机中，为什么一台计算机能够准确着寻找到另外一台计算机，并且把数据发送给它呢？可能很多人都听说过网络通信的 5 层模型，但是可能并不是很清楚为什么需要五层模型，五层模型负责的任务也有可能经常混淆。 下面是网络通信的五层模型 说实话，五层模型的具体内容还是极其复杂的，不过今天这篇文章，我将用最简洁的模式，通过网络通信的五层模型来讲解一台计算机是如何找到另外一台计算机并且把数据发送给另一台计算机的，就算你没学过计算机网络，也能够听的懂。 1. 物理层 一台计算机与另一台计算机要进行通信，第一件要做的事是什么？ 当然是要把这台计算机与另外的其他计算机连起来啊，这样，我们才能把数据传输过去。 例如可以通过光纤啊，电缆啊，双绞线啊等介质把他们连接起来，然后才能进行通信。 也就是说，物理层负责把两台计算机连起来，然后在计算机之间通过高低电频来传送0,1这样的电信号。 2. 数据链路层 前面说了，物理层它只是单纯着负责把计算机连接起来，并且在计算机之间传输0，1这样的电信号。 如果这些0，1组合的传送毫无规则的话，计算机是解读不了的。 一大堆0，1谁知道是什么鬼啊。 因此，我们需要制定一套规则来进行0，1的传送。 例如多少个电信号为一组啊，每一组信号应该如何标识才能让计算机读懂啊等等。 于是，有了以太网协议。 1. 以太网协议以太网协议规定，一组电信号构成一个数据包，我们把这个数据包称之为帧。 每一个桢由标头(Head)和数据(Data)两部分组成。 帧的大小一般为 64 – 1518 个字节。 假如需要传送的数据很大的话，就分成多个桢来进行传送。 对于表头和数据这两个部分，他们存放的都是一些什么数据呢？ 我猜你眯着眼睛都能想到他们应该放什么数据。 毫无疑问，我们至少得知道这个桢是谁发送，发送给谁的等这些信息吧？ 所以标头部分主要是一些说明数据，例如发送者，接收者等信息。 而数据部分则是这个数据包具体的，想给接守者的内容。 大家想一个问题，一个桢的长度是 64~1518 个字节，也就是说桢的长度不是固定的，那你觉得标头部分的字节长度是固定的吗？ 它当然是固定的啊，假如不是固定的，每个桢都是单独发的，那计算机怎么知道标头是几个字节，数据是几个字节呢。 所以标头部分的字节是固定的，并且固定为18个字节。 把一台计算的的数据通过物理层和链路层发送给另一台计算机，究竟是谁发给谁的，计算机与计算机之间如何区分，，你总得给他们一个唯一的标识吧？ 于是，MAC 地址出现了。 2. MAC 地址连入网络的每一个计算机都会有网卡接口，每一个网卡都会有一个唯一的地址，这个地址就叫做 MAC 地址。 计算机之间的数据传送，就是通过 MAC 地址来唯一寻找、传送的。 MAC地址 由 48 个二进制位所构成，在网卡生产时就被唯一标识了。 3. 广播与ARP协议(1). 广播如图，假如计算机 A 知道了计算机 B 的 MAC 地址，然后计算机 A 想要给计算机 B 传送数据，虽然计算机 A 知道了计算机 B 的 MAC 地址，可是它要怎么给它传送数据呢？ 计算机 A 不仅连着计算机 B，而且计算机 A 也还连着其他的计算机。 虽然计算机 A 知道计算机 B 的 MAC 地址，可是计算机 A 却不知道知道计算机 B 是分布在哪边路线上，为了解决这个问题，于是，有了 广播的出现。 在同一个子网中，计算机 A 要向计算机 B 发送一个数据包，这个数据包会包含接收者的 MAC 地址。 当发送时，计算机 A 是通过广播的方式发送的，这时同一个子网中的计算机 C, D 也会收到这个数据包的，然后收到这个数据包的计算机，会把数据包的 MAC 地址取出来，与自身的 MAC 地址对比，如果两者相同，则接受这个数据包，否则就丢弃这个数据包。 这种发送方式我们称之为广播,就像我们平时在广场上通过广播的形式呼叫某个人一样，如果这个名字是你，你就理会一下，如果不是你，你就当作听不见 (2). ARP 协议。那么问题来了，计算机 A 是如何知道计算机 B 的 MAC 地址的呢？ 这个时候就得由 ARP 协议这个家伙来解决了，不过 ARP 协议会涉及到IP地址，我们下面才会扯到IP地址。 因此我们先放着，就当作是有这么一个 ARP 协议，通过它我们可以知道子网中其他计算机的 MAC 地址。 3. 网络层上面我们有说到子网这个关键词，实际上我们所处的网络，是由无数个子网络构成的。 广播的时候，也只有同一个子网里面的计算机能够收到。 假如没有子网这种划分的话，计算机 A 通过广播的方式发一个数据包给计算机 B , 其他所有计算机也都能收到这个数据包，然后进行对比再舍弃。 世界上有那么多它计算机，每一台计算机都能收到其他所有计算机的数据包，那就不得了了。 那还不得奔溃。 因此产生了子网这么一个东西。 那么问题来了，我们如何区分哪些 MAC 地址是属于同一个子网的呢？ 假如是同一个子网，那我们就用广播的形式把数据传送给对方，如果不是同一个子网的，我们就会把数据发给网关，让网关进行转发。 为了解决这个问题，于是，有了 IP 协议。 3. DNS服务器这里再说一个问题，我们是如何知道对方计算机的IP地址的呢？ 这个问题可能有人会觉得很白痴，心想，当然是计算机的操作者来进行输入了。 这没错，当我们想要访问某个网站的时候，我们可以输入IP来进行访问，但是我相信绝大多数人是输入一个网址域名的，例如访问百度是输入 www.baidu.com 这个域名。 其实当我们输入这个域名时，会有一个叫做DNS服务器的家伙来帮我们解析这个域名，然后返回这个域名对应的IP给我们的。 因此，网络层的功能就是让我们在茫茫人海中，能够找到另一台计算机在哪里，是否属于同一个子网等。 4. 传输层通过物理层、数据链路层以及网络层的互相帮助，我们已经把数据成功从计算机A传送到计算机B了，可是，计算机B里面有各种各样的应用程序，计算机该如何知道这些数据是给谁的呢？ 这个时候，端口(Port)这个家伙就上场了，也就是说，我们在从计算机A传数据给计算表B的时候，还得指定一个端口，以供特定的应用程序来接受处理。 也就是说，传输层的功能就是建立端口到端口的通信。 相比网络层的功能是建立主机到主机的通信。 也就是说，只有有了IP和端口，我们才能进行准确着通信。 这个时候可能有人会说，我输入IP地址的时候并没有指定一个端口啊。 其实呢，对于有些传输协议，已经有设定了一些默认端口了。 例如http的传输默认端口是80，这些端口信息也会包含在数据包里的。 传输层最常见的两大协议是 TCP 协议和 UDP 协议，其中 TCP 协议与 UDP 最大的不同就是 TCP 提供可靠的传输，而 UDP 提供的是不可靠传输。 5. 应用层终于说到应用层了，应用层这一层最接近我们用户了。 虽然我们收到了传输层传来的数据，可是这些传过来的数据五花八门，有html格式的，有mp4格式的，各种各样。 你确定你能看的懂？ 因此我们需要指定这些数据的格式规则，收到后才好解读渲染。 例如我们最常见的 Http 数据包中，就会指定该数据包是 什么格式的文件了。 总结五层模型至此讲到这里。 对于有些层讲的比较简洁，就随便概况了一下。 因为如果我说的详细一点的话，篇幅肯定会特别特别长，我着已经是尽最大的努力以最简洁的方式来讲的了。 如果你想详细去了解，可以去买计算机网络相应的资料，强烈推荐《计算机网络：自顶向下》这本书。 希望我的讲解能让你对计算机之间数据的传输有个大概的了解。 1. IP协议IP协议，它所定义的地址，我们称之为IP地址。 IP协议有两种版本，一种是 IPv4,另一种是 IPv6。 不过我们目前大多数用的还是 IPv4，我们现在也只讨论 IPv4 这个版本的协议。 这个 IP 地址由 32 位的二进制数组成，我们一般把它分成4段的十进制表示，地址范围为0.0.0.0~255.255.255.255。 每一台想要联网的计算机都会有一个IP地址。 这个IP地址被分为两部分，前面一部分代表网络部分，后面一部分代表主机部分。 并且网络部分和主机部分所占用的二进制位数是不固定的。 假如两台计算机的网络部分是一模一样的，我们就说这两台计算机是处于同一个子网中。 例如 192.168.43.1 和 192.168.43.2, 假如这两个 IP 地址的网络部分为 24 位，主机部分为 8 位。 那么他们的网络部分都为 192.168.43，所以他们处于同一个子网中。 可是问题来了，你怎么知道网络部分是占几位，主机部分又是占几位呢？ 也就是说，单单从两台计算机的IP地址，我们是无法判断他们的是否处于同一个子网中的。 这就引申出了另一个关键词————子网掩码。 子网掩码和IP地址一样也是 32 位二进制数，不过它的网络部分规定全部为 1，主机部分规定全部为 0.也就是说，假如上面那两个IP地址的网络部分为 24 位，主机部分为 8 位的话，那他们的子网掩码都为 11111111.11111111.11111111.00000000，即255.255.255.0。 那有了子网掩码，如何来判端IP地址是否处于同一个子网中呢。 显然，知道了子网掩码，相当于我们知道了网络部分是几位，主机部分是几位。 我们只需要把 IP 地址与它的子网掩码做与(and)运算，然后把各自的结果进行比较就行了，如果比较的结果相同，则代表是同一个子网，否则不是同一个子网。 例如，192.168.43.1和192.168.43.2的子码掩码都为255.255.255.0，把IP与子码掩码相与，可以得到他们都为192.168.43.0，进而他们处于同一个子网中。 2. ARP协议有了上面IP协议的知识，我们回来讲一下ARP协议。 有了两台计算机的IP地址与子网掩码，我们就可以判断出它们是否处于同一个子网之中了。 假如他们处于同一个子网之中，计算机A要给计算机B发送数据时。 我们可以通过ARP协议来得到计算机B的MAC地址。 ARP协议也是通过广播的形式给同一个子网中的每台电脑发送一个数据包(当然，这个数据包会包含接收方的IP地址)。 对方收到这个数据包之后，会取出IP地址与自身的对比，如果相同，则把自己的MAC地址回复给对方，否则就丢弃这个数据包。 这样，计算机A就能知道计算机B的MAC地址了。 可能有人会问，知道了MAC地址之后，发送数据是通过广播的形式发送，询问对方的MAC地址也是通过广播的形式来发送，那其他计算机怎么知道你是要传送数据还是要询问MAC地址呢？ 其实在询问MAC地址的数据包中，在对方的MAC地址这一栏中，填的是一个特殊的MAC地址，其他计算机看到这个特殊的MAC地址之后，就能知道广播想干嘛了。 假如两台计算机的IP不是处于同一个子网之中，这个时候，我们就会把数据包发送给网关，然后让网关让我们进行转发传送 注意ARP协议arp协议在，在OSI模型中属于链路层。 arp协议即地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。 它可以解决同一个局域网内主机或路由器的IP地址和MAC地址的映射问题。 arp协议，也称地址解析协议，是根据IP地址获取物理地址的一个TCP/IP协议。","path":"2022/03/04/计算机网络/讲一下网络五层模型，每一层的职责/"},{"title":"SQL注入","text":"SQL注入就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。 1). SQL注入攻击的总体思路 (1). 寻找到SQL注入的位置 (2). 判断服务器类型和后台数据库类型 (3). 针对不同的服务器和数据库特点进行SQL注入攻击 2). SQL注入攻击实例 比如，在一个登录界面，要求输入用户名和密码，可以这样输入实现免帐号登录： 用户名： ‘or 1 = 1 — 密 码： BashCopy 用户一旦点击登录，如若没有做特殊处理，那么这个非法用户就很得意的登陆进去了。这是为什么呢? 下面我们分析一下：从理论上说，后台认证程序中会有如下的SQL语句： String sql = “select * from user_table where username=’ “+userName+” ’ and password=’ “+password+” ‘”; JavaCopy 因此，当输入了上面的用户名和密码，上面的SQL语句变成： SELECT * FROM user_table WHERE username=’’or 1 = 1 –- and password=’’ JavaCopy 分析上述SQL语句我们知道，username= or 1=1 这个语句一定会成功；然后后面加两个 -，这意味着注释，它将后面的语句注释，让他们不起作用。这样，上述语句永远都能正确执行，用户轻易骗过系统，获取合法身份。 应对方法 (1). 参数绑定 使用预编译手段，绑定参数是最好的防SQL注入的方法。目前许多的ORM框架及JDBC等都实现了SQL预编译和参数绑定功能，攻击者的恶意SQL会被当做SQL的参数而不是SQL命令被执行。在mybatis的mapper文件中，对于传递的参数我们一般是使用 # 和$来获取参数值。 当使用#时，变量是占位符，就是一般我们使用javajdbc的PrepareStatement时的占位符，所有可以防止sql注入； 当使用$时，变量就是直接追加在sql中，一般会有sql注入问题。 (2). 使用正则表达式过滤传入的参数","path":"2022/03/04/计算机网络/SQL注入/"},{"title":"IP地址分类（A类 B类 C类 D类 E类）","text":"IP地址根据网络号和主机号来分，分为A、B、C三类及特殊地址D、E。 全0和全1的都保留不用。 A类：(1.0.0.0-126.0.0.0)（默认子网掩码：255.0.0.0或 0xFF000000）第一个字节为网络号，后三个字节为主机号。该类IP地址的最前面为“0”，所以地址的网络号取值于1~126之间。一般用于大型网络。 B类：(128.0.0.0-191.255.0.0)（默认子网掩码：255.255.0.0或0xFFFF0000）前两个字节为网络号，后两个字节为主机号。该类IP地址的最前面为“10”，所以地址的网络号取值于128~191之间。一般用于中等规模网络。 C类：(192.0.0.0-223.255.255.0)（子网掩码：255.255.255.0或 0xFFFFFF00）前三个字节为网络号，最后一个字节为主机号。该类IP地址的最前面为“110”，所以地址的网络号取值于192~223之间。一般用于小型网络。 D类：是多播地址。该类IP地址的最前面为“1110”，所以地址的网络号取值于224~239之间。一般用于多路广播用户[1] 。 E类：是保留地址。该类IP地址的最前面为“1111”，所以地址的网络号取值于240~255之间。 在IP地址3种主要类型里，各保留了3个区域作为私有地址，其地址范围如下：A类地址：10.0.0.0～10.255.255.255B类地址：172.16.0.0～172.31.255.255C类地址：192.168.0.0～192.168.255.255 回送地址：127.0.0.1。 也是本机地址，等效于localhost或本机IP。一般用于测试使用。例如：ping 127.0.0.1来测试本机TCP/IP是否正常。","path":"2022/03/04/计算机网络/IP地址分类（A类 B类 C类 D类 E类）/"},{"title":"TCP滑动窗口和拥塞控制详解","text":"滑动窗口（流量控制）滑动窗口的定义： 1.“窗口”对应的是一段可以被发送的字节序列，其连续的范围称为窗口；2.“滑动”则是指这段“允许发送的范围”是可以随着发送的过程而变化的，方式就是按顺序“滑动”。 滑动窗口的作用： 是一种流量控制方法，该协议允许发送方在停止等待确认前可以连续发送发个分组。由于发送方不必每发送一个分组就停下来等待确认，因此该协议可以加速数据的传输。 1 TCP协议的两端分别是发送者A和接受者B，由于是全双工通讯的，因此A and B应该同时维护着一个独立的发送缓冲区和接受缓冲区，由于对等性，我们以A发送B接受的情况作为例子； -2 发送窗口是发送缓存的一部分，是可以被TCP协议发送的那部分，其实应用层需要发送的所有数据都被放进了发送者的发送缓冲区了；当接收方确认数据后，这个滑动窗口不时地向右移动。窗口两个边沿的相对运动增加或减少了窗口的大小。 -3 发送窗口相关的四个概念：已发送并收到确认的数据（不再发送窗口和发送缓冲区之内）；已发送但未收到确认的数据（位于发送窗口之中）；允许发送但尚未发送的数据以及发送窗口外发送缓冲区内暂时不需要发送的数据。 -4 每次成功发送数据之后，发送窗口就会在发送缓冲区中按顺序移动，将新的数据包含到窗口中准备发送。(即受到接收方的ACK) 当滑动窗口为 0 时，发送方一般不能再发送数据报，但有两种情况除外，一种情况是可以发送紧急数据，例如，允许用户终止在远端机上的运行进程。另一种情况是发送方可以发送一个 1 字节的数据报来通知接收方重新声明它希望接收的下一字节及发送方的滑动窗口大小。 拥塞控制原理 原因是有可能整个网络环境特别差，容易丢包，那么发送端就应该注意了。主要用三种方法： 慢启动阈值 + 拥塞避免 快速重传 快速恢复 慢启动阈值 + 拥塞避免对于拥塞控制来说，TCP 主要维护两个核心状态： 拥塞窗口（cwnd） 慢启动阈值（ssthresh）在发送端使用拥塞窗口来控制发送窗口的大小。 然后采用一种比较保守的慢启动算法来慢慢适应这个网络，在开始传输的一段时间，发送端和接收端会首先通过三次握手建立连接，确定各自接收窗口大小，然后初始化双方的拥塞窗口，接着每经过一轮 RTT（收发时延），拥塞窗口大小翻倍，直到达到慢启动阈值。 然后开始进行拥塞避免，拥塞避免具体的做法就是之前每一轮 RTT，拥塞窗口翻倍，现在每一轮就加一个。 快速重传在 TCP 传输过程中，如果发生了丢包，接收端就会发送之前重复 ACK，比如 第 5 个包丢了，6、7 达到，然后接收端会为 5，6，7 都发送第四个包的 ACK，这个时候发送端受到了 3 个重复的 ACK，意识到丢包了，就会马上进行重传，而不用等到 RTO （超时重传的时间） 选择性重传：报文首部可选性中加入 SACK 属性，通过 left edge 和 right edge 标志那些包到了，然后重传没到的包 快速恢复如果发送端收到了 3 个重复的 ACK，发现了丢包，觉得现在的网络状况已经进入拥塞状态了，那么就会进入快速恢复阶段： 会将拥塞阈值降低为 拥塞窗口的一半 然后拥塞窗口大小变为拥塞阈值 接着 拥塞窗口再进行线性增加，以适应网络状况","path":"2022/03/04/计算机网络/TCP滑动窗口和拥塞控制机制详解/"},{"title":"在交互过程中如果数据传送完了，还不想断开连接怎么办，怎么维持？","text":"在 HTTP 中响应体的 Connection 字段指定为 keep-aliveconnetion:keep-alive;","path":"2022/03/04/计算机网络/在交互过程中如果数据传送完了_还不想断开连接怎么办_怎么维持/"},{"title":"HTTP状态码301和302的区别，都有哪些用途？","text":"一. 301重定向的概念301重定向（301 Move Permanently），指页面永久性转移，表示为资源或页面永久性地转移到了另一个位置。301是HTTP协议中的一种状态码，当用户或搜索引擎向服务器发出浏览请求时，服务器返回的HTTP数据流中头信息（header）中包含状态码 301 ，表示该资源已经永久改变了位置。 301重定向是一种非常重要的”自动转向“技术，网址重定向最为可行的一种方法。 二. 哪些情况需要做301重定向？网页开发过程中，时常会遇到网站目录结构的调整，将页面转移到一个新地址；网页扩展名的改变，这些变化都会导致网页地址发生改变，此时用户收藏夹和搜索引擎数据库中的旧地址是一个错误的地址，访问之后会出现404页面，直接导致网站流量的损失。或者是我们需要多个域名跳转至同一个域名，例如本站主站点域名为 www.conimi.com ，而还有一个域名 www.nico.cc，由于对该域名设置了301重定向，当输入www.nico.cc 时，自动跳转至 www.conimi.com 。 三. 301重定向有什么优点？有利于网站首选域的确定，对于同一资源页面多条路径的301重定向有助于URL权重的集中。例如 www.conimi.com和 conimi.com 是两个不同的域名，但是指向的内容完全相同，搜索引擎会对两个域名收录情况不同，这样导致网站权重和排名被分散；对conimi.com 做301重定向跳转至www.conimi.com 后，权重和排名集中到www.conimi.com，从而提升自然排名。 四. 302重定向又是什么鬼？302重定向（302 Move Temporarily），指页面暂时性转移，表示资源或页面暂时转移到另一个位置，常被用作网址劫持，容易导致网站降权，严重时网站会被封掉，不推荐使用。 五. 301与302的区别302重定向是页面暂时性转移，搜索引擎会抓取新的内容而保存旧的网址并认为新的网址只是暂时的。","path":"2022/03/04/计算机网络/HTTP状态码301和302的区别，都有哪些用途？/"},{"title":"HTTP常用状态码","text":"状态码分类1xx：表示目前是协议的中间状态，还需要后续请求 2xx：表示请求成功 3xx：表示重定向状态，需要重新请求 4xx：表示请求报文错误 5xx：服务器端错误 常用状态码101 切换请求协议，从 HTTP 切换到 WebSocket 200 请求成功，有响应体 301 永久重定向：会缓存 302 临时重定向：不会缓存 304 协商缓存命中 403 服务器禁止访问 404 资源未找到 400 请求错误 500 服务器端错误 503 服务器繁忙","path":"2022/03/04/计算机网络/HTTP常用状态码/"},{"title":"GET 和 POST的区别","text":"参考资料 使用场景GET 用于获取资源，而 POST 用于传输实体主体。 GET在浏览器回退时是无害的，而POST会再次提交请求。 GET产生的URL地址可以被Bookmark，而POST不可以。 GET请求会被浏览器主动cache，而POST不会，除非手动设置。 GET请求只能进行url编码，而POST支持多种编码方式。 GET请求参数会被完整保留在浏览器历史记录里，而POST中的参数不会被保留。 GET请求在URL中传送的参数是有长度限制的，而POST没有。 对参数的数据类型，GET只接受ASCII字符，而POST没有限制。 GET比POST更不安全，因为参数直接暴露在URL上，所以不能用来传递敏感信息。 GET参数通过URL传递，POST放在Request body中","path":"2022/03/04/计算机网络/POST与GET区别/"},{"title":"HTTP 1和1.1和2的区别","text":"HTTP1HTTP/1.0规定浏览器与服务器只保持短暂的连接，浏览器的每次请求都需要与服务器建立一个TCP连接，服务器完成请求处理后立即断开TCP连接， HTTP/1.0中浏览器与服务器只保持短暂的连接，连接无法复用。也就是说每个TCP连接只能发送一个请求。发送数据完毕，连接就关闭，如果还要请求其他资源，就必须再新建一个连接。 我们知道TCP连接的建立需要三次握手，是很耗费时间的一个过程。所以，HTTP/1.0版本的性能比较差。 HTTP1.0 其实也可以强制开启长链接，例如接受Connection: keep-alive 这个字段，但是，这不是标准字段，不同实现的行为可能不一致，因此不是根本的解决办法。 HTTP1.1为了解决HTTP/1.0存在的缺陷，HTTP/1.1于1999年诞生。相比较于HTTP/1.0来说，最主要的改进就是引入了持久连接。所谓的持久连接即TCP连接默认不关闭，可以被多个请求复用。 由于之前打一次电话只能说一件事儿，效率很低。后来人们提出一种想法，就是电话打完之后，先不直接挂断，而是持续一小段时间，这一小段时间内，如果还有事情沟通可以再次进行沟通。 客户端和服务器发现对方一段时间没有活动，就可以主动关闭连接。或者客户端在最后一个请求时，主动告诉服务端要关闭连接。 HTTP/1.1版还引入了管道机制（pipelining），即在同一个TCP连接里面，客户端可以同时发送多个请求。这样就进一步改进了HTTP协议的效率。 HTTP2HTTP/2 为了解决HTTP/1.1中仍然存在的效率问题，HTTP/2 采用了多路复用。即在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应。能这样做有一个前提，就是HTTP/2进行了二进制分帧，即 HTTP/2 会将所有传输的信息分割为更小的消息和帧（frame）,并对它们采用二进制格式的编码。 也就是说，老板可以同时下达多个命令，员工也可以收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。A请求的两部分响应在组合到一起发给老板。 而这个负责拆分、组装请求和二进制帧的一层就叫做二进制分帧层。 除此之外，还有一些其他的优化，比如做Header压缩、服务端推送等。 Header压缩就是压缩老板和员工之间的对话。 服务端推送就是员工事先把一些老板可能询问的事情提现发送到老板的手机（缓存）上。这样老板想要知道的时候就可以直接读取短信（缓存）了。 目前，主流的HTTP协议还是HTTP/1.1 和 HTTP/2。并且各大网站的HTTP/2的使用率也在逐年增加。","path":"2022/03/03/计算机网络/HTTP1_1.1_2的区别/"},{"title":"TCP和UDP的区别","text":"TCP协议的主要特点（1）TCP是面向连接的运输层协议；所谓面向连接就是双方传输数据之前，必须先建立一条通道，例如三次握手就是建议通道的一个过程，而四次挥手则是结束销毁通道的一个其中过程。 （2）每一条TCP连接只能有两个端点（即两个套接字），只能是点对点的； （3）TCP提供可靠的传输服务。传送的数据无差错、不丢失、不重复、按序到达；（4）TCP提供全双工通信。允许通信双方的应用进程在任何时候都可以发送数据，因为两端都设有发送缓存和接受缓存；（5）面向字节流。虽然应用程序与TCP交互是一次一个大小不等的数据块，但TCP把这些数据看成一连串无结构的字节流，它不保证接收方收到的数据块和发送方发送的数据块具有对应大小关系，例如，发送方应用程序交给发送方的TCP10个数据块，但就受访的TCP可能只用了4个数据块久保收到的字节流交付给上层的应用程序，但字节流完全一样。 TCP的可靠性原理 可靠传输有如下两个特点:a.传输信道无差错,保证传输数据正确; b.不管发送方以多快的速度发送数据,接收方总是来得及处理收到的数据; （1）首先，采用三次握手来建立TCP连接，四次挥手来释放TCP连接，从而保证建立的传输信道是可靠的。 （2）其次，TCP采用了连续ARQ协议（回退N，Go-back-N；超时自动重传）来保证数据传输的正确性，使用滑动窗口协议来保证接方能够及时处理所接收到的数据，进行流量控制。 （3）最后，TCP使用慢开始、拥塞避免、快重传和快恢复来进行拥塞控制，避免网络拥塞。 UDP协议特点（１）UDP是无连接的传输层协议； （２）UDP使用尽最大努力交付，不保证可靠交付； （３）UDP是面向报文的，对应用层交下来的报文，不合并，不拆分，保留原报文的边界； （４）UDP没有拥塞控制，因此即使网络出现拥塞也不会降低发送速率； （５）UDP支持一对一 一对多 多对多的交互通信； （６）UDP的首部开销小，只有８字节． TCP和UDP的区别(1)TCP是可靠传输,UDP是不可靠传输; (2)TCP面向连接,UDP无连接; (3)TCP传输数据有序,UDP不保证数据的有序性; (4)TCP不保存数据边界,UDP保留数据边界; (5)TCP传输速度相对UDP较慢; (6)TCP有流量控制和拥塞控制,UDP没有; (７)TCP是重量级协议,UDP是轻量级协议; (８)TCP首部较长２０字节,UDP首部较短８字节; （如果有可选字段那么TCP最多60） 基于TCP和UDP的常用协议 HTTP、HTTPS、FTP、TELNET、SMTP(简单邮件传输协议)协议基于可靠的TCP协议。TFTP、DNS、DHCP、TFTP、SNMP(简单网络管理协议)、RIP基于不可靠的UDP协议 TCP 和 UDP 应用场景 TCP应用场景： 效率要求相对低，但对准确性要求相对高的场景。因为传输中需要对数据确认、重发、排序等操作，相比之下效率没有UDP高。举几个例子：文件传输（准确高要求高、但是速度可以相对慢）、接受邮件、远程登录。 UDP应用场景： 效率要求相对高，对准确性要求相对低的场景。举几个例子：QQ聊天、在线视频、网络语音电话（即时通讯，速度要求高，但是出现偶尔断续不是太大问题，并且此处完全不可以使用重发机制）、广播通信（广播、多播） udp如何实现可靠性传输？UDP不属于连接协议，具有资源消耗少，处理速度快的优点，所以通常音频，视频和普通数据在传送时，使用UDP较多，因为即使丢失少量的包，也不会对接受结果产生较大的影响。 传输层无法保证数据的可靠传输，只能通过应用层来实现了。实现的方式可以参照tcp可靠性传输的方式，只是实现不在传输层，实现转移到了应用层。 最简单的方式是在应用层模仿传输层TCP的可靠性传输。下面不考虑拥塞处理，可靠UDP的简单设计。 1、添加seq/ack机制，确保数据发送到对端 2、添加发送和接收缓冲区，主要是用户超时重传。 3、添加超时重传机制。 详细说明：送端发送数据时，生成一个随机seq=x，然后每一片按照数据大小分配seq。数据到达接收端后接收端放入缓存，并发送一个ack=x的包，表示对方已经收到了数据。发送端收到了ack包后，删除缓冲区对应的数据。时间到后，定时任务检查是否需要重传数据。 目前有如下开源程序利用udp实现了可靠的数据传输。分别为RUDP、RTP、UDT。","path":"2022/03/03/计算机网络/TCP和UDP区别/"},{"title":"TCP四次挥手","text":"刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则：1、第一次挥手：客户端发送一个 FIN 报文，报文中会指定一个序列号。此时客户端处于FIN_WAIT1状态。 2、第二次挥手：服务端收到 FIN 之后，会发送 ACK 报文，且把客户端的序列号值 + 1 作为 ACK 报文的序列号值，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT状态。 3、第三次挥手：如果服务端也想断开连接了，和客户端的第一次挥手一样，发给 FIN 报文，且指定一个序列号。此时服务端处于 LAST_ACK 的状态。 4、第四次挥手：客户端收到 FIN 之后，一样发送一个 ACK 报文作为应答，且把服务端的序列号值 + 1 作为自己 ACK 报文的序列号值，此时客户端处于 TIME_WAIT 状态。需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 CLOSED 状态 5、服务端收到 ACK 报文之后，就处于关闭连接了，处于 CLOSED 状态。 这里特别需要主要的就是TIME_WAIT这个状态了，这个是面试的高频考点，就是要理解，为什么客户端发送 ACK 之后不直接关闭，而是要等一阵子才关闭。这其中的原因就是，要确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。 至于 TIME_WAIT 持续的时间至少是一个报文的来回时间。一般会设置一个计时，如果过了这个计时没有再次收到 FIN 报文，则代表对方成功就是 ACK 报文，此时处于 CLOSED 状态。 这里我给出每个状态所包含的含义，有兴趣的可以看看。 LISTEN – 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED – 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 – 等待远程TCP的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 – 从远程TCP等待连接中断请求； CLOSE-WAIT – 等待从本地用户发来的连接中断请求； CLOSING -等待远程TCP对连接中断的确认； LAST-ACK – 等待原来发向远程TCP的连接中断请求的确认； TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； CLOSED – 没有任何连接状态；","path":"2022/03/03/计算机网络/TCP四次挥手/"},{"title":"TCP三次握手","text":"三次握手 当面试官问你为什么需要有三次握手、三次握手的作用、讲讲三次三次握手的时候，我想很多人会这样回答： 首先很多人会先讲下握手的过程： 1、第一次握手：客户端给服务器发送一个 SYN 报文。 2、第二次握手：服务器收到 SYN 报文之后 3.第三次握手：客户端收到 SYN+ACK 报文之后，会回应一个 ACK 报文。 4、服务器收到 ACK 报文之后，三次握手建立完成 作用是为了确认双方的接收与发送能力是否正常。 这里我顺便解释一下为啥只有三次握手才能确认双方的接受与发送能力是否正常，而两次却不可以：第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。不过此时服务器并不能确认客户端的接收能力是否正常。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力正常，服务器自己的发送、接收能力也正常。 而且描述的详细一点意味着可以扯久一点。加分的描述我觉得应该是这样：刚开始客户端处于 closed 的状态，服务端处于 listen 状态。然后 1、第一次握手：客户端给服务端发一个 SYN 报文，并指明客户端的初始化序列号 ISN(c)。此时客户端处于 SYN_Send 状态。 2、第二次握手：服务器收到客户端的 SYN 报文之后，会以自己的 SYN 报文作为应答，并且也是指定了自己的初始化序列号 ISN(s)，同时会把客户端的 ISN + 1 作为 ACK 的值，表示自己已经收到了客户端的 SYN，此时服务器处于 SYN_RCVD 的状态。 3、第三次握手：客户端收到 SYN 报文之后，会发送一个 ACK 报文，当然，也是一样把服务器的 ISN + 1 作为 ACK 的值，表示已经收到了服务端的 SYN 报文，此时客户端处于 established 状态。 4、服务器收到 ACK 报文之后，也处于 established 状态，此时，双方以建立起了链接 三次握手的作用也是有好多的，多记住几个，保证不亏。例如：1、确认双方的接受能力、发送能力是否正常。 2、指定自己的初始化序列号，为后面的可靠传送做准备。 1、（ISN）是固定的吗三次握手的一个重要功能是客户端和服务端交换ISN(Initial Sequence Number), 以便让对方知道接下来接收数据的时候如何按序列号组装数据。 如果ISN是固定的，攻击者很容易猜出后续的确认号，因此 ISN 是动态生成的。 2、什么是半连接队列服务器第一次收到客户端的 SYN 之后，就会处于 SYN_RCVD 状态，此时双方还没有完全建立其连接，服务器会把此种状态下请求连接放在一个队列里，我们把这种队列称之为半连接队列。当然还有一个全连接队列，就是已经完成三次握手，建立起连接的就会放在全连接队列中。如果队列满了就有可能会出现丢包现象。 这里在补充一点关于SYN-ACK 重传次数的问题： 服务器发送完SYN－ACK包，如果未收到客户确认包，服务器进行首次重传，等待一段时间仍未收到客户确认包，进行第二次重传，如果重传次数超 过系统规定的最大重传次数，系统将该连接信息从半连接队列中删除。注意，每次重传等待的时间不一定相同，一般会是指数增长，例如间隔时间为 1s, 2s, 4s, 8s, 3、三次握手过程中可以携带数据吗很多人可能会认为三次握手都不能携带数据，其实第三次握手的时候，是可以携带数据的。也就是说，第一次、第二次握手不可以携带数据，而第三次握手是可以携带数据的。 为什么这样呢？大家可以想一个问题，假如第一次握手可以携带数据的话，如果有人要恶意攻击服务器，那他每次都在第一次握手中的 SYN 报文中放入大量的数据，因为攻击者根本就不理服务器的接收、发送能力是否正常，然后疯狂着重复发 SYN 报文的话，这会让服务器花费很多时间、内存空间来接收这些报文。也就是说，第一次握手可以放数据的话，其中一个简单的原因就是会让服务器更加容易受到攻击了。 而对于第三次的话，此时客户端已经处于 established 状态，也就是说，对于客户端来说，他已经建立起连接了，并且也已经知道服务器的接收、发送能力是正常的了，所以能携带数据页没啥毛病。","path":"2022/03/03/计算机网络/TCP三次握手/"},{"title":"计算机网络七层协议以及相关的功能是什么","text":"可以参考 https://www.cnblogs.com/schips/p/osi_framework_and_tcp-ip.html 应用层：负责给应⽤程序提供统⼀的接⼝； 表示层：数据格式的转换，以及一些压缩解压的功能，比如下层给过来的数据是二进制的，转换其为图片让人可以看到图片这就是数据转换。即对数据格式进行转换，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。 会话层：为网络设备提供会话的功能，过程中可能会有身份验证等功能，然后当进程终止时会话不一定是终止的，如果没超时，下次继续连接这个会话还存在，那么就不需要身份验证等事情了。 传输层：向上提供可靠的透明数据传输功能，是用于网络中两个进程之间的，处理数据包的错误等传输问题。 网络层：负责数据的路由、转发、分⽚； 链路层：负责数据的封帧和差错检测，以及 MAC 寻址； 物理层：负责在物理⽹络中传输数据帧； 在四层，既传输层数据被称作段（Segments）； 三层网络层数据被称做包（Packages）； 二层数据链路层时数据被称为帧（Frames）； 一层物理层时数据被称为比特流（Bits）。","path":"2022/03/03/计算机网络/计算机网络七层协议/"},{"title":"push_back and emplace_back difference","text":"push_back 和 emplace_back 的区别在哪里？ 回答emplace_back 能就地通过参数构造对象，不需要拷贝或者移动内存，相比 push_back 能更好地避免内存的拷贝与移动，使容器插入元素的性能得到进一步提升。在大多数情况下应该优先使用 emplace_back 来代替 push_back。 就是说本来要先构造，然后再内部调用拷贝构造放到容器里面。 empalce就是直接在容器对应的地方构造了。 下面的代码节选自 http://c.biancheng.net/view/6826.html，可以很好的解释它们的区别， #include &lt;vector&gt; #include &lt;string&gt; #include &lt;iostream&gt; struct President &#123; std::string name; std::string country; int year; President(std::string p_name, std::string p_country, int p_year) : name(std::move(p_name)), country(std::move(p_country)), year(p_year) &#123; std::cout &lt;&lt; &quot;I am being constructed.\\n&quot;; &#125; President(President&amp;&amp; other) : name(std::move(other.name)), country(std::move(other.country)), year(other.year) &#123; std::cout &lt;&lt; &quot;I am being moved.\\n&quot;; &#125; President&amp; operator=(const President&amp; other) = default; &#125;; int main() &#123; std::vector&lt;President&gt; elections; std::cout &lt;&lt; &quot;emplace_back:\\n&quot;; elections.emplace_back(&quot;Nelson Mandela&quot;, &quot;South Africa&quot;, 1994); std::vector&lt;President&gt; reElections; std::cout &lt;&lt; &quot;\\npush_back:\\n&quot;; reElections.push_back(President(&quot;Franklin Delano Roosevelt&quot;, &quot;the USA&quot;, 1936)); std::cout &lt;&lt; &quot;\\nContents:\\n&quot;; for (President const&amp; president: elections) &#123; std::cout &lt;&lt; president.name &lt;&lt; &quot; was elected president of &quot; &lt;&lt; president.country &lt;&lt; &quot; in &quot; &lt;&lt; president.year &lt;&lt; &quot;.\\n&quot;; &#125; for (President const&amp; president: reElections) &#123; std::cout &lt;&lt; president.name &lt;&lt; &quot; was re-elected president of &quot; &lt;&lt; president.country &lt;&lt; &quot; in &quot; &lt;&lt; president.year &lt;&lt; &quot;.\\n&quot;; &#125; &#125; 输出： emplace_back: I am being constructed. push_back: I am being constructed. I am being moved. Contents: Nelson Mandela was elected president of South Africa in 1994. Franklin Delano Roosevelt was re-elected president of the USA in 1936.","path":"2022/02/20/C++/C++_push_back相比emplace_back/"},{"title":"placement new and delete 用法","text":"运算符重载可以重载new and delete。 但是第一个参数必须为std::size_t size 必须返回值为void*，一般如果重载了new，也要 用相同参数重载delete，因为当使用了某种new，就会使用对应参数的delete来删除，如果没有定义，就不会调用，会发生内存泄漏 void * new(std::size_t size) &#123; return std:: malloc(size); &#125; Foo* m = new Foo; void* operator new(std::size_t size, void* ptr) &#123; std::cout &lt;&lt; &quot;placement new&quot; &lt;&lt; std::endl; return ptr; &#125; 如果加入其他形参，比如指针，就是placement new。就是实际上没有分配内存，返回了之前给的指针，实际上是用的之前的内存。 调用就像下面这样 Foo* m2 = new(m) Foo; 如果定义了placement new，就要使用placement delete，不然会发生内存泄漏。","path":"2022/02/14/C++/C++_placement_new/"},{"title":"STL:priority_queue 用法","text":"#include&lt;queue&gt; // 默认优先从小到大输出 std::priority_queue&lt;Type,Container,Functional&gt; //期中type是数据类型，第二个是保存数据的容器，第三个是元素比较函数，默认从大到小operator&lt; //容器默认为vectord //如果优先输出小数据则使用， priority_queue&lt;int,vector&lt;int&gt;,greater&lt;int&gt;&gt; p; // less则是大顶堆，降序 //如果使用自定义的节点 struct node &#123; int x; int y; node(int a,int b):x(a),y(b)&#123;&#125; &#125;; struct cmp &#123; bool operator()(node a,node b) &#123; if(a.x==b.x) return a.y&gt;b.y; else return a.x&gt;b.x;//从小到大 &#125; &#125;; priority_queue&lt;node,vector&lt;node&gt;,cmp&gt; p; 这里很容易混淆的一点是priority_queue是默认大顶堆的，所以a.x&lt;b.x是降序，a.x&gt;b.x是升序。 但是sort是默认升序的，所以a.x&lt;b.x是升序，a.x&gt;b.x是降序。 优先队列自定义排序方式 重载operater&lt;或operator&gt; 创建大顶堆时重载operator&lt;，对应less方法，元素降序 bool operator&lt;(node a,node b) &#123; if(a.x==b.x) return a.y&gt;b.y; else return a.x&lt;b.x;//从小到大 &#125; 创建小顶堆时重载operator&gt;，对应greater方法，元素升序 声明比较类cmp struct cmp &#123; bool operator()(node a,node b) &#123; if(a.x==b.x) return a.y&gt;b.y; else return a.x&gt;b.x;//从小到大 &#125; &#125;; 但是sort还多一个自定义比较函数cmp bool cmp(node a,node b) &#123; return a.x&lt;b.x; &#125; sort(vec.begin(),vec.end(),cmp()) 两个自定义函数对比 priority_queue有两种自定义方式：重载操作符和声明比较类；sort相比于前者增加一个定义比较函数； 默认排序方式不同：priority_queue默认为大顶堆，降序；sort默认升序 自定义运算方式不同：比如&quot;a &lt; b&quot;在priority_queue中代表降序，而在sort中代表升序 调用方式不同：定义比较类时，priority_queue调用过程中不需要&quot;()&quot;–&gt;cmp，而sort无论调用自定义比较函数还是比较类都需要加上&quot;()&quot;–&gt;cmp() 可以参考这篇文章 https://blog.csdn.net/wwrzzu/article/details/106177818","path":"2022/02/14/C++/STL_priority_queue用法/"},{"title":"signal和sigaction的用法","text":"参考博客 Linux进程间通信（一）： 信号 signal()、sigaction()一、什么是信号用过Windows的我们都知道，当我们无法正常结束一个程序时，可以用任务管理器强制结束这个进程，但这其实是怎么实现的呢？同样的功能在Linux上是通过生成信号和捕获信号来实现的，运行中的进程捕获到这个信号然后作出一定的操作并最终被终止。 信号是UNIX和Linux系统响应某些条件而产生的一个事件，接收到该信号的进程会相应地采取一些行动。通常信号是由一个错误产生的。但它们还可以作为进程间通信或修改行为的一种方式，明确地由一个进程发送给另一个进程。一个信号的产生叫生成，接收到一个信号叫捕获。 二、信号的种类信号的名称是在头文件signal.h中定义的，信号都以SIG开头，常用的信号并不多，常用的信号如下：SIGINT一般是由终端敲击的ctrl+C组合键以及预先设置的中断字符 SIGUSR1,SIGUSR2,进程间使用这个信号通信，如报告状态信息 SIGPIPE，如果向管道写数据但是没有读进程就会产生这个信号。 三、信号的处理 —— signal()函数程序可用使用signal()函数来处理指定的信号，主要通过忽略和恢复其默认行为来工作。 void (signal(int sig, void (func)(int)))(int);这是一个相当复杂的声明，耐心点看可以知道signal是一个带有sig和func两个参数的函数，func是一个类型为void (*)(int)的函数指针。该函数返回一个与func相同类型的指针，指向先前指定信号处理函数的函数指针。准备捕获的信号的参数由sig给出，接收到的指定信号后要调用的函数由参数func给出。其实这个函数的使用是相当简单的，通过下面的例子就可以知道。注意信号处理函数的原型必须为void func（int），或者是下面的特殊值： SIG_IGN : 忽略信号 SIG_DFL : 恢复信号的默认行为 四、信号处理 —— sigaction()函数前面我们看到了signal()函数对信号的处理，但是一般情况下我们可以使用一个更加健壮的信号接口 —— sigaction()函数。它的原型为： int sigaction(int sig, const struct sigaction act, struct sigaction oact); 该函数与signal()函数一样，用于设置与信号sig关联的动作，而oact如果不是空指针的话，就用它来保存原先对该信号的动作的位置，act则用于设置指定信号的动作。 sigaction结构体定义在signal.h中，但是它至少包括以下成员： void (*) (int) sa_handler：处理函数指针，相当于signal函数的func参数。 sigset_t sa_mask： 指定一个。信号集，在调用sa_handler所指向的信号处理函数之前，该信号集将被加入到进程的信号屏蔽字中。信号屏蔽字是指当前被阻塞的一组信号，它们不能被当前进程接收到 int sa_flags：信号处理修改器; sa_mask 的值通常是通过使用信号集函数来设置的，关于信号集函数，我将会在我的下一篇文章 —— Linux进程间通信——信号集函数，详细讲述。 sa_flags，通常可以取以下的值：例如SA_NODEFER,捕捉到信号时不添加到信号屏蔽字中。 此外，现在有一个这样的问题，我们使用signal()或sigaction()函数来指定处理信号的函数，但是如果这个信号处理函数建立之前就接收到要处理的信号的话，进程会有怎样的反应呢？它就不会像我们想像的那样用我们设定的处理函数来处理了。sa_mask就可以解决这样的问题，sa_mask指定了一个信号集，在调用sa_handler所指向的信号处理函数之前，该信号集将被加入到进程的信号屏蔽字中，设置信号屏蔽字可以防止信号在它的处理函数还未运行结束时就被接收到的情况，即使用sa_mask字段可以消除这一竞态条件。 五、发送信号上面说到的函数都是一些进程接收到一个信号之后怎么对这个信号作出反应，即信号的处理的问题，有没有什么函数可以向一个进程主动地发出一个信号呢？我们可以通过两个函数kill()和alarm()来发送一个信号。 1、kill()函数 先来看看kill()函数，进程可以通过kill()函数向包括它本身在内的其他进程发送一个信号，如果程序没有发送这个信号的权限，对kill()函数的调用就将失败，而失败的常见原因是目标进程由另一个用户所拥有。想一想也是容易明白的，你总不能控制别人的程序吧，当然超级用户root，这种上帝般的存在就除外了。 kill()函数的原型为： include include int kill(pid_t pid, int sig); 它的作用把信号sig发送给进程号为pid的进程，成功时返回0。 kill()调用失败返回-1，调用失败通常有三大原因： 1、给定的信号无效（errno = EINVAL)2、发送权限不够( errno = EPERM ）3、目标进程不存在( errno = ESRCH ) 2、alarm()函数 这个函数跟它的名字一样，给我们提供了一个闹钟的功能，进程可以调用alarm()函数在经过预定时间后向发送一个SIGALRM信号。 alarm()函数的型如下： alarm()函数用来在seconds秒之后安排发送一个SIGALRM信号，如果seconds为0，将取消所有已设置的闹钟请求。alarm()函数的返回值是以前设置的闹钟时间的余留秒数，如果返回失败返回-1。","path":"2021/12/26/C++/signal和sigaction/"},{"title":"select和poll和epoll的区别","text":"参考博客参考博客 参考博客参考博客 参考博客参考博客 参考博客参考博客 select当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程 异步I/O则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间当select函数返回后，可以 通过遍历fd_set，来找到就绪的描述符。 select本质上是通过设置或检查存放fd标志位的数据结构进行下一步处理。 这带来缺点： FD_SETSIZE宏定义，其大小是32个整数的大小当然我们可以对进行修改，然后重新编译内核，但是性能可能会受到影响，这需要进一步的测试 一般该数和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。32位机默认1024个，64位默认2048 对socket是线性扫描，即轮询，效率较低： 仅知道有I/O事件发生，却不知是哪几个流，只会无差异轮询所有流，找出能读数据或写数据的流进行操作。同时处理的流越多，无差别轮询时间越长 - O(n)。 （1）使用copy_from_user从用户空间拷贝fd_set到内核空间 （2）注册回调函数__pollwait （3）遍历所有fd，调用其对应的poll方法（对于socket，这个poll方法是sock_poll，sock_poll根据情况会调用到tcp_poll,udp_poll或者datagram_poll） （4）以tcp_poll为例，其核心实现就是__pollwait，也就是上面注册的回调函数。 （5）__pollwait的主要工作就是把current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于tcp_poll来说，其等待队列是sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时current便被唤醒了。 （6）poll方法返回时会返回一个描述读写操作是否就绪的mask掩码，根据这个mask掩码给fd_set赋值。 （7）如果遍历完所有的fd，还没有返回一个可读写的mask掩码，则会调用schedule_timeout是调用select的进程（也就是current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout指定），还是没人唤醒，则调用select的进程会重新被唤醒获得CPU，进而重新遍历fd，判断有没有就绪的fd。 （8）把fd_set从内核空间拷贝到用户空间。 缺点： 内核需要将消息传递到用户空间，都需要内核拷贝动作。需要维护一个用来存放大量fd的数据结构，使得用户空间和内核空间在传递该结构时复制开销大。 每次调用select，都需把fd集合从用户态拷贝到内核态，fd很多时开销就很大 同时每次调用select都需在内核遍历传递进来的所有fd，fd很多时开销就很大 select支持的文件描述符数量太小了，默认最大支持1024个 主动轮询效率很低 poll 和select类似，只是描述fd集合的方式不同，poll使用pollfd结构而非select的fd_set结构。 管理多个描述符也是进行轮询，根据描述符的状态进行处理，但poll没有最大文件描述符数量的限制。因为pollfd使用的是链表 poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。 它将用户传入的数组拷贝到内核空间 然后查询每个fd对应的设备状态： 如果设备就绪 在设备等待队列中加入一项继续遍历 若遍历完所有fd后，都没发现就绪的设备 挂起当前进程，直到设备就绪或主动超时，被唤醒后它又再次遍历fd。这个过程经历多次无意义的遍历。 没有最大连接数限制，因其基于链表存储，其缺点： 大量fd数组被整体复制于用户态和内核地址空间间，而不管是否有意义 如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd epoll参考博客参考博客,使用数据结构红黑树，包括红黑树和就绪链表的数据结构 epollctl主要修改红黑树，epollwait主要使用就绪双向链表 epoll模型修改主动轮询为被动通知，当有事件发生时，被动接收通知。所以epoll模型注册套接字后，主程序可做其他事情，当事件发生时，接收到通知后再去处理。 可理解为event poll，epoll会把哪个流发生哪种I/O事件通知我们。所以epoll是事件驱动（每个事件关联fd），此时我们对这些流的操作都是有意义的。复杂度也降到O(1)。 epoll的触发模式，两种水平触发和边缘触发，EPOLLLT和EPOLLET两种： LTLT的一个例子 默认的模式（水平触发） 只要该fd还有数据可读，每次 epoll_wait 都会返回它的事件，提醒用户程序去操作， ETET的一个例子 是“高速”模式（边缘触发），只会提示一次，直到下次再有数据流入之前都不会再提示，无论fd中是否还有数据可读。所以在ET模式下，read一个fd的时候一定要把它的buffer读完，即读到read返回值小于请求值或遇到EAGAIN错误 epoll使用“事件”的就绪通知方式，通过epoll_ctl注册fd，一旦该fd就绪，内核就会采用类似回调机制激活该fd，epoll_wait便可收到通知。 若用EPOLLLT，系统中一旦有大量无需读写的就绪文件描述符，它们每次调用epoll_wait都会返回，这大大降低处理程序检索自己关心的就绪文件描述符的效率。 而采用EPOLLET，当被监控的文件描述符上有可读写事件发生时，epoll_wait会通知处理程序去读写。如果这次没有把数据全部读写完(如读写缓冲区太小)，那么下次调用epoll_wait时，它不会通知你，即只会通知你一次，直到该文件描述符上出现第二次可读写事件才会通知你。这比水平触发效率高，系统不会充斥大量你不关心的就绪文件描述符。 epoll优点没有最大并发连接的限制，能打开的FD的上限远大于1024（1G的内存上能监听约10万个端口） 效率提升，不是轮询，不会随着FD数目的增加效率下降。只有活跃可用的FD才会调用callback函数 即Epoll最大的优点就在于它只关心“活跃”的连接，而跟连接总数无关，因此在实际的网络环境中，Epoll的效率就会远远高于select和poll 内存拷贝，利用mmap()文件映射内存加速与内核空间的消息传递；即epoll使用mmap减少复制开销。 epoll通过内核和用户空间共享一块内存来实现的 总结：在连接数少并且连接都十分活跃的情况下，select和poll的性能可能比epoll好，毕竟epoll的通知机制需要很多函数回调。 epoll跟select都能提供多路I/O复用的解决方案。在现在的Linux内核里有都能够支持，其中epoll是Linux所特有，而select则应该是POSIX所规定，一般操作系统均有实现。 对于第一个缺点，epoll的解决方案在epoll_ctl函数中。每次注册新的事件到epoll句柄中时（在epoll_ctl中指定EPOLL_CTL_ADD），会把所有的fd拷贝进内核，而不是在epoll_wait的时候重复拷贝。epoll保证了每个fd在整个过程中只会拷贝一次。 对于第二个缺点，epoll的解决方案不像select或poll一样每次都把current轮流加入fd对应的设备等待队列中，而只在epoll_ctl时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。epoll_wait的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用schedule_timeout()实现睡一会，判断一会的效果，O(1)复杂度和select实现中的第7步是类似的）。 对于第三个缺点，epoll没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以cat /proc/sys/fs/file-max察看,一般来说这个数目和系统内存关系很大。","path":"2021/12/26/网络编程/select和epoll和poll的区别/"},{"title":"红黑树知识点","text":"一般来说红黑树有以下的知识点 根是黑色 叶节点是黑色的（即为空的黑色的哨兵节点） 从跟到叶子经过相同数目的黑色节点 红色节点的子节点一定是两个黑色的 节点为红色或者黑色 可以参考这个链接来使用30张图带你彻底理解红黑树 红黑树主要是通过左旋右旋和节点变色来实现的。这个左旋右旋和b树b+树的都是一样的。 红黑树查找与二叉搜索树差不多的，但是由于红黑树总是黑色平衡的，所以最坏是O(2lgN)，也即整颗树刚好红黑相隔的时候。能有这么好的查找效率得益于红黑树自平衡的特性 红黑树插入首先必须先找到插入位置，把插入结点放到正确的位置就可以啦，但插入结点是应该是什么颜色呢？答案是红色。理由很简单，红色在父结点（如果存在）为黑色结点时，红黑树的黑色平衡没被破坏，不需要做自平衡操作。但如果插入结点是黑色，那么插入位置所在的子树黑色结点总是多1，必须做自平衡。 一般来说加入红节点会破坏1或者4。 1. 如果此时树为空树，那么必须把插入的节点改成黑色。2. 如果插入的节点父节点为黑节点，那么可以直接插入。3. 如果插入的节点的父节点为红色节点，破坏了4，同时此时的爷爷节点一定为黑色，需要分三种情况讨论3.1 叔叔节点为红色，直接爷爷父亲叔叔变为红黑黑，如果爷爷层级颜色被破坏就还需要继续修改，没有就ok了。3.2 叔叔节点为黑色或者不存在，且父亲是爷爷的左节点3.2.1 自己插入的是父亲节点的左节点，将父亲改为黑色，爷爷改为红色，右旋。3.2.2 自己插入的是父亲节点的右节点，对父亲节点左旋变成3.2.13.3叔叔节点为黑色或者不存在（此时应该是不存在的，因为插入的地方是叶子节点的地方，如果叔叔节点存在且为黑色，那么自己的路径和叔叔路径的黑色数目就不一样了），且父亲是爷爷的右节点（是3.2的另外一个方向的版本） 3.3.1 自己插入的是父亲节点的左节点，右旋，变成3.3.2。3.3.2 自己插入的是父亲节点的右节点，对父亲节点左旋，然后将父亲改为黑色，爷爷改为红色。插入节点的key已经存在，那么此时更新节点的value。红黑树删除删除的情况主要有几个点 1.删除的节点没有子节点，直接删除。 删除的节点有一个子节点，用子节点代替删除的节点（可以认为是删除了子节点） 删除的节点有两个子节点，用后继节点代替删除的节点。（也可以用前驱节点代替，这里以后继节点为例）。把二叉树所有结点投射在X轴上，所有结点都是从左到右排好序的，所有目标结点的前后结点就是对应前继和后继结点。（即中序遍历的后面一个节点）这里可以认为是删除了后继节点，转成情况2或者通过情况2（不存在左节点）转情况1 我们目的都是可以把情况2，3认为是情况1 综上所述，删除操作删除的结点可以看作删除替代结点，而替代结点最后总是在树末。 替换节点是红色节点 我们把替换结点换到了删除结点的位置时，由于替换结点时红色，删除也了不会影响红黑树的平衡，只要把替换结点的颜色设为删除的结点的颜色即可重新平衡。 2.替换节点是黑色节点 2.1.1 替换结点是其父结点的左子结点，替换结点的兄弟结点是红结点，兄弟节点的父节点和子节点都是黑色。 此时把替换节点，父节点，兄弟节点变成黑红黑，然后左旋。 2.1.2 替换结点是其父结点的左子结点，替换结点的兄弟结点是红结点， 2.1.2.1替换结点的兄弟结点的右子结点是红结点，左子结点任意颜色 此时由于会删除黑色节点导致不平衡，所以兄弟节点改成父节点的颜色，将父节点改为黑色，兄弟节点的右节点改为黑色。然后左旋。 2.1.2.2 替换结点的兄弟结点的右子结点为黑结点，左子结点为红结点 删除黑色的替换节点会不平衡，所以将S设置为红色，对兄弟节点右旋，然后得到2.1.2.1的情况。 2.1.2.3 替换结点的兄弟结点的右子结点为黑结点，左子结点为黑结点 将兄弟节点设置为红色。将父节点作为新的替换节点。然后重新进行删除节点处理。 2.2：替换结点是其父结点的左子结点 这个情况和2.1相同，只是方向相反。","path":"2021/12/24/算法/红黑树知识点/"},{"title":"1705. 吃苹果的最大数目（可以用红黑树即map或者优先队列priority_queue实现）","text":"一般可以用优先队列的也可以用红黑树实现，可以比较一下。 优先队列实现&lt;!—hexoPostRenderEscape:int eatenApples(vector&lt;int&gt;&amp; apples, vector&lt;int&gt;&amp; days)&lt;/span&gt; &lt;/span&gt;&#123; &lt;span class=&quot;hljs-built_in&quot;&gt;priority_queue&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;, &lt;span class=&quot;hljs-built_in&quot;&gt;vector&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;&amp;gt;, greater&amp;lt;&lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt;&amp;gt;&amp;gt; pq; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; res = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt; (&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; i = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;, n = apples.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;(); i &amp;lt; n || !pq.empty(); ++i) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (i &amp;lt; n &amp;amp;&amp;amp; apples[i] != &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &amp;#123; pq.emplace(i + days[i], apples[i]); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;while&lt;/span&gt; (!pq.empty() &amp;amp;&amp;amp; pq.top().first &amp;lt;= i) &amp;#123; pq.pop(); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (!pq.empty()) &amp;#123; res++; &lt;span class=&quot;hljs-built_in&quot;&gt;pair&lt;/span&gt;&amp;lt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;,&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt;&amp;gt; mypair = pq.top(); mypair.second--; pq.pop(); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (mypair.second&amp;gt;&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &amp;#123; pq.emplace(mypair); &amp;#125; &amp;#125; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; res; &#125;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;红黑树实现class Solution &#123; public: int eatenApples(vector&lt;int&gt;&amp; apples, vector&lt;int&gt;&amp; days) &#123; int n=apples.size(); map&lt;int,int&gt; m; int res=0; for(int i=0;i&lt;n||!m.empty();i++) &#123; m.erase(i); if(i&lt;n&amp;&amp;apples[i]!=0) m[i+days[i]]=apples[i]; if(!m.empty()) &#123; auto tmp=m.begin(); tmp-&gt;second--; if(tmp-&gt;second==0) m.erase(tmp); res++; &#125; &#125; return res; &#125; &#125;;","path":"2021/12/24/算法/优先队列和红黑树实现/"},{"title":"C++虚函数虚表内容","text":"知乎这个答案讲的很详细可以看下总结以下就是，指针在64位系统中占8字节，在32位系统占4字节 单继承包含虚函数假设B继承A， vptr(这种方式把前面的拿出来还可以算是完整的A) A 成员变量 B成员变量 vptr指向的B虚表的构建规则（放在常量区，只读数据段）: 最上面是offset_to_top （到顶部的偏移量） RTTI（运行时类型信息） 虚函数指针（指向代码段的虚函数代码）（如果是虚析构函数，那么会有两个一个是complete，一个是deleting，前者负责执行析构函数，后者负责在析构函数执行完之后清空内存） 具体是： 将A虚表中内容拷贝一份保存到B的虚表中 如果B重写了A的虚函数，那么将B的虚表对应的函数指针替换为对应的函数地址 如果类型B中出现了基类型A中没有的虚函数，新的虚函数将会被附加在虚函数表的最后 多继承内存模型参考的文章&lt;!—hexoPostRenderEscape:假设类型C同时继承了两个独立的基类A和B,假设A有1 2 3虚函数，B有2 3 4虚函数，C有1 2 4 5虚函数 假设C继承A，BA_vptr(这种方式把前面的拿出来还可以算是完整的A)A 成员变量C 成员变量B_vptrB成员变量 然后A_vptr和B_vptr是连着的，布局如下：offset_to_topRTTI_A_C(A和C的RTTI信息)A的虚函数C重写的A的虚函数C的新加的虚函数offset_to_topRTTI_BB的虚函数（这里的如果被C覆盖的一些函数会使用Thunk，加上某个偏移量去上一个虚表中找） 首先在每个虚函数表的类型信息RTTI之前还有一个偏移量offset_to_top假设是-8，表示当前这个虚函数表地址距离对象顶部地址的偏移量 首先A和B的虚函数指针都会被继承，然后会选一个虚函数表作为主虚函数表，假设选A，那么C的有P_A,P_B,此时P_A会包含1 2 3 5的函数指针，即包括A中的都会在，以及C重写的，C加的同时基类都没有的，P_B包含的是2，3 4，即C类有的，但是没有被重写的，2被重写的会被替换为thunk，这个会加上offset_to_top偏移到C的主的虚表中，然后找到对应的虚函数&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 菱形继承（使用 虚继承）可以参考的文章&lt;!—hexoPostRenderEscape:假设B，C都继承A，D继承B，C，使用虚继承B的布局分别是：vbase_offset(到基类虚表的偏移量)offset_to_top（到顶部的偏移量）RTTI_BB的虚函数vcall_offset(调用子类函数的偏移量,这个是对应的是A的虚函数越在下面对应的这个偏移量越在上面)offset_to_top（到顶部的偏移量）RTTI_AA的虚函数(使用thunk就会使用vcall_offset的偏移量) D的布局v_base_offset(到基类的偏移量)offset_to_topRTTI_B_DB和D的虚函数v_base_offset(到基类的偏移量)v_call_offsetoffset_to_top(到顶部的偏移量)RTTI_CC的虚函数（会利用thunk）v_call_offsetoffset_to_topRTTI_AA的虚函数 B，C会有两个虚表指针，包括A和自己的虚表指针（因为使用了虚继承），这个和单继承的情况有所区别，假设看B，B的虚表指针在前，然后A的虚表指针在后，在offset_to_top的前面还会出现一个vbase_offset，代表距离A的虚函数表的指针地址的偏移量 同时还会出现vcall_offset(X)：当Base的引用或指针base实际接受的是Derive类型的对象，执行base-&gt;FuncC()时候，由于FuncC()没有被重写，所以不需要对this指针进行调整，就是vcall_offset(0)，之后调用FuncC(),如果重写了就会偏移8（假设是8），然后调用。只要需要偏移函数对应的虚表才会出现vcall_offset(8). 当出现虚继承的时候，D只会有3份虚表指针，B,C的主的虚表指针，A只会保留一份,然后也会像多继承一样选择一个主的虚表，然后有的对应的函数在B，或者A的虚表中，有些在主的虚表中，当虚基类Base的引用或指针base实际接受的是Derive类型的对象，执行base-&gt;FuncB()时候，由于FuncB()已经被重写，而此时的this指针指向的是Base类型的对象，需要对this指针进行调整，就是vcall_offset(-32)，所以this指针向上调整了32字节，之后调用FuncB()，就调用到了被重写后的FuncB()函数。 &lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 为什么需要虚继承为了防止二义性，非虚继承时，显然D会继承两次A，内部就会存储两份A的数据浪费空间，而且还有二义性，D调用A的方法时，由于有两个A，究竟时调用哪个A的方法呢，编译器也不知道，就会报错，所以有了虚继承，解决了空间浪费以及二义性问题。在虚拟继承下，只有一个共享的基类子对象被继承，而无论该基类在派生层次中出现多少次。共享的基类子对象被称为虚基类。在虚继承下，基类子对象的复制及由此而引起的二义性都被消除了。 为什么虚函数表中有两个析构函数我们可以看到虚函数表中有两个析构函数，一个标志为deleting，一个标志为complete（不执行delete），因为对象有两种构造方式，栈构造和堆构造，所以对应的实现上，对象也有两种析构方式，其中堆上对象的析构和栈上对象的析构不同之处在于，栈内存的析构不需要执行 delete 函数，会自动被回收。 为什么构造函数不能是虚函数？ 构造函数就是为了在编译阶段确定对象的类型以及为对象分配空间，如果类中有虚函数，那就会在构造函数中初始化虚函数表，虚函数的执行却需要依赖虚函数表。如果构造函数是虚函数，那它就需要依赖虚函数表才可执行，而只有在构造函数中才会初始化虚函数表，鸡生蛋蛋生鸡的问题，很矛盾，所以构造函数不能是虚函数。 为什么基类析构函数要是虚函数？一般基类的析构函数都要设置成虚函数，因为如果不设置成虚函数，在析构的过程中只会调用到基类的析构函数而不会调用到子类的析构函数，可能会产生内存泄漏。 构造函数和析构函数中为什么不可以调用虚函数(不会出现多态)？ 背景知识： 构造子类对象时，首先调用父类构造函数初始化对象的父类部分，在执行父类的构造函数时，对象的子类部分都是未初始化的，实际上此时对象还不是一个子类对象 析构子类对象时，先析构子类部分，然后按照构造顺序逆序析构父类部分 所以在运行子类的构造和析构函数时，对象都是不完整的，为了适应这种不完整，编译器视对象类型为当前构造或析构函数所在类的类型，由此造成的结果就是：在父类的构造或析构函数中，会将子类对象当作父类对象看待 在这样的背景下，如果我们在父类的构造或析构函数中调用虚函数，调用的往往是当前类的虚函数，达不到多态的效果，跟普通函数调用没有区别 小总结offset_to_top：对象在对象布局中与对象顶部地址的偏移量。 RTTI指针：指向存储运行时类型信息(type_info)的地址，用于运行时类型识别，用于typeid和dynamic_cast。 vbase_offset：对象在对象布局中与指向虚基类虚函数表的指针地址的偏移量。 vcall_offset：父类引用或指针指向子类对象，调用被子类重写的方法时，用于对虚函数执行指针地址调整，方便成功调用被重写的方法。 thunk: 表示上面虚函数表中带有adjustment字段的函数调用需要先进行this指针调整，才可以调用到被子类重写的函数。","path":"2021/12/21/C++/c++虚函数_虚表内容/"},{"title":"const and static and volatile用法","text":"static用法主要是表明某个变量是模块私有的，放在静态区，和全局变量放在一个区域，默认初始化为0，在类实例化之前，静态变量区域的变量就已经初始化好了。 具体分为几种情况：1类成员变量，初始化后不可改变，只能在类外初始化，可由类直接访问，也可以用对象访问。 2类成员函数，只能访问静态成员变量，可有类直接访问，而且由于是修饰类的，没有this指针。 3局部变量，在模块外不可使用，实际上变成全局的，但是只能在这个模块内用。 4某个文件全局变量，不可在文件外使用，即使用了extern 5静态函数，只能在本文件调用，其他文件不可以调用 const规则：const离谁近，谁就不能被修改； const修饰一个变量时，一定要给这个变量初始化，若不初始化，在后面也不能初始化。 例如const int *p=1;p指向的内容是不可以改变的，可以去除int来看，易于理解。 int* const p=1;指针的地址是不可改变的。 这个和&amp;的语法糖是一样的T * const p C++ 在函数前面使用const 代表返回值为const的 在函数后面使用const代表函数不可以修改数据成员，同时只能用在非静态成员函数中。 关键字volatile有什么含意？并给出三个不同的例子。一个定义为volatile的变量是说这变量可能会被意想不到地改变，这样，编译器就不会去假设这个变量的值了。精确地说就是，优化器在用到这个变量时必须每次都小心地重新读取这个变量的值，而不是使用保存在寄存器里的备份。下面是volatile变量的几个例子： 1：并行设备的硬件寄存器（如：状态寄存器） 2：一个中断服务子程序中会访问到的非自动变量(Non-automatic variables) 3: 和非本地跳转（setjmp 和 longjmp）相关的场合","path":"2021/12/21/C++/const_static_votatile用法/"},{"title":"C语言宏定义和一些小用法","text":"UL后缀代表无符号长整型后缀#define SEC_YEAR (365*24*60*60)UL 下面的宏定义代表最小值，但是会有副作用#define MIN(a,b) ((a)&lt;=(b)?(a):(b))例如使用MIN(a++,b),此时可以使用下面的代替#include &lt;stdio.h&gt; #define min_i(x,y) ((x)&lt;=(y)?(x):(y)) //（1） #define min_t(type,x,y) (&#123;type _x = x;\\ //（2） type _y = y;\\ _x&lt;_y?_x:_y;\\ &#125;) #define min(x,y) &#123;const typeof(x) _x = (x);\\ //（3） const typeof(y) _y = (y);\\ (void)(&amp;_x=&amp;_y);\\ //（4） _x&lt;_y?_x:_y;\\ &#125;)这个定义计算x和y分别两次（x和y中的小者被计算两次)，当参数由副作用时，将产生不正确的结果使用语句表达式只计算参数一次，避免了可能的错误，语句表达式通常用于宏定义typeof(x)表示x的值类型检查参数x和y的类型是否相同(如果x和y的类型不同编译器将会发出warning，并不影响后面语句的运行 e)int a[10]指针数组，修饰后面的每个元素，数组的每个元素都是指针 f)int (a)[10]，指向数组的指针，修饰a， g)int (*a)(int a)，函数指针a，这个函数返回值为int，参数为int h)int (*a[10])(int)，用指针数组指向函数，该函数有一个整型参数并返回一个整型数 访问一绝对地址把一个整型数强制转换（typecast）为一指针是合法的。 ptr = (int *)0x67a9;","path":"2021/12/21/C++/c语言宏定义和一些小用法/"},{"title":"WSL的图形界面设置","text":"安装xserver首先是Windows上Xserver的安装，作者这里选择的是VcXsrv X Server，下载之后按照所有默认设置进行安装即可。安装完毕之后打开防火墙配置，允许所有的Xserver连接。 然后安装apt-get install xfce4和xfce4-terminal 打开XLaunch，在Display settings里面将Display number改为0，在Extra settings里面勾选Disable access control，启动Xserver。 然后是WSL2里面的配置，作者是用Ubuntu，其他发行版也类似。首先sudo vim ~/.zshrc # sudo vim ~/.bashrc # export DISPLAY=:0 # in WSL 1 export DISPLAY=$(awk &#x27;/nameserver / &#123;print $2; exit&#125;&#x27; /etc/resolv.conf 2&gt;/dev/null):0 # in WSL 2 然后source ~/.zshrc就可以了","path":"2021/12/21/文档相关/WSL的图形界面设置/"},{"title":"哈夫曼树压缩和解压缩","text":"主要是把字符串读到vector中，然后记录每个字符出现的次数，然后构建哈夫曼树，然后再生成哈夫曼编码，再写入。 #include &lt;iostream&gt; #include &lt;Windows.h&gt; #include &lt;fstream&gt; #include &lt;vector&gt; #include&lt;stdio.h&gt; #include &lt;algorithm&gt; #include &lt;cstring&gt; #include &lt;map&gt; #include &lt;bitset&gt; #include&lt;unordered_map&gt; using namespace std; long byteNum = 0; typedef struct &#123; int weight; int parent, lchild, rchild; &#125;HafuNode, * HufumanTree; typedef struct &#123; char* data; int* num; int length; &#125;TNode; typedef struct &#123; char* data; char** HM; &#125;Code; typedef char** HuffmanCode; class Hafuman &#123; private: HuffmanCode code; TNode tnod; HufumanTree hafutree; map&lt;string, char&gt; hafumanHash; //存文件内容 vector&lt;char&gt; str; public: void compression(string decomFile,string comFile) &#123; Read(comFile); TNodeCount(); CreateHuffmanTree(); CreatHuffmanCode(); int i, j, k; unsigned int tmp = 0; int bit = 0; ofstream outfile(&quot;compression.txt&quot;, ios::out); ofstream outComFile(decomFile, ios::out); if (!outfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; //写入编码 outComFile &lt;&lt; tnod.length &lt;&lt; &#x27; &#x27;; for (i = 0; i &lt; tnod.length; i++) &#123; outComFile &lt;&lt; tnod.data[i]; outComFile &lt;&lt; code[i + 1]; outComFile &lt;&lt; &#x27; &#x27;; &#125; for (i = 0; i &lt; str.size(); i++) &#123; for (j = 0; j &lt; tnod.length; j++) &#123; if (tnod.data[j] == str[i]) &#123; break; &#125; &#125; for (k = 0; code[j + 1][k] != &#x27;\\0&#x27;; k++) &#123; outfile &lt;&lt; code[j + 1][k]; if (code[j + 1][k] == &#x27;0&#x27;) &#123; tmp = tmp | 0; &#125; else &#123; tmp = (tmp | 1); &#125; bit = (bit + 1) % 32; if (!bit) &#123; outComFile &lt;&lt; tmp &lt;&lt; &#x27; &#x27;; tmp = 0; &#125; else tmp = tmp &lt;&lt; 1; byteNum++; &#125; &#125; tmp = tmp &lt;&lt; (32 - byteNum % 32 - 1); outComFile &lt;&lt; tmp &lt;&lt; &#x27; &#x27;; outComFile &lt;&lt; byteNum; cerr &lt;&lt; &quot;文件的总的字符数为 &quot; &lt;&lt; byteNum &lt;&lt; endl; outfile.close(); //写总共的位数 cerr &lt;&lt; &quot;压缩成功!,可以到compression.txt中查看具体二进制码，压缩文件为 &quot;&lt;&lt;decomFile &lt;&lt; endl; //outComFile.seekg(0, ios::beg); //streampos size = outComFile.tellg(); cout &lt;&lt; &quot;压缩文件大小为：&quot; &lt;&lt; byteNum/8 &lt;&lt; &quot; 字节&quot; &lt;&lt; endl; outComFile.close(); &#125; void decompression(string decomFilename, string comfilename) &#123; char a[30]; ofstream outfile(comfilename, ios::out); ifstream inComfile(decomFilename, ios::in); if (!outfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; if (!inComfile) &#123; cerr &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; int bytenum; inComfile.seekg(-2L, ios::end); inComfile &gt;&gt; bytenum; inComfile.seekg(0, ios::beg); int codeNum; inComfile &gt;&gt; codeNum; char* code = new char[100]; char ch; unordered_map&lt;string, char&gt; hash; for (int i = 0; i &lt; codeNum; i++) &#123; inComfile &gt;&gt; ch; inComfile &gt;&gt; code; string tmp = code; hash[tmp] = ch; &#125; unsigned int m; string mystr = &quot;&quot;; for (; bytenum &gt;= 32; bytenum -= 32) &#123; inComfile &gt;&gt; m; unsigned int mask = 0x80000000; int countForByte = 32; while (1) &#123; if (!(mask &amp; m)) mystr.append(&quot;0&quot;); else mystr.append(&quot;1&quot;); m = m &lt;&lt; 1; countForByte--; if (hash.count(mystr)) &#123; outfile &lt;&lt; hash[mystr]; mystr = &quot;&quot;; &#125; if (countForByte &lt;= 0) break; &#125; &#125; inComfile &gt;&gt; m; unsigned int mask = 0x80000000; int countForByte = bytenum; while (1) &#123; if (!(mask &amp; m)) mystr.append(&quot;0&quot;); else mystr.append(&quot;1&quot;); m = m &lt;&lt; 1; countForByte--; if (hash.count(mystr)) &#123; outfile &lt;&lt; hash[mystr]; mystr = &quot;&quot;; &#125; if (countForByte &lt;= 0) break; &#125; cout &lt;&lt; &quot;解压成功！解压文件为&quot; &lt;&lt; comfilename&lt;&lt;endl; delete code; code = nullptr; &#125; void CreatHuffmanCode() &#123; int n = tnod.length; int pare, child, start; code = new char* [n + 1]; char* cd = new char[n]; cd[n - 1] = &#x27;\\0&#x27;; for (int i = 1; i &lt;= n; i++) &#123; start = n - 1; child = i; pare = hafutree[i].parent; while (pare != 0) &#123; start--; if (child == hafutree[pare].lchild) &#123; cd[start] = &#x27;0&#x27;; &#125; else &#123; cd[start] = &#x27;1&#x27;; &#125; child = pare; pare = hafutree[child].parent; &#125; code[i] = new char[n - start]; strcpy(code[i], &amp;cd[start]); &#125; for (int i = 1; i &lt;= n; i++) &#123; cerr &lt;&lt; tnod.data[i-1] &lt;&lt; &quot;权重 : &quot; &lt;&lt; tnod.num[i-1]; cerr &lt;&lt;&quot;二进制编码为&quot;&lt;&lt; code[i] &lt;&lt; endl; &#125; delete cd; &#125; void initTnode() &#123; tnod.data = new char[256]; tnod.num = new int[256]; if (tnod.data == NULL || tnod.num == NULL) &#123; cout &lt;&lt; &quot;发生错误&quot; &lt;&lt; endl; exit(1); &#125; tnod.length = 0; &#125; void Read( string filename) &#123; char ch; ifstream infile(filename, ios::in); if (!infile) &#123; cout &lt;&lt; &quot;open error&quot; &lt;&lt; endl; exit(1); &#125; while (infile.peek() != EOF) &#123; infile.get(ch); str.push_back(ch); &#125; infile.seekg(0, ios::end); streampos size = infile.tellg(); cout &lt;&lt; &quot;源文件大小为：&quot; &lt;&lt; size &lt;&lt; &quot; 字节&quot; &lt;&lt; endl; infile.close(); &#125; bool find(const char ch, TNode t) &#123; for (int i = 0; i &lt; t.length; i++) &#123; if (t.data[i] == ch) &#123; return true; &#125; &#125; return false; &#125; void TNodeCount() &#123; int m = str.size(), j = 0; char ch; for (int i = 0; i &lt; m; i++) &#123; ch = str[i]; if (!find(ch, tnod)) &#123; tnod.data[j] = ch; tnod.num[j] = count(str.begin(), str.end(), ch); tnod.length++; j++; &#125; &#125; &#125; void Select(HufumanTree&amp; tree, int a, int&amp; b, int&amp; c) &#123; int min1, min2, minweight = 10000; for (int i = 1; i &lt;= a; i++) &#123; if (tree[i].parent == 0) &#123; if (tree[i].weight &lt; minweight) &#123; minweight = tree[i].weight; min1 = i; &#125; &#125; &#125; tree[min1].parent = 1; minweight = 10000; for (int i = 1; i &lt;= a; i++) &#123; if (tree[i].parent == 0) &#123; if (tree[i].weight &lt; minweight) &#123; minweight = tree[i].weight; min2 = i; &#125; &#125; &#125; tree[min2].parent = 1; b = min1; c = min2; &#125; void CreateHuffmanTree() &#123; int n = tnod.length; if (n &lt;= 1) &#123; return; &#125; int m = 2 * n - 1; hafutree = new HafuNode[m + 1]; for (int i = 1; i &lt;= m; i++)//为0表示没有左右节点，父节点 &#123; hafutree[i].lchild = 0; hafutree[i].parent = 0; hafutree[i].rchild = 0; &#125; for (int i = 1; i &lt;= n; i++) &#123; hafutree[i].weight = tnod.num[i - 1]; &#125; int s1, s2; for (int i = n + 1; i &lt;= m; i++) &#123; Select(hafutree, i - 1, s1, s2); hafutree[s1].parent = i; hafutree[s2].parent = i; hafutree[i].lchild = s1; hafutree[i].rchild = s2; hafutree[i].weight = hafutree[s1].weight + hafutree[s2].weight; &#125; &#125; &#125;; int main() &#123; Hafuman hafumanClass; hafumanClass.initTnode(); string command; char commandOpt; string comFile, deComFile; while (1) &#123; cerr &lt;&lt; &quot;请输入选择的功能&quot; &lt;&lt; endl; cerr &lt;&lt; &quot;1.压缩文件（SZip A xx.haf test.txt（需要压缩的文件名）)&quot; &lt;&lt; endl; cerr &lt;&lt; &quot;2.解压文件（SZip X xx.haf test1.txt(解压的文件名))&quot; &lt;&lt; endl; cin &gt;&gt; command; cin &gt;&gt; commandOpt; if (command != &quot;SZip&quot;||(commandOpt!=&#x27;A&#x27;&amp;&amp; commandOpt != &#x27;X&#x27;)) &#123; cout &lt;&lt; &quot;命令输入错误，请重新输入 &quot; ; continue; &#125; cin &gt;&gt; deComFile &gt;&gt; comFile; switch (commandOpt) &#123; case &#x27;A&#x27;: hafumanClass.compression(deComFile, comFile); break; case &#x27;X&#x27;: hafumanClass.decompression(deComFile,comFile); break; default: cout &lt;&lt; &quot;输入错误！请重新输入&quot;; break; &#125; &#125; return 0; &#125;","path":"2021/12/21/算法/哈夫曼树/"},{"title":"latex中文使用miktex，ctexart","text":"latex中文使用miktex，ctexart \\documentclass[UTF8]&#123;ctexart&#125; \\usepackage[T1]&#123;fontenc&#125; \\usepackage&#123;listings&#125; \\usepackage&#123;graphicx&#125; \\usepackage&#123;xcolor&#125; \\usepackage&#123;fancyhdr&#125; \\usepackage&#123;lastpage&#125; \\pagestyle&#123;fancy&#125; \\chead&#123;西安邮电大学实验报告&#125; \\lhead&#123;&#125; \\rhead&#123;&#125; \\lstset&#123;numbers=left, %用来设置代码块的 numberstyle= \\tiny,keywordstyle= \\color&#123; blue!70&#125;,commentstyle=\\color&#123;red!50!green!50!blue!50&#125;, frame=shadowbox, rulesepcolor= \\color&#123; red!20!green!20!blue!20&#125;, escapeinside=``&#125; \\begin&#123;document&#125; \\tableofcontents \\clearpage \\begin&#123;lstlisting&#125;[language=&#123;[ANSI]C&#125;,numbers=left,numberstyle=\\tiny,%frame=shadowbox, rulesepcolor=\\color&#123;red!20!green!20!blue!20&#125;, keywordstyle=\\color&#123;blue!70!black&#125;, commentstyle=\\color&#123;blue!90!&#125;, basicstyle=\\ttfamily] \\end&#123;document&#125;","path":"2021/12/21/文档相关/latex中文使用/"},{"title":"leetcode29_两数相除","text":"方法主要是用了倍增的思想+位运算如果能用long，就用位运算，再判断溢出的特例。class Solution &#123; public: int divide(int dividend, int divisor) &#123; int flag; if((dividend&gt;0&amp;&amp;divisor&gt;0)||(divisor&lt;0&amp;&amp;dividend&lt;0)) flag=1; else flag=-1; if(dividend==0x80000000&amp;&amp;divisor==-1) return 0x7fffffff; long long div1=abs(long(dividend)),div2=abs(long(divisor)); long long res=0; while(div1&gt;=div2) &#123; int tmp=0; while((div1&gt;&gt;(tmp+1))&gt;=(div2)) &#123; tmp++; &#125; div1-=(div2&lt;&lt;(tmp)); res+=(1&lt;&lt;tmp); &#125; return res*flag; &#125; &#125;; 如果不能用long，就用倍增的方法+同时将数全部化为负数，然后要控制数小于INT_MIN/2的情况。 int divide(int dividend, int divisor) &#123; int flag; if((dividend&gt;0&amp;&amp;divisor&gt;0)||(divisor&lt;0&amp;&amp;dividend&lt;0)) flag=1; else flag=-1; if(dividend==0x80000000&amp;&amp;divisor==-1) return 0x7fffffff; int div1=dividend,div2=divisor; if(dividend&gt;0) div1=-dividend; if(divisor&gt;0) div2=-divisor; int res=0; while(div1&lt;=div2) &#123; int tmp=-1; int div2tmp=div2; while(div2tmp&gt;=INT_MIN/2&amp;&amp;((div1)&lt;=(div2tmp+div2tmp))) &#123; div2tmp+=div2tmp; tmp+=tmp; &#125; div1-=div2tmp; res+=tmp; &#125; return res*-flag; &#125;","path":"2021/12/19/算法/29. 两数相除/"},{"title":"raft算法","text":"lab2实现raft算法（一种共识算法），raft相比 paxos更容易理解，是一种强leader，日志只能从leader复制日志到其他服务器，复制是用来解决分布式系统的容错的问题的。 复制状态机就是这种用来解决分布式系统的容错的问题的，在怎么做的呢？复制状态机是通过复制日志来实现的，每个服务器都有相同的日志 raft算法不依赖于时间 raft这种一致性算法就是为了实现分布式的容错性，通过保证复制日志的一致性来实现的。为了解决这个问题，实际上是通过raft实际上只有三个问题。 主要是选择一个确定的Leader，然后通过leader管理日志的复制，leader接收来自客户端的请求并追加到本地日志，然后把日志复制到其他机器并告诉它们什么时候可以安全的将日志提交到状态机。 raft主要是三个问题： 1 是如何选举出leader 2 如何复制日志，leader接受来自客户端的请求并把日志复制到集群来保证其他机器的日志与自己的相同 3 怎么保证安全，安全指的是，一旦有一个机器将特定的日志复制到自己的状态机，那么其他机器不能够应用一条不同的日志到自己的状态机。（主要是在选举时增加额外的规则约束） 当客户端连接到follewer那么参与者会将其重定向到leader。 raft的任期任期是一个任意长度的间隔，每个任期由连续的整数组成，而且任期是单调递增的，server通讯会交换互相的任期。 如果发现自己的任期小于对方的，会变更自己的任期到大的那个任期。如果candidate或者leader发现自己的任期过期，那么就会变为follower。任意的server接收到过期的请求就会拒绝请求。 raft的RPC通讯raft是通过RPC通讯的，主要是两个RPC，一个是requestVoteRPC（请求投票） 和AppendentriesRPC（进行日志复制和心跳）以及doInstallSnapshotRPC（传送快照） 1.如何选举leaderserver一开始启动都是参与者，然后经过一段时间的超时（即没有收到leader的心跳），那么就会发起选举，转换为candidate，然后增加自己的任期，投票给自己，然后向其他的server发起requestVoteRPC（请求投票）,只要收到超过一半的server投票给自己，那么就转变为leader。一旦成为leader，就会发送心跳给其他人，说明自己胜出。 只有在发起requestVoteRPC（请求投票）的server的任期更新或者日志不更旧的情况下才可以给他投票，否则就会拒绝投票。 同时为了防止没有一个机器拿到一半以上的投票，leader超时的时间是随机150ms到300ms之间。 2.如何进行日志的复制当有一个server是leader，他会处理来自client的请求，首先会将请求追加到自己日志记录，然后发送AppendentriesRPC进行日志复制，日志复制成功之后，leader会将日志应用到自己的状态机并将结果返回给客户端。如果follower宕机或者丢包了，会重复发送AppendentriesRPC直到安全的复制。 日志包括command，以及term，以及index(记录在日志中的位置) 当日志被应用到状态机，这样的日志被称为已经提交。 raft保证所有被提交的日志都会被应用到状态机。如果当前日志被提交那么由前任leader或者由当前leader之前创建的日志记录也都被提交了。 leader维护了被提交日志记录的索引，这个索引会放在AppendentriesRPC（进行日志复制和心跳）中，当参与者收到RPC中的提交的索引的时候，会将本地该索引的日志应用到状态机。 日志匹配原则：1.如果两条日志记录的索引和任期是一样的，那么这两条日志记录的命令也是一样的 2.如果两条日志记录的索引和任期是一样的，那么这两条日志记录的之前的日志记录也是一样的。 给定日期的日志索引是递增的，并且创建之后不会改变他在日志中的位置（保证了第一条） AppendentriesRPC（进行日志复制和心跳）会包含当前正在复制的日志记录的前继日志记录的索引和任期，如果follower发现自己的日志中没有这一条就会拒绝请求。（保证了第二条） follower与leader日志不同的时候follwer可能比leader日志多或者少，可能日志不一致。 raft强制follower只能复制leader的日志来解决不一致问题，即follower与leader冲突的时候，follower会重写或者删除。 这个时候需要确认它们相同的最后一条日志，然后让follower删除之后的，然后再把leader剩下的复制给follower。 leader为每一个follower维护了nextIndex(记录需要复制给follower的下一个日志索引，初始值为leader最后一条日志的索引)。当出现不匹配的时候可能需要找nextindex，那么每次leader发RPC会nextindex减一尝试寻找一致的位置，但是效率会很低，所以为了提速可以follower直接响应这个任期的第一条日志（相当于这个任期的日志都不要了，重新从leader复制过来） 3.如何保持安全安全指的是，一旦有一个机器将特定的日志复制到自己的状态机，那么其他机器不能够应用一条不同的日志到自己的状态机。（主要是在选举时增加额外的规则约束） 这里添加的约束有这些 1选举约束每个raft的leader必须包含之前已经提交的日志。在选举中，一个candidate必须包含所有已经提交的日志才会胜出。 requestVoteRPC（请求投票）实现这个约束：在RPC中包含leader的日志信息，如果投票者的日志比候选者更新那么其拒绝投票（这是通过比较日志的最后一条的任期和索引来比较的，任期大的更新，任期一样，索引大的更新） 2.提交上一个任期的日志为了解决fig8的问题，即一个日志已经被复制到大部分的机器，但是leader在提交日志之前宕机了。 这种情况下虽然日志被复制到大部分机器，但是仍然可能被后面的leader覆盖掉，为了防止这个情况，raft不能够提交上一个任期的日志，只有当前任期的日志才可以被提交，在提交当前任期的时候，顺手提交之前的日志。 细说fig8在时刻(a), s1是leader，在term2提交的日志只赋值到了s1 s2两个节点就crash了。在时刻（b), s5成为了term 3的leader，日志只赋值到了s5，然后crash。 关键点在于c,在(c)时刻，s1又成为了term 4的leader，开始复制日志，于是把term2的日志复制到了s3，此刻，可以看出term2对应的日志已经被复制到了majority，假设上个任期的日志可以被提交（例如term2，但是实际上是不行的），那么term2被提交，应用到状态机。 那么接下来（d）时刻，s1又crash了，s5重新当选（S2,s3,s4)，然后将term3的日志复制到所有节点,这个时候就冲突了，因为按道理s5没有已经提交的最新的日志（1，2），是不可以当选leader的。 究其根本，是因为 term4的时候leader s1 在（c）时刻提交了之前term2任期的日志。 为了杜绝这种情况：在某个leader选举成功后，不可以直接提交前任leader 时期的日志，可以复制日志，比如说把term2和term4复制到大多数，然后提交term4，顺手提交了term2，而是通过提交当前任期的日志的时候，‘顺手’把之前的日志提交了。如果leader 选举之后没有收到客户端的请求呢？，在任期来时的时候立即尝试复制、提交一条空 log。 因此在c图中，term2不会被提交，只有4被复制到大多数，才会1，2，4一起被提交。 如果我们假设term4没有被复制到大多数s1就宕机了，s5任期增加编程term5，赢得任期，那么它可以只有1，3，5被复制到大多数的情况下才可以提交term5的时候顺便提交term3. 因此 在上图中不会出现（c）的情况，即term4任期的leader s1不会复制term2 的日志到s3。而是如同（e）描述的情况，通过复制-提交term4的日志顺便提交term2的日志。如果term4的日志提交成功，那么term2 的日志也一定提交成功，此时，即使 s1 crash，s5也不会重新当选。 如果参与者和候选者宕机如果候选者或者参与者宕机，leader会重复发送RPC，raft请求是可重入的，重试没有危害，如果候选者接受的AppendentriesRPC（进行日志复制和心跳）日志已经被存储，那么就会直接忽略这些请求。 时基和可用性设server并行发送RPC，并接收到它们回应的平均时间设为broadtime 设单台机器的平均故障间隔时间为MTBF 设选举时间为electtime 需要满足broadtime《electtime《MTBF 集群成员变更raft成员变更在6.824中没有实现，这里我参考了一些网上的博客。raft成员变更raft成员变更 变更一个粗暴的方法就是停机然后更新配置文件，但是这个在生产环境中不可使用。没有一定的策略，在选举过程中有可能选举出两个leader，就比如说3个机器到5个机器，如果一次添加两个，可能会导致出现2 3两个分区，一个用的旧配置，一个用的新配置，导致两个Leader。 解决这个的主要是两种办法 联合共识和单步变更的方式，这两种办法总是保证新旧之间存在交集，从而使得只能选出一个Leader。 联合共识 Joint Consensus主要过程： Leader收到来自新的成员变更生成一个C_{new,old}的ConfChang 日志，然后马上应用这个日志，然后将这个日志复制到follower中，收到该日志的节点马上应用新日志（不需要提交）。 当这个C{new,old}日志被复制到大多数节点上的时候，即old配置的大多数和new配置的大多数。那么这条日志就可以被提交，在这条日志被提交之后，马上新建一个C{new}日志，然后将这个日志复制到follower，收到这个日志的节点马上应用这个配置作为这个节点的配置。 一旦这个C{new}被复制到大部分节点上，即C{new}的大多数，那么C{new}就可以被提交了，C{new}提交完成后，就可以进行下一轮的成员变更了。 在联合共识的情况下，出现多个阶段，这几个阶段之间总是配置存在交集的，从而保证不会出现两个Leader。 在1的情况下，C_{new,old}的节点成为Leader的话，需要old的大多数，然后推进成员变更，old配置下也需要old的大多数，只能有一个leader，然后回滚。 在2的情况下，C{new,old}被提交之后，C{old}首先不可能成为Leader，然后C{new,old}需要new的大多数，C{new}需要new的大多数因此总是只有一个Leader C_{new}被提交之后，总是需要new的大多数。 单步成员变更这个意思就是每次我只增加或者删除一个节点。这可以保证新旧配置之间总有交集。那个交点总是只会投给一个leader，因此避免了出现两个leader。用式子的话就是（n/2+1)+((n+1)/2 +1 ) &gt;n+1,对于 raft 集群来说，旧配置的大多数与新配置的大多数之和一定大于新配置的节点个数。 流程如下： 客户端提出一个成员变更的请求，为添加或者删除一个节点。 Leader收到请求之后，追加一个C_{new}的日志，然后这个日志会被追加到follower中。 当日志被追加到follower节点之后会立即生效。 当日志被复制到C_{new}的大部分节点之后，就可以进行提交。（如果用旧的数目来计算提交数目，可能会导致已经被提交的日志被覆盖。） 提交完成之后，变更完成。如果移除了服务器，那么服务器可以关机了。 可以进行下一轮成员变更了，注意在上一次成员变更没有完成之前，不允许进行下一次成员变更。 单步成员变更的问题参考链接以下是一个单步变更出 bug 的例子, 原成员是 4 节点a，b，c，d。2 个进程分别要加入 u 和加入 v，如果中间出现换主，就会丢失一个已提交的变更。解决办法：新 leader 必须提交一条自己的 term 的 no-op 日志, 才允许接着变更日志。 变更可用性问题（联合共识和单步都可能出现）添加服务器可能导致新机器缺少了很多的日志，需要花费很长的时间来追赶，这可能导致可用性很差。例如a,b,c，c宕机，新加入d，总是需要3台机器才能算日志复制完成，导致可用性变差。 或者在联合共识下3台变6台也有可能。解决办法：在集群中加入新角色作为学习者，学习者只对集群的日志进行复制，没有投票权，日志复制同步成功时，才能进行成员变更。 还有成员变更可能会导致可用性变差，三个机房a,b,c，然后加入d到a中，如果a,d与其他机房失联，此时是不可用的，因为四台机器最少需要3台。这就是单点故障问题，这个可以使用一些加权重的办法来解决这个问题。 Leader移除了自己当新日志中没有Leader的时候，如果直接应用对应的日志，会导致如下的问题， C_{new}还没有被复制到其他节点，Leader没了，相当于这个移除操作根本不存在。 Leader 退位成为 Follower 后可能因为超时重新成为 Leader，因为该节点上的日志是最新的，因为日志的安全性，该节点并不会为其他节点投票。 解决办法： 如果C_{new}中没有Leader，先通过Leader transfer转移Leader，然后再应用这个日志。 等这个C{new}提交之后，再移除自己，这个时候follower会超时选出leader，因为C{new}已经commit，C_{new}已经被复制到大部分节点上（注意这个大部分节点不包括这个即将被移除的Leader，虽然它现在还没被移除，但是算大多数的时候要用新配置，同时不能算它），即使原来的Leader超时，也无法成为Leader。 中断服务器的干扰当一个服务器从新配置中被移除，但还没有关机，因为没有 leader 会给它发送心跳，它自己会尝试增加 term 开始选举。在 C_{new}中的 leader 收到更大 term 的投票，会自动退化成了 follower，然后重新选举。虽然那个被移除的机器永远无法成为 leader，但是它会不断的干扰正常集群的工作。 可以采用 PreVote 方法解决，一个服务器开始选举时，先发起 PreVote，如果得到半数以上的同意，再发起投票。 在 PreVote 算法中，Candidate 首先要确认自己能赢得集群中大多数节点的投票，这样才会把自己的 term 增加，发起真正的投票。其他投票节点同意给它投票的条件是（同时满足下面两个条件）： 没有收到有效领导的心跳，至少有一次选举超时。（这里如果能在正常时间内收到Leader的心跳，那么就拒绝投票） Candidate 的日志足够新（Term 更大，或者 Term 相同 Raft log index 更大）。 暂时可以参考raft成员变更 多节点成员变更对于多节点成员变更场景，Raft首先切换到过渡配置，称为joint consensus。当过渡配置提交后，整个系统再转入到C-new配置，并将C-new配置提交，之后成员变更操作就完成了。所以过渡配置到底是啥东西呢： 如果集群处于过渡配置状态，那么log entry会被复制到C-old和C-new包含的所有节点 如果集群处于过渡配置状态，属于C-old或者C-new的节点都可以成为leader 如果集群属于过渡配置状态，判断一条日志是否提交或者请求选举在计算quorum的时候既要满足C-old的majority，又要满足C-new的majority下图很好的说明了raft多节点成员变更的过程。该图中中间的三条线表示随时间流逝，集群所处状态的变化，即集群最开始处于C-old状态，然后用户发起了配置变更，此时leader产生C-old-new配置log，并向集群中所有节点复制该log，当C-old和C-new的多数节点都复制成功C-old-new配置log后，表示C-old-new被提交，此时集群处于过渡配置状态(joint consensus)，之后leader可以安全的产生C-new配置，然后将其复制到整个集群(在复制C-new时，集群处于过渡配置状态，所以此时计算quorum时，应该需要满足C-old和C-new的majority)。当C-new也被提交后，集群完成配置变更。 日志压缩集群的日志会不断增长，维克可用性，需要压缩日志。 快照是最简单的压缩办法。 每个机器独立的进行快照压缩，快照只会覆盖已经提交的日志。 快照包含最后一条被快照取代的日志的索引。（lastIncludeIndex） 快照包含最后一条被快照取代的日志的任期。（lastIncludeTerm） 这些要被持久化（即写到磁盘） 一旦机器完成快照，在lastIncludeIndex之前的日志可以删除。 正常情况日志是单独进行快照的，但是如果某个机器的日志太老了，即下一条该发给他的已经被删除了，那么就发送InstallsnapshotRPC,这个情况下，follower删除整个日志然后用快照取代，如果重复收到，那么快照之前的可以删除，快照之后的是正常的需要保留。 做snapshot既不要做的太频繁，否则消耗磁盘带宽， 也不要做的太不频繁，否则一旦节点重启需要回放大量日志，影响可用性。推荐当日志达到某个固定的大小做一次snapshot。 做一次snapshot可能耗时过长，会影响正常日志同步。可以通过使用copy-on-write技术避免snapshot过程影响正常日志同步。 与客户端交互客户端将请求发送到leader，然后他会随机选取server发起请求，如果对方不是leader，那么他会告知客户端leader，然后客户端去请求leader，如果leader宕机，那么就随机选择机器重试。 为了保持幂等性，就算客户端多次请求只会被执行一次。方法是客户端有一个独立的编号，命令有一个独立的编号，然后状态机记录客户端处理的最新的编号，如果接受到一个客户端的请求已经被执行了，直接返回不执行。 只读操作可能会导致返回脏数据，即（出现脑裂，旧leader在少数派中，多数派选出新leader同时写了新内容，此时客户端请求旧leader会返回脏数据）， 使用两个方法避免， 1.leader必须知道已经提交的所有日志记录的最新信息。选举制度保证leader一定有所有已经提交的日志，但是任期刚刚开始它可能不知道哪些日志已经提交了，所以需要在当选的时候追加一条空日志到自己的日志中。 leader在处理只读任务（即Get)的时候需要知道自己这个leader是不是有效的（防止出现脑裂），在响应get的时候需要与半数以上的机器交换心跳信息。或者通过心跳值来提供租约（这样会使得安全依赖于时间）。 raft协议，leader在commit了一条日志后，立刻挂了，那其他节点如何处理这条日志？ 只有包含有这条日志的机器才能成为Leader，然后会复制到其他机器上。 选举是比较任期和日志，先比较任期，任期越大的越新，再比较日志，日志号越大的越新。这个任期是最后一条日志的任期，不是当前任期。","path":"2021/05/25/分布式/raft 算法/"},{"title":"kmp算法，模板","text":"在求next数组和求相似数组很相似，只是i的起始点要为1，一个为0 可以参考leetcode链接 void getNext(List&lt;Integer&gt; next,String s1) &#123; int j=0; for(int i=1;i&lt;s1.length();i++) &#123; while(j&gt;0&amp;&amp;(s1.charAt(j)!=s1.charAt(i))) j=next.get(j-1); if(s1.charAt(j)==s1.charAt(i)) j++; next.set(i,j); &#125; &#125; public int strStr(String haystack, String needle) &#123; if(needle.length()==0) return 0; List&lt;Integer&gt; next=new ArrayList&lt;&gt;(Collections.nCopies(needle.length(),0)); getNext(next,needle); int i,j=0; for(i=0;i&lt;haystack.length();i++) &#123; while((j&gt;0)&amp;&amp;(haystack.charAt(i)!=needle.charAt(j))) j=next.get(j-1); if(haystack.charAt(i)==needle.charAt(j)) j++; if(j==needle.length()) return i-j+1; &#125; return -1; &#125;","path":"2021/04/27/算法/kmp算法/"},{"title":"马拉车算法","text":"关键之处在于要利用镜像的信息，对于镜像已经知道的及时跳过。 然后还有一点就是扩充字符串#，然后两端加@！，这个时候我们如果得到最长回文串，那么怎么获得原始的最长回文串呢，是最右边的-中心得到最左边的位置，然后最左边的位置除2就是原始的起始值，这个很容易理解，因为是刚好扩充了两倍的，用#隔开的。 还有一点关键是更新的是每个点已经以他为中心扩充的字符串，dp数组记录的是长度 class Solution &#123; public String longestPalindrome(String s) &#123; StringBuilder sb=new StringBuilder(&quot;!#&quot;); for(int i=0;i&lt;s.length();i++) &#123; sb.append(s.charAt(i)); sb.append(&quot;#&quot;); &#125; sb.append(&quot;@&quot;); int dp[]=new int[sb.length()]; int C=0,R=0; int maxlen=0,center=0; for(int i=0;i&lt;sb.length();i++) &#123; int slen=1;//子串长度 if(i&lt;R)//如果包含在内 &#123; int mirror=2*C-i;//如果镜像没超过边界，那么直接赋值，否则还要验证 dp[i]=Math.min(dp[mirror],R-i);//直接取镜像的dp值和到边界距离的最小值 slen=dp[i]; &#125; while((i-slen)&gt;=0&amp;&amp;(i+slen)&lt;sb.length()&amp;&amp;(sb.charAt(i-slen)==sb.charAt(i+slen))) &#123; slen++; &#125; if(i+slen-1&gt;R) &#123; R=i+slen-1; C=i; &#125; dp[i]=slen-1; if(dp[i]&gt;maxlen) &#123; maxlen=dp[i]; center=i; &#125; &#125; // System.out.println(maxlen); return s.substring((center-maxlen)/2,(center-maxlen)/2+maxlen); &#125; &#125;","path":"2021/04/12/算法/马拉车算法/"},{"title":"146. LRU 缓存机制","text":"HashMap 大家都清楚，底层是 数组 + 红黑树 + 链表 （不清楚也没有关系），同时其是无序的，而 LinkedHashMap 刚好就比 HashMap 多这一个功能，就是其提供 有序，并且，LinkedHashMap的有序可以按两种顺序排列，一种是按照插入的顺序，一种是按照读取的顺序（这个题目的示例就是告诉我们要按照读取的顺序进行排序），而其内部是靠 建立一个双向链表 来维护这个顺序的，在每次插入、删除后，都会调用一个函数来进行 双向链表的维护&lt;!—hexoPostRenderEscape:class LRUCache &#123;&lt;/span&gt; private int cap; private Map&lt;Integer, Integer&gt; map = new LinkedHashMap&lt;&gt;(); // 保持插入顺序 &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;LRUCache&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; capacity)&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;this&lt;/span&gt;.cap = capacity; &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; key)&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.keySet().contains(key)) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; value = &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;get&lt;/span&gt;(key); &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;remove&lt;/span&gt;(key); &lt;span class=&quot;hljs-comment&quot;&gt;// 保证每次查询后，都在末尾&lt;/span&gt; &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;put&lt;/span&gt;(key, value); &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; value; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;-1&lt;/span&gt;; &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; key, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; value)&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.keySet().contains(key)) &amp;#123; &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;remove&lt;/span&gt;(key); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt; (&lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;() == cap) &amp;#123; Iterator&amp;lt;Map.E***y&amp;lt;Integer, Integer&amp;gt;&amp;gt; iterator = &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.e***ySet().iterator(); iterator.next(); iterator.&lt;span class=&quot;hljs-built_in&quot;&gt;remove&lt;/span&gt;(); &lt;span class=&quot;hljs-comment&quot;&gt;// int firstKey = map.e***ySet().iterator().next().getValue();&lt;/span&gt; &lt;span class=&quot;hljs-comment&quot;&gt;// map.remove(firstKey);&lt;/span&gt; &amp;#125; &lt;span class=&quot;hljs-built_in&quot;&gt;map&lt;/span&gt;.&lt;span class=&quot;hljs-built_in&quot;&gt;put&lt;/span&gt;(key, value); &amp;#125; &#125;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 另外一个方法是采用双向链表，然后用hashmap存每个节点的key和地址。&lt;!—hexoPostRenderEscape:class LRUCache &#123; class myLinked &#123; int val; int key; myLinked next; myLinked prev; myLinked()&#123;&#125; myLinked(int _key,int _value)&#123;key=_key;val=_value;&#125; &#125; private HashMap&lt;Integer,myLinked&gt; m&lt;/span&gt;=new HashMap&lt;&gt;(); private int size; private int capacity; private myLinked head,tail; public LRUCache(int capacity&lt;/span&gt;) &lt;/span&gt;&lt;/span&gt; &#123; this.size=0; this.capacity=capacity; head=new myLinked(); tail=new myLinked(); head.next=tail; tail.next=head; &#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;get&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; key&lt;/span&gt;)&lt;/span&gt; &amp;#123; myLinked l=m.&lt;span class=&quot;hljs-keyword&quot;&gt;get&lt;/span&gt;(key); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(l==&lt;span class=&quot;hljs-literal&quot;&gt;null&lt;/span&gt;) &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;-1&lt;/span&gt;; movetohead(l); &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; l.val; &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;put&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; key, &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;value&lt;/span&gt;&lt;/span&gt;) &lt;/span&gt; &lt;/span&gt; &#123; myLinked l=m.get(key); if(l!=null) &#123; l.val=value; movetohead(l); &#125; else &#123; myLinked tmp=new myLinked(key,value); m.put(key,tmp); addtohead(tmp); ++size; if(size&gt;capacity) &#123; myLinked tt=removetail(); m.remove(tt.key); size—; &#125; &#125; &#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;addtohead&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;myLinked node&lt;/span&gt;)&lt;/span&gt; &amp;#123; node.prev = head; node.next = head.next; head.next.prev = node; head.next = node; &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;removeNode&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;myLinked node&lt;/span&gt;)&lt;/span&gt; &amp;#123; node.prev.next = node.next; node.next.prev = node.prev; &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;movetohead&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;myLinked node&lt;/span&gt;)&lt;/span&gt; &amp;#123; removeNode(node); addtohead(node); &amp;#125; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;private&lt;/span&gt; myLinked &lt;span class=&quot;hljs-title&quot;&gt;removetail&lt;/span&gt;(&lt;span class=&quot;hljs-params&quot;&gt;&lt;/span&gt;)&lt;/span&gt; &amp;#123; myLinked res = tail.prev; removeNode(res); &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; res; &amp;#125; &#125;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2021/03/29/算法/146. LRU 缓存机制/"},{"title":"5. 最长回文子串 和马拉车算法","text":"主要是利用了回文串中的对称性质。将回文串分成两部分来看待，左边的已知结果，右边的未知，然后利用左边的信息，需要特殊讨论的情况就是左边回文串超出最左边的时候，超出中心并不需要讨论，因为超出中间的时候不会影响右边的结果，因为右边也只是超出中心，并没有超出最右边。算法效率很好。public String longestPalindrome(String s) &#123; int C=0,R=0; int len=s.length(); StringBuilder sbd=new StringBuilder(&quot;&quot;); sbd.append(&quot;!&quot;); sbd.append(&quot;#&quot;); for(int i=0;i&lt;len;i++) &#123; sbd.append(s.charAt(i)); sbd.append(&#x27;#&#x27;); &#125; sbd.append(&quot;?&quot;); int n=sbd.length(); int a[]=new int[n]; for(int i=1;i&lt;n-1;i++) &#123; int mirror=2*C-i; if(i&lt;R) &#123; a[i]=Math.min(a[mirror&lt;0?C:mirror],R-i); a[i]=Math.min(a[i],i-C); &#125; else &#123; a[i]=0; &#125; while(sbd.charAt(i-a[i]-1)==sbd.charAt(i+a[i]+1)) &#123; a[i]++; &#125; if(i+a[i]&gt;R) &#123; R=i+a[i]; C=i; &#125; // System.out.println(a[i]); &#125; int maxlen=0; int center=0; for(int i=1;i&lt;n-1;i++) &#123; if(a[i]&gt;maxlen) &#123; maxlen=a[i]; center=i; &#125; &#125; String res=sbd.substring(center-maxlen,center+maxlen); int reslen=res.length(); StringBuilder s1=new StringBuilder(&quot;&quot;); for(int i=1;i&lt;reslen;i+=2) &#123; s1.append(res.charAt(i)); &#125; return s1.toString(); &#125;","path":"2021/02/19/算法/5. 最长回文子串/"},{"title":"327. 区间和的个数（树状数组+前缀和+离散化）","text":"依然考虑前缀和数组 \\textit{preSum}preSum。 对于每个下标 jj，以 jj 为右端点的下标对的数量，就等于数组 \\textit{preSum}[0..j-1]preSum[0..j−1] 中的所有整数，出现在区间 [\\textit{preSum}[j]-\\textit{upper}, \\textit{preSum}[j]-\\textit{lower}][preSum[j]−upper,preSum[j]−lower] 的次数。 区间和的问题比较适合用线段树和树状数组 很多人都把constexpr和const相比较。 其实，const并不能代表“常量”，它仅仅是对变量的一个修饰，告诉编译器这个变量只能被初始化，且不能被直接修改（实际上可以通过堆栈溢出等方式修改）。而这个变量的值，可以在运行时也可以在编译时指定。 constexpr可以用来修饰变量、函数、构造函数。一旦以上任何元素被constexpr修饰，那么等于说是告诉编译器 “请大胆地将我看成编译时就能得出常量值的表达式去优化我”。 树状数组可以参考class Solution &#123; public: class BIT &#123; private: int n; vector&lt;int&gt; arr; public: int lowerbit(int i) &#123; return i&amp;(-i); &#125; int query(int i)//求A[1 - i]的和 &#123; int res=0; while(i) &#123; res+=arr[i]; i-=lowerbit(i); &#125; return res; &#125; void add(int i,int x)//在i位置加上k &#123; while(i&lt;=n)//树状数组是从1开始的，所以需要有等号 &#123; arr[i]+=x; i+=lowerbit(i); &#125; &#125; BIT(int _n): n(_n),arr(_n+1)&#123;&#125; &#125;; typedef long long ll; int countRangeSum(vector&lt;int&gt;&amp; nums, int lower, int upper) &#123; int len=nums.size(); vector&lt;ll&gt; presum=&#123;0&#125;; ll sum=0; for(int i=0;i&lt;len;i++) &#123; sum+=nums[i]; presum.push_back(sum); &#125; set&lt;ll&gt; se; for(ll p: presum) &#123; se.insert(p); se.insert(p-upper); se.insert(p-lower); &#125; unordered_map&lt;ll,int&gt; m; int index=0; for(ll p: se) &#123; m[p]=index; index++; &#125; int result=0; BIT tree(m.size()); for(int i=0;i&lt;presum.size();i++) &#123; int left=m[presum[i]-upper]; int right=m[presum[i]-lower]; result+=tree.query(right+1)-tree.query(left);//这里有点迷惑，不懂为什么这样弄 tree.add(m[presum[i]]+1,1); &#125; return result; &#125; &#125;;","path":"2021/01/23/算法/327. 区间和的个数/"},{"title":"1584. 连接所有点的最小费用（最小生成树Prime）","text":"朴素版Prim O(n^2) 适用于稠密图 稀疏图的 最小生成树 这个是prim的情况 学习STL，发现STL默认都是使用()比较的，默认比较使用less（即’&lt;’运算符），如sort(a,a+n)，默认将数组按照递增的顺序来排序（前面的元素&lt;后面的嘛），但是优先队列的源码比较奇特，虽然按道理使用less比较应该默认是小根堆（即堆顶元素最小），但是priority_queue&lt;&gt;默认是大根堆的，这是因为优先队列队首指向最后，队尾指向最前面的缘故！每次入队元素进去经排序调整后，优先级最大的元素排在最前面，也就是队尾指向的位置，这时候队首指向优先级最小的元素！所以虽然使用less但其实相当于greater，我们重载运算符的时候比较函数里面写&gt;就相当于&lt;排序方式，这点需要花点时间想想，再来说一说优先队列的这个类型，其实有三个参数：priority_queue，即类型，容器和比较器，后两个参数可以缺省，这样默认的容器就是vector，比较方法是less，也就是默认大根堆，可以自定义写比较方法，但此时若有比较方法参数，则容器参数不可省略！priority_queue&lt;&gt;的可支持的容器必须是用数组实现的容器，如vector，deque，但不能是list（推荐vector），比较方法可以写结构体重载()运算符，也可以用less，greater这些语言实现了的，但是灵活性不够，建议手写重载结构体，或者——如果不想写比较结构体的话，就将后面的两个参数缺省，直接重载类型的&lt;运算符，所以这里写的时候要注意优先队列和其他容器比较器的区别。 class Solution &#123; public: int a[1002][1002]; int sta[1002]; struct node &#123; int weight,p1,p2; &#125;; struct cmp &#123; bool operator()(node a,node b) &#123; return a.weight &gt; b.weight; &#125; &#125;; int minCostConnectPoints(vector&lt;vector&lt;int&gt;&gt;&amp; points) &#123; int INF=0x3f3f3f3f; int len=points.size(); vector&lt;vector&lt;int&gt;&gt; dist(len+1,vector&lt;int&gt;(len+1,INF)); for(int i=0;i&lt;points.size();i++) &#123; for(int j=0;j&lt;points.size();j++) &#123; dist[j][i]=dist[i][j]=abs(points[i][0]-points[j][0])+abs(points[i][1]-points[j][1]); &#125; &#125; vector&lt;int&gt; po; po.push_back(0); sta[0]=1; int result=0; priority_queue &lt;node,vector&lt;node&gt;,cmp&gt; qu; for(int i=1;i&lt;len;i++) &#123; node tt = &#123;weight:dist[0][i], p1:0,p2:i&#125;; qu.push(tt); &#125; while(po.size()&lt;len) &#123; while(!qu.empty()) &#123; node tmp1=qu.top(); if(sta[tmp1.p2]==1&amp;&amp;sta[tmp1.p1]==1) &#123; qu.pop(); continue; &#125; else break; &#125; node tmp=qu.top(); // cout&lt;&lt;tmp.p1&lt;&lt;&quot; &quot;&lt;&lt;tmp.p2&lt;&lt;endl; qu.pop(); sta[tmp.p2]=1; for(int i=0;i&lt;len;i++) &#123; if(sta[i]==1||i==tmp.p2) continue; // cout&lt;&lt;dist[tmp.p2][i]&lt;&lt;&quot; &quot;&lt;&lt;tmp.p2&lt;&lt;&quot; &quot;&lt;&lt;i&lt;&lt;endl; node tt = &#123;weight:dist[tmp.p2][i], p1:tmp.p2,p2:i&#125;; qu.push(tt); &#125; result+=tmp.weight; po.push_back(1); &#125; return result; &#125; &#125;;","path":"2021/01/22/算法/1584. 连接所有点的最小费用/"},{"title":"能谱CT物理原理","text":"CNR = contrast-to-noise ratio, EID = energy-integrating detector, PCD= photon-counting detector 相对于传统的能量集成探测器CT，光子计数CT将允许减少辐射剂量，提高空间分辨率，纠正光束硬化伪影，并使用替代对比剂，同时为定量成像创造机会。 EID CT， x光打到一个吸收层上，吸收层吸收x射线光子，然后转化为可见光光子，可见光光子被一个由半导体材料制成的光电二极管吸收，光电二极管测量入射光的数量，并产生一个电信号，该电信号与在测量期间沉积的总能量成比例，而不是单个x射线光子的能量。 光子计数探测器(PCDs)，另一方面，不需要一个单独的层来转换x射线到光，但由一个单一的厚层半导体二极管(1.6-30毫米取决于材料)，在上面施加一个大的电压。如果入射的x射线被半导体吸收，它就会产生一团正负电荷(6)，迅速地彼此分离。移动的电荷在连接在电极上的电线上产生一个电脉冲，并被电子读出电路记录下来。因此，pcd直接将单个x射线光子转换成电信号，不像当前CT中使用的EIDs，需要额外的步骤将光子转换成可见光。 每一个光子撞击探测器元件，都会产生一个电脉冲，其高度与光子储存的能量成正比。探测器的电子系统计算高度超过预设阈值水平的脉冲的数目。阈值设置在高于电子噪声水平但低于入射光子产生的脉冲水平。此外，通过将每个脉冲与几个阈值水平进行比较，探测器可以根据光子的能量将入射光子分类成若干个能量箱(通常为2到8个)(图3)。因此，电子噪声有效地排除在光子和/或脉冲计数之外，所以一次射线可以产生很多个能谱段。 PCD计数器暂时没有商业应用。使用特定能量测量和能量阈值来拒绝电子噪声。促进新的成像方法，如k-边缘减法原因：造成性能下降的影响取决于探测器中使用的传感器材料的类型。PCDs的研究主要集中在碲化镉、碲化镉锌和硅(6) 康普顿效应 在理想PCD中，光子只在它所撞击的探测器元件中产生信号。在现实中，有几个物理效应可能导致单个光子在多个探测器元素中被登记为计数事件。在硅探测器中，很大一部分光子在探测器材料中通过康普顿散射相互作用，将一小部分能量沉积在探测器元素中。然后，散射光子就会向一个新的、随机的方向移动，可能会把剩余的能量储存在另一个探测器元素中，对于碲化镉和碲化镉锌，康普顿散射概率较低。然而，在原始相互作用中沉积的部分能量可能会以荧光x射线的形式释放，它可以被邻近的探测器元素吸收，如图4,a(8,9)所示。尽管康普顿散射和x射线荧光是不同的物理效应，但它们都导致光子的能量范围不正确，并且可能被多次计算。 电荷共享效应 在硅和镉碲化或镉锌碲化探测器中，探测器元件之间的串扰也可以归因于一种称为电荷共享的效应。如图4,B所示，每个被吸收的x射线光子都会在传感器材料中产生大量的正负电荷。如果光子在两个探测器元件之间的边界附近被吸收，电荷云的一部分可能会延伸到相邻的探测器元件，这可以记录光子能量的一部分。结果是光子被计数两次。 各种各样的串扰在不同的方面降低了图像质量。首先，它们会降低空间分辨率(即模糊图像)，因为它们会导致光子被记录在错误的探测器元件中。其次，它们可能会导致光子被多次计数。这降低了图像的对比度-噪声比(CNR)，因为所有在计数光子数量中引入额外随机性的影响都会产生额外的图像噪声。第三，不同形式的串扰降低了探测器的能量分辨率，降低了能量信息的可靠性，并导致材料选择性图像中的图像噪声增加。 堆积效应 需要一个快速探测器来计数单个光子。每平方毫米每秒有几亿光子撞击探测器，因此传感器材料必须能够快速传输释放的电荷，读出电子必须能够足够快地计算产生的脉冲。对足够快速和稳定的探测器的需求是光子计数CT扫描仪最近才开始用于临床CT剂量水平的原因之一(13)。然而，PCDs广泛应用于PET、SPECT和双能量x线吸收仪，并已被引入一种商业乳房x线成像系统(微剂量;Philips Healthcare, Best，荷兰)，那里的计数率要低得多。如果光子到达得太快，一些由此产生的电脉冲会相互叠加，这种现象被称为脉冲堆积 如果两个连续脉冲几乎同时发生，它们将被记录为一个能量等于两个入射光子能量之和的单个脉冲。如果脉冲到达时间的差异稍微大一些，探测器可能会将它们记录为两个单独的计数，但部分重叠仍然会导致测量光子能量的误差(图5,B)。堆积对图像质量有两种影响。首先，计数损失增加了图像噪声，因为较少的光子有助于测量(14)。第二，能量分辨率下降，类似于相声(14-16)的效果。因为在高计数率下会发生堆积，所以它不会降低图像的所有部分这些影响可以通过设计更小的探测器元件和更快的计数器来最小化。然而，当探测器元件变得更小时，在堆积和电荷共享之间有一个折衷。 由于具有不同能量的光子的加权方式，理想PCD可以产生比理想EID更低的图像噪声。由于EID测量的是吸收的总x射线能量，高能光子对总信号的贡献相对于低能量光子。然而，这种加权并不能产生最佳的CNR，因为在高能量时组织对比度较低。为了优化图像的CNR，可以将最大的权重分配给能量较低、组织间对比度最高的光子，如图7所示。能量分解PCD能够为低能量箱分配更高的权重因子，从而提高CNR(4,18,19)。给予低能量光子更高重量的一个缺点是，由于x射线光谱中低能量部分的组织衰减更加非均匀，因此会导致光束硬化现象的增加(20) 在x射线计算机断层扫描(CT)中，具有不同元素组成的材料可以用CT图像上的相同像素值(即CT数)表示，这取决于材料的质量密度 在双能量CT中，以第二能量获得额外的衰减测量，允许两种材料的区分，这个双能CT，就是加两个能量kev，和能谱CT划分能量箱有所不同。 双能量CT的技术途径 Two Temporally Sequential Scans 两个时间顺序扫描,进行了两次时间顺序扫描，以获取两个管电位处的数据,由于数据不是同时获得的，患者在两次扫描之间发生的运动导致结果图像和材料组成信息的严重退化,后面有一种单轴旋转改进的方法，但是效果应该也不是很好，然后我也没太看懂，尴尬。这个方法可以在任何CT扫描仪上执行(不需要特殊硬件 Rapid Switching of X-Ray Tube Potential x射线管电位的快速切换，允许在低和高管电位下获得交替投影测量，应用主要是骨骼密度测量。然而，在低管电位测量中，管电流不能迅速增加到足够快的程度，从而在低管电位和高管电位数据集中都能达到相当的噪声水平。这种噪音上的差异限制了该技术在骨密度测量之外的应用在连续视图之间切换管电位要求从低到高管电位的转换时间小于一毫秒。此外，过渡必须尽可能突然，以最大限度地分离测量数据的能量，尽管快速调制x射线管电流的困难可能在低能量数据中造成高噪音水平或来自高能量投影的过量剂量。然而，这个问题可以通过对低和高能量投影使用不对称采样来解决。通过这种方式，在不迅速改变管电流的情况下，获得了低能量投影所需的增加管电流-时间积低能量和高能量数据集的近同时数据采集。允许通过使用投影数据或重建图像来实现双能量物质分解算法。减少计算出的“虚拟单能量”图像中的光束硬化现象，需要专门的硬件。能量谱的高重叠 Multilayer Detector 多层探测器就是探测头有两层，里层的获得低能量的信息，外层的获得高能量的信息。低能耗数据收集从前面或内层的探测器层和高能数据收集从后面或外层探测器层(图5)。这类似于多层探测器的使用双能x线摄影(6 - 8)。为了在低和高能量图像中获得相同的噪声，使用了不同的探测器厚度。低能量数据集和高能量数据集的同时数据采集。所有图像数据都以支持特定材料成像的方式获取，但是需要专门的硬件。能量谱的高重叠。低和高能量图像的噪声水平可能不同 Dual x-ray sources双x射线源双源CT是将两个x射线源和两个数据采集系统安装在同一架龙门上，相互垂直放置的CT系统因为两个管同时被激发，原始主光子来自一个管的散射辐射可能被另一个管的探测器探测到，反之亦然。这将降低光谱分离，并要求实现适当的散射校正算法(12)。双源方法的一个优点是能够独立优化每个管-探测器对的光谱过滤，从而增加在特定物质图像中光谱分离和增加信噪比管电流和管过滤可以分别优化每个管电位。相对较低的光谱重叠程度，这提高了材料特定图像的对比噪声比。光束硬化校正应用于图像重建之前，允许在图像域中创建特定材料的图像。需要专门的硬件。在低能和高能数据之间有90度的相移。同时使用这两种x射线源允许散射辐射，其原始的主光子来自一个管被另一个管的探测器检测到，需要专门的散射校正。","path":"2021/01/18/医学图像/能谱CT物理原理/"},{"title":"匈牙利算法（二分图）","text":"匹配：在图论中，一个匹配（matching）是指一个边的集合，其中任意两条边都没有公共顶点。 最大匹配：一个图所有匹配中，所含匹配边数最多的匹配，称为这个图的最大匹配 完美匹配：如果一个图的某个匹配中，所有的顶点都是匹配点，那么它就是一个完美匹配。完美匹配一定是最大匹配（完美匹配的任何一个点都已经匹配，添加一条新的匹配边一定会与已有的匹配边冲突），但并非每个图都存在完美匹配。 交替路径：从一个未匹配点出发，依次经过非匹配边、匹配边、非匹配边…形成的路径称为交替路径。 增广路径：从一个未匹配点出发，走交替路，如果途径另一个未匹配点（出发的点不算），则这条交替路称为增广路（agumenting path）。 增广路径性质： （1）P的路径长度必定为奇数，第一条边和最后一条边都不属于M，因为两个端点分属两个集合，且未匹配。 （2）P经过取反操作可以得到一个更大的匹配M’。 （3）M为G的最大匹配当且仅当不存在相对于M的增广路径。 匈牙利算法：利用增广路径求二分图的最大匹配算法称作匈牙利算法。（匈牙利数学家Edmonds于1965年提出）。基本思想：通过寻找增广路径，把增广路径中的匹配边和非匹配边的相互交换，这样就会多出一条匹配边，直到找不到增广路径为止。 就是每次从一个未匹配点出发，然后依次经过非匹配边、匹配边、非匹配边，并且途径另一个未匹配点，然后匹配边和非匹配边的相互交换，这样就会多出一个匹配边，直到找不到增广路径。 这是leetcodeLCP 04. 覆盖你有一块棋盘，棋盘上有一些格子已经坏掉了。你还有无穷块大小为1 * 2的多米诺骨牌，你想把这些骨牌不重叠地覆盖在完好的格子上，请找出你最多能在棋盘上放多少块骨牌？这些骨牌可以横着或者竖着放。 输入：n, m代表棋盘的大小；broken是一个b * 2的二维数组，其中每个元素代表棋盘上每一个坏掉的格子的位置。 输出：一个整数，代表最多能在棋盘上放的骨牌数。 该题看上去与二分图匹配无关，但其实可以转化成二分图匹配。一个骨牌恰好覆盖两格，而这两格必须是相邻的。因此如果把相邻的两格看成分别属于X、Y两个集合的节点，相邻的节点之间认为有一条（黑色）边相连，放骨牌看做将被覆盖的两格之间的边染成红色；由于一格（一个节点）只能被一个骨牌覆盖（被一条红边连接），那么连接的方式整个就是二分图的一个匹配。如何构建这张图呢？由于相邻的点属于不同的集合，因此仿照国际象棋的棋盘“间隔地”染色就好了。于是，相邻格子之间对应的边连接的都是属于不同集合的节点，相同集合的节点因为对应的不是相邻格子都不直接相连，形成了二分图。最后，能放置骨牌的最大数量就是二分图最大匹配中的边数。 二分图最大匹配可以用匈牙利算法解决，也可以转化成最大流解决，本次使用前者。匈牙利算法的核心操作其实与后者还挺像，后者是寻找增流路径，而前者是寻找一个“交互道路”（节点颜色交替的道路），其实都可以理解为增广道路（augmentation path）。只不过，由于在二分图匹配中一条边要么就是选要么就是不选，相当于是特殊的“流”，0或者1，因此最大流的“退流”操作，被简化为了异或操作。无论是从算 示例 1： 输入：n = 2, m = 3, broken = [[1, 0], [1, 1]]输出：2解释：我们最多可以放两块骨牌：[[0, 0], [0, 1]]以及[[0, 2], [1, 2]]。（见下图）&lt;!—hexoPostRenderEscape:class Solution &#123;public: int row=0,col=0; int grid[10][10]; int erge[100][100]; int matchvi[100]; int belong[100]; int domino(int n, int m, vector&lt;vector&lt;int&gt;&gt;&amp; broken) &#123; row=n,col=m; int a[4][2]=&#123;1,0,-1,0,0,-1,0,1&#125;; for(auto g: broken) &#123; grid[g[0]][g[1]]=1; &#125; for(int i=0;i&lt;row;i++) &#123; for(int j=0;j&lt;col;j++) &#123; if(grid[i][j]) continue; for(int k=0;k&lt;4;k++)//构造边 &#123; int arow=a[k][0]+i,acol=a[k][1]+j; if(arow&lt;0||arow&gt;=row||acol&lt;0||acol&gt;=col||grid[arow][acol]) continue; // cout&lt;&lt;1; erge[icol+j][arowcol+acol]=erge[arowcol+acol][icol+j]=1; &#125; &#125; &#125; return hug(); &#125; int hug() &#123; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; res=&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;;i&amp;lt;row*col;i++) &amp;#123; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; tmp1=i/col; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; tmp2=i%col; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(grid[tmp1][tmp2]) &lt;span class=&quot;hljs-keyword&quot;&gt;continue&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(!((tmp1+tmp2)&amp;amp;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;))&lt;span class=&quot;hljs-comment&quot;&gt;//为偶数格子跳过，对奇数找匹配&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;continue&lt;/span&gt;; memset(matchvi, &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;, sizeof(matchvi)); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(match(i)) res++; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; res; &amp;#125; &lt;span class=&quot;hljs-built_in&quot;&gt;bool&lt;/span&gt; match(&lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; x) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;;i&amp;lt;row*col;i++) &amp;#123; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; tmp1=i/col; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; tmp2=i%col; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(((tmp1+tmp2)&amp;amp;&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;))&lt;span class=&quot;hljs-comment&quot;&gt;//如果是偶数跳过&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;continue&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;((erge[x][i]==&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;)&amp;amp;&amp;amp;(matchvi[i]==&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;)) &amp;#123; matchvi[i]=&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(belong[i]==&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;||match(belong[i])) &amp;#123;&lt;span class=&quot;hljs-comment&quot;&gt;//如果i没有确定，或者确定的人可以换&lt;/span&gt; belong[i]=x; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;; &amp;#125; &amp;#125; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-literal&quot;&gt;false&lt;/span&gt;; &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2021/01/16/算法/二分图_匈牙利算法/"},{"title":"785. 判断二分图（染色法）","text":"一个图是二分图，当且仅当图中不含有奇数环二分图的方法，染色法，就是通过对节点进行着色，算法就是深搜的方法 bool res=true; int sta[105]; bool isBipartite(vector&lt;vector&lt;int&gt;&gt;&amp; graph) &#123; for(int i=0;i&lt;graph.size();i++) &#123; if(sta[i]==0) paint(i,1,graph); &#125; return res; &#125; void paint(int t,int color,vector&lt;vector&lt;int&gt;&gt;&amp; g) &#123; if(res==false) return ; for(int i=0;i&lt;g[t].size();i++) &#123; if(sta[g[t][i]]==0) &#123; sta[g[t][i]]=-color; paint(g[t][i],-color,g); &#125; else if(sta[g[t][i]]==-color) continue; else &#123; res=false; return ; &#125; &#125; &#125;","path":"2021/01/14/算法/785. 判断二分图/"},{"title":"787. K 站中转内最便宜的航班（bellman-ford）","text":"循环n次遍历所有边u-&gt;v,权w (松弛操作)dist[v]=min(dist[v], dist[u]+w) 应用处理有负权边的图循环次数的含义：循环K次后，表示不超过K条边的最短距离有边数限制的最短路，只能用Bellman-Ford算法，不能用spfa算法如果有负权回路，最短路不一定存在 - Bellman-Ford算法可以求出是否有负环第n循环后，还有更新，说明路径上有n+1个点，也就是存在环，还有更新，说明环是负环循环n次后, 所有的边u-&gt;v,权w满足三角不等式:dist[v]&lt;=dist[u]+wint findCheapestPrice(int n, vector&lt;vector&lt;int&gt;&gt;&amp; flights, int src, int dst, int K) &#123; const int INF=0x3f3f3f3f; vector&lt;int&gt; res(n+1,INF); res[src]=0; for(int i=0;i&lt;=K;i++) &#123; vector&lt;int&gt; tmp(res); for(int j=0;j&lt;flights.size();j++) &#123; if(flights[j][2]+tmp[flights[j][0]]&lt;res[flights[j][1]]) res[flights[j][1]]=flights[j][2]+tmp[flights[j][0]]; &#125; &#125; if(res[dst]==INF) return -1; return res[dst]; &#125;","path":"2021/01/13/算法/787. K 站中转内最便宜的航班/"},{"title":"743. 网络延迟时间（迪杰斯特拉+SPFA+floyd)","text":"有 N 个网络节点，标记为 1 到 N。 给定一个列表 times，表示信号经过有向边的传递时间。 times[i] = (u, v, w)，其中 u 是源节点，v 是目标节点， w 是一个信号从源节点传递到目标节点的时间。 现在，我们从某个节点 K 发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回 -1。 输入：times = [[2,1,1],[2,3,1],[3,4,1]], N = 4, K = 2输出：2 主要就是迪杰斯特拉的代码这个是没有优化的结果，每次选的是距离初始点最小距离的点。集合S：当前已经确定最短距离的点 dist[1] = 0, dist[i] = 正无穷for v: 1 ~ nt &lt;- 不在s中的距离最近的点s &lt;- t用t更新其他点的距离朴素的Dijkstra算法往往是稠密图，用邻接矩阵来存储class Solution &#123; public: int networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int N, int K) &#123; vector&lt;vector&lt;int&gt;&gt; mat(N+1,vector&lt;int&gt;(N+1,0x3f3f3f3f)); vector&lt;int&gt; res(N+1,0x3f3f3f3f); vector&lt;int&gt; sta(N+1,0);//值为1点被被选，为0没被选 int result=-1; sta[K]=1; res[K]=0; for(int i=0;i&lt;times.size();i++) &#123; mat[times[i][0]][times[i][1]]=times[i][2]; if(times[i][0]==K) &#123; res[times[i][1]]=times[i][2]; &#125; &#125; // cout&lt;&lt;&quot;1&quot;&lt;&lt;endl; for(int i=0;i&lt;N-1;i++) &#123; int t=-1; for(int j=1;j&lt;=N;j++) &#123; if(sta[j]==0&amp;&amp;(t==-1||res[j]&lt;res[t])) &#123; t=j; &#125; &#125; sta[t]=1; for(int j=1;j&lt;=N;j++) &#123; if(res[t]+mat[t][j]&lt;res[j]) &#123; res[j]=res[t]+mat[t][j]; &#125; &#125; &#125; for(int i=1;i&lt;=N;i++) &#123; if(res[i]==0x3f3f3f3f) return -1; if(i==K) continue; result=max(result,res[i]); &#125; return result; &#125; &#125;; 集合S：当前已经确定最短距离的点 dist[1] = 0, dist[i] = 正无穷for v: 1 ~ nt &lt;- 不在s中的 与起始点距离最近的点 ；小顶堆维护 O(logN)s &lt;- t; O(1)用t更新其他点的距离 ; O(mlogN)稀疏图用堆优化版的Dijkstra算法这个是优化之后的，主要是用稀疏图替换邻接矩阵，同时用优先队列替换遍历搜寻最小的边。 int networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int N, int K) &#123; const int INF=0x3f3f3f3f; vector&lt;int&gt; stat(N+1,0); vector&lt;int&gt; res(N+1,INF); vector&lt;vector&lt;pair&lt;int,int&gt;&gt;&gt; m(N+1); priority_queue&lt;pair&lt;int,int&gt;,vector&lt;pair&lt;int,int&gt;&gt;,greater&lt;pair&lt;int,int&gt;&gt;&gt; queue; queue.push(&#123;0,K&#125;); res[K]=0; int result=0; for(int i=0;i&lt;times.size();i++) &#123; m[times[i][0]].push_back(&#123;times[i][2],times[i][1]&#125;); &#125; while(!queue.empty()) &#123; auto tmp=queue.top(); queue.pop(); if(stat[tmp.second]==1) continue; stat[tmp.second]=1; for(auto &amp;p: m[tmp.second]) &#123; if(p.first+tmp.first&lt;res[p.second])//tmp代表我们找到的下一个加入的点，然后找这个点的所有的边来更新 &#123; res[p.second]=p.first+tmp.first; queue.push(&#123;p.first+tmp.first,p.second&#125;); &#125; &#125; &#125; for(int i=1;i&lt;=N;i++) &#123; if(res[i]==INF) return -1; if(i==K) continue; result=max(result,res[i]); &#125; return result; &#125; SPFA算法 首先相比Dijkstra算法，SPFA可以处理带有负权变的图。（个人认为原因是SPFA在进行松弛操作时就是那个更新距离的地方可以对某一条边重复进行松弛，因为可能某一个点会被多次加入队列，这个可以这么理解，如果在没有负边的情况下松弛一次就是说一条最短路径最多只能经过松弛的这个点一次，这个在没有负边的情况下是显而易见的，当有负边的情况下，经过这个点多次就可能获得更小的最短路径。当我们松弛了某个点超过N次，就可以认为出现了负环，为什么是超过N次呢，极端情况下如果没有负环那么每次加入一次点我们都可以认为这个点与其他点连成的一条边加入最短路径中，如果加了N-1条边还不是最短路径，到第n次那肯定就是有负环了。（大家都写的大于N次），我个人交代码试了以下，好像到n就可以了，但是保险还是大于N更好） 实现方法： 建立一个队列，初始时队列里只有起始点，再建立一个表格记录起始点到所有点的最短路径（该表格的初始值要赋为极大值，该点到他本身的路径赋为0）。然后执行松弛操作，用队列里有的点作为起始点去刷新到所有点的最短路，如果刷新成功且被刷新点不在队列中则把该点加入到队列最后。重复执行直到队列为空。 判断有无负环： 如果某个点进入队列的次数超过N次则存在负环（SPFA无法处理带负环的图，但是可以判断是否出现负权环）,这一点和ford算法是一样的，超过N次松弛就代表出现的最短路径长度是大于等于N的，这样的简单路径是不存在的。 我们可以看出代码上其实是和迪杰斯特拉算法很像的。&lt;!—hexoPostRenderEscape: int networkDelayTime(vector&lt;vector&lt;int&gt;&gt;&amp; times, int N, int K) &#123; const int INF=0x3f3f3f3f; vector&lt;int&gt; stat(N+1,0); vector&lt;int&gt; res(N+1,INF); vector&lt;vector&lt;pair&lt;int,int&gt;&gt;&gt; m(N+1);//距离队列 priority_queue&lt;pair&lt;int,int&gt;,vector&lt;pair&lt;int,int&gt;&gt;,greater&lt;pair&lt;int,int&gt;&gt;&gt; queue;//刷新队列 queue.push(&#123;0,K&#125;); res[K]=0; stat[K]=1; int result=0; for(int i=0;i&lt;times.size();i++) &#123; m[times[i][0]].push_back(&#123;times[i][2],times[i][1]&#125;); &#125; while(!queue.empty()) &#123; auto tmp=queue.top(); queue.pop(); stat[K]=0; // if(stat[tmp.second]==1) // continue; // stat[tmp.second]=1; for(auto &amp;p: m[tmp.second]) &#123; if(p.first+tmp.first&lt;res[p.second])//first 距离，second 目的点 &#123; res[p.second]=p.first+tmp.first; if(stat[K]==0) &#123; queue.push(&#123;p.first+tmp.first,p.second&#125;); stat[p.second]=1; &#125; &amp;#125; &amp;#125; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;hljs-number&quot;&gt;1&lt;/span&gt;;i&amp;lt;=N;i++) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(res[i]==INF) &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;-1&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(i==K) &lt;span class=&quot;hljs-keyword&quot;&gt;continue&lt;/span&gt;; result=max(result,res[i]); &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; result; &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; floyd算法 这个也是求最短路径的算法，是求任意两点之间的最短路径，可以有负边，时间复杂度为O(N^3),空间复杂度为O(N^2),算法主要是考虑的是从i到j经过的点的号不超过k的路径dist[k][i][j]=min(dist[k-1][i][j],dist[k-1][i][k]+dist[k-1][k][j]); 这个可以通过动态规划进行空间优化。//主要的代码如下 for (int k = 0; k &lt; n; k++) &#123; for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j]); &#125; &#125; &#125;","path":"2021/01/13/算法/743. 网络延迟时间/"},{"title":"177. 第N高的薪水","text":"编写一个 SQL 查询，获取 Employee 表中第 n 高的薪水（Salary）。 +——+————+| Id | Salary |+——+————+| 1 | 100 || 2 | 200 || 3 | 300 |+——+————+例如上述 Employee 表，n = 2 时，应返回第二高的薪水 200。如果不存在第 n 高的薪水，那么查询应返回 null。 +————————————+| getNthHighestSalary(2) |+————————————+| 200 |+————————————+ SELECT e1.salary FROM employee e1 JOIN employee e2 ON e1.salary &lt;= e2.salary GROUP BY e1.salary HAVING count(DISTINCT e2.salary) = N","path":"2021/01/04/数据库/mysql177. 第N高的薪水/"},{"title":"601. 体育馆的人流量","text":"表：Stadium+———————-+————-+| Column Name | Type |+———————-+————-+| id | int || visit_date | date || people | int |+———————-+————-+visit_date 是表的主键每日人流量信息被记录在这三列信息中：序号 (id)、日期 (visit_date)、 人流量 (people)每天只有一行记录，日期随着 id 的增加而增加 编写一个 SQL 查询以找出每行的人数大于或等于 100 且 id 连续的三行或更多行记录。 返回按 visit_date 升序排列的结果表。 查询结果格式如下所示。 Stadium table:+———+——————+—————-+| id | visit_date | people |+———+——————+—————-+| 1 | 2017-01-01 | 10 || 2 | 2017-01-02 | 109 || 3 | 2017-01-03 | 150 || 4 | 2017-01-04 | 99 || 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-09 | 188 |+———+——————+—————-+ Result table:+———+——————+—————-+| id | visit_date | people |+———+——————+—————-+| 5 | 2017-01-05 | 145 || 6 | 2017-01-06 | 1455 || 7 | 2017-01-07 | 199 || 8 | 2017-01-09 | 188 |+———+——————+—————-+id 为 5、6、7、8 的四行 id 连续，并且每行都有 &gt;= 100 的人数记录。请注意，即使第 7 行和第 8 行的 visit_date 不是连续的，输出也应当包含第 8 行，因为我们只需要考虑 id 连续的记录。不输出 id 为 2 和 3 的行，因为至少需要三条 id 连续的记录。 select distinct t1.* from Stadium t1,Stadium t2, Stadium t3 where t1.people&gt;=100 and t2.people&gt;=100 and t3.people&gt;=100 and ( (t1.id=t2.id-1 and t2.id=t3.id-1) or (t1.id=t2.id+1 and t2.id=t3.id-2) or (t1.id=t2.id+1 and t2.id=t3.id+1)) order by id;","path":"2021/01/04/数据库/mysql601. 体育馆的人流量/"},{"title":"626. 换座位","text":"小美是一所中学的信息科技老师，她有一张 seat 座位表，平时用来储存学生名字和与他们相对应的座位 id。 其中纵列的 id 是连续递增的 小美想改变相邻俩学生的座位。 你能不能帮她写一个 SQL query 来输出小美想要的结果呢？ 示例： +————-+————-+| id | student |+————-+————-+| 1 | Abbot || 2 | Doris || 3 | Emerson || 4 | Green || 5 | Jeames |+————-+————-+假如数据输入的是上表，则输出结果如下： +————-+————-+| id | student |+————-+————-+| 1 | Doris || 2 | Abbot || 3 | Green || 4 | Emerson || 5 | Jeames |+————-+————-+注意： 如果学生人数是奇数，则不需要改变最后一个同学的座位。 我第一次发现mysql还能这样写判断，学习一个。select if(id%2=0, id-1, if(id=(select count(*) from seat), id, id+1 ))as id,student from seat order by id;","path":"2021/01/04/数据库/mysql626. 换座位/"},{"title":"886. 可能的二分法（二分图+染色法）","text":"染色，一个染色成-1，一个染色成1.，出现冲突就false,否则为true。 我之前只记录单向边，然后dfs中间也没判断，然后就有样例一直过不了，很奇怪。class Solution &#123; bool ans = true; public: bool possibleBipartition(int N, vector&lt;vector&lt;int&gt;&gt;&amp; dislikes) &#123; if(dislikes.size() &lt;= 2) return true; vector&lt;int&gt; color(N+1, 0); vector&lt;vector&lt;int&gt;&gt; link(N+1); for(auto&amp; d : dislikes)//建图 &#123; link[d[0]].push_back(d[1]); link[d[1]].push_back(d[0]);//这里反向的也要选择不然容易出错 &#125; for(int i = 1; i &lt;= N; i++) &#123; if(color[i] == 0&amp;&amp;link[i].size()!=0)//未着色的 &#123; color[i] = 1;//着色为1 dfs(link,i, 1, color); if(!ans) return false; &#125; &#125; return true; &#125; void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; link,int id, int col, vector&lt;int&gt; &amp;color) &#123; if(!ans) return; int nextcol = -col;//跟我相连的(不喜欢的人)颜色相反 for(int i=0;i&lt;link[id].size();i++) &#123; if(color[link[id][i]] == col)//颜色相同，出错 ans = false; if(color[link[id][i]] == 0)//没有访问过的，继续着色 &#123; color[link[id][i]] = nextcol; dfs(link,link[id][i], nextcol, color); &#125; &#125; &#125; &#125;;","path":"2020/12/24/算法/886. 可能的二分法/"},{"title":"127. 单词接龙","text":"我一开始用的dfs，然后超时了，剪支了还是超时，写普通的广度优先搜索还是超时，这个是双向的bfs. 具体地，可以创建虚拟节点。对于单词 hit，我们创建三个虚拟节点 it、ht、hi*，并让 hit 向这三个虚拟节点分别连一条边即可。如果一个单词能够转化为 hit，那么该单词必然会连接到这三个虚拟节点之一。对于每一个单词，我们枚举它连接到的虚拟节点，把该单词对应的 id 与这些虚拟节点对应的 id 相连即可。 最后我们将起点加入队列开始广度优先搜索，当搜索到终点时，我们就找到了最短路径的长度。注意因为添加了虚拟节点，所以我们得到的距离为实际最短路径长度的两倍。同时我们并未计算起点对答案的贡献，所以我们应当返回距离的一半再加一的结果。 class Solution &#123; public: unordered_map&lt;string, int&gt; wordId; vector&lt;vector&lt;int&gt;&gt; link; int nodeNum = 0; void addword(string &amp; s) &#123; if(!wordId.count(s)) &#123; wordId[s]=nodeNum++; link.emplace_back(); &#125; &#125; void geneword(string &amp; s) &#123; addword(s); int n1=wordId[s]; int len=s.size(); for(char&amp; it : s) &#123; char a=it; it=&#x27;*&#x27;; addword(s); int n2=wordId[s]; it=a; // cout&lt;&lt;1; link[n1].push_back(n2); link[n2].push_back(n1); // cout&lt;&lt;2; &#125; &#125; int ladderLength(string beginWord, string endWord, vector&lt;string&gt;&amp; wordList) &#123; for(auto &amp; word : wordList) &#123; geneword(word); &#125; geneword(beginWord); if(!wordId.count(endWord)) return 0; int endnum=wordId[endWord]; int beginnum=wordId[beginWord]; queue&lt;int&gt; qbegin; queue&lt;int&gt; qend; qbegin.push(beginnum); qend.push(endnum); vector&lt;int&gt; disbegin(nodeNum+2,INT_MAX); vector&lt;int&gt; disend(nodeNum+2,INT_MAX); disbegin[beginnum]=0; disend[endnum]=0; while(!qbegin.empty()&amp;&amp;!qend.empty()) &#123; int beginlen=qbegin.size(); for(int i=0;i&lt;beginlen;i++) &#123; int w=qbegin.front(); qbegin.pop(); if(disend[w]!=INT_MAX) return (disend[w]+disend[w])/2+1; for(int j=0;j&lt;link[w].size();j++) &#123; if(disbegin[link[w][j]]==INT_MAX) &#123; qbegin.push(link[w][j]); disbegin[link[w][j]]=disbegin[w]+1; &#125; &#125; &#125; int endlen=qend.size(); for(int i=0;i&lt;endlen;i++) &#123; int w=qend.front(); qend.pop(); if(disbegin[w]!=INT_MAX) &#123; return (disend[w]+disend[w])/2+1; &#125; for(int j=0;j&lt;link[w].size();j++) &#123; if(disend[link[w][j]]==INT_MAX) &#123; qend.push(link[w][j]); disend[link[w][j]]=disend[w]+1; &#125; &#125; &#125; &#125; return 0; &#125; &#125;;","path":"2020/12/24/算法/127. 单词接龙/"},{"title":"1293. 网格中的最短路径(状压dp+记忆化搜索）","text":"状态空间搜索解题模板class Solution &#123; public: struct State &#123; int x,y; int r; State(int x1,int y1,int r1) &#123; x=x1; y=y1; r=r1; &#125; &#125;; int dx[4]=&#123;1,0,-1,0&#125;; int dy[4]=&#123;0,1,0,-1&#125;; int shortestPath(vector&lt;vector&lt;int&gt;&gt;&amp; g, int k) &#123; int m=g.size(); int n=g[0].size(); if(k&gt;=m+n-3) return m+n-2; vector&lt;vector&lt;vector&lt;bool&gt;&gt;&gt; visited(m, vector&lt;vector&lt;bool&gt;&gt;(n, vector&lt;bool&gt;(k + 1, 0))); queue&lt;State&gt; Q; Q.emplace(0, 0, k); int step = 0; while(!Q.empty()) &#123; int s = Q.size(); while(s--) &#123; auto p = Q.front(); Q.pop(); int x = p.x, y = p.y; int r = p.r; if(x == m - 1 &amp;&amp; y == n - 1 &amp;&amp; r &gt;= 0) return step; if(visited[x][y][r] == 1) continue; visited[x][y][r] = 1; for(int k = 0; k &lt; 4; k++) &#123; if(x + dx[k] &gt;= 0 &amp;&amp; x + dx[k] &lt; m &amp;&amp; y + dy[k] &gt;= 0 &amp;&amp; y + dy[k] &lt; n) &#123; if(g[x + dx[k]][y + dy[k]] == 1 &amp;&amp; r &gt;= 1) Q.emplace(x + dx[k], y + dy[k], r - 1); else if(g[x + dx[k]][y + dy[k]] == 0) Q.emplace(x + dx[k], y + dy[k], r); &#125; &#125; &#125; step++; &#125; return -1; &#125; &#125;;","path":"2020/11/02/算法/1293. 网格中的最短路径/"},{"title":"901. 股票价格跨度","text":"答案的题解用的是单调栈我用的不是，但是总体来说也是dp的方法，速度好像还快一点的，击败了99.8%。 class StockSpanner &#123; public: vector&lt;int&gt; num; vector&lt;int&gt; res; StockSpanner() &#123; num.clear(); res.clear(); num.push_back(-1); res.push_back(0); &#125; int next(int price) &#123; int len=num.size(); int top=num[len-1]; if(top&lt;=price) &#123; int tmp=0;//最后的结果 int p=len-1;//最后的位置 while(top&lt;=price&amp;&amp;p!=0) &#123; tmp+=res[p]; p=p-res[p]; top=num[p]; &#125; num.push_back(price); res.push_back(tmp+1); return tmp+1; &#125; else &#123; num.push_back(price); res.push_back(1); return 1; &#125; &#125; &#125;;","path":"2020/11/02/算法/901. 股票价格跨度/"},{"title":"576. 出界的路径数（记忆化搜索）","text":"class Solution &#123; public: long res[55][55][55]; int findPaths(int m, int n, int N, int i, int j) &#123; res[0][i][j]=1; int mod = 1000000007; for(int num=1;num&lt;N;num++) &#123; for(int row=0;row&lt;m;row++) &#123; for(int col=0;col&lt;n;col++) &#123; if(row-1&gt;=0) res[num][row][col]=(res[num-1][row-1][col]+res[num][row][col])%(mod); if(row+1&lt;m) res[num][row][col]=(res[num-1][row+1][col]+res[num][row][col])%(mod); if(col-1&gt;=0) res[num][row][col]=(res[num-1][row][col-1]+res[num][row][col])%(mod); if(col+1&lt;n) res[num][row][col]=(res[num-1][row][col+1]+res[num][row][col])%(mod); &#125; &#125; &#125; long result=0; for(int num=0;num&lt;N;num++) &#123; for(int row=0;row&lt;m;row++) &#123; result+=res[num][row][0]; result%=mod; result+=res[num][row][n-1]; result%=mod; &#125; for(int col=0;col&lt;n;col++) &#123; result+=res[num][0][col]; result%=mod; result+=res[num][m-1][col]; result%=mod; &#125; // cout&lt;&lt;result&lt;&lt;endl; &#125; return int(result); &#125; &#125;;","path":"2020/11/02/算法/576. 出界的路径数/"},{"title":"LeetCode 794. Valid Tic-Tac-Toe State (medium)（ 博弈dp）","text":"因为X先下，所以如果X和O的数目关系要么相等，要么X比O多1，只有这两种关系，其次再判断如果X已经赢了，O没法下，此时O的数目只能比X小1，或者O赢了，X的数目只能和O一样。bool check(vector&lt;string&gt;&amp; board,char key) &#123; if(board[0][0]==board[0][1]&amp;&amp;board[0][1]==board[0][2]&amp;&amp;board[0][2]==key)return true; if(board[2][0]==board[2][1]&amp;&amp;board[2][1]==board[2][2]&amp;&amp;board[2][2]==key)return true; if(board[0][0]==board[1][0]&amp;&amp;board[1][0]==board[2][0]&amp;&amp;board[2][0]==key)return true; if(board[0][2]==board[1][2]&amp;&amp;board[1][2]==board[2][2]&amp;&amp;board[2][2]==key)return true; if(board[0][0]==board[1][1]&amp;&amp;board[1][1]==board[2][2]&amp;&amp;board[2][2]==key)return true; if(board[0][2]==board[1][1]&amp;&amp;board[1][1]==board[2][0]&amp;&amp;board[2][0]==key)return true; return false; &#125; bool validTicTacToe(vector&lt;string&gt;&amp; board) &#123; int ansX=0,ansO=0; for(int i=0;i&lt;3;i++) &#123; for(int j=0;j&lt;3;j++) &#123; if(board[i][j]==&#x27;X&#x27;) ansX++; else if(board[i][j]==&#x27;O&#x27;) ansO++; &#125; &#125; if(ansX&lt;ansO)return false; if(ansX-ansO&gt;1)return false; if(check(board,&#x27;X&#x27;)&amp;&amp;ansX==ansO)return false; if(check(board,&#x27;O&#x27;)&amp;&amp;ansX!=ansO)return false; return true; &#125;","path":"2020/11/02/算法/LeetCode 794. 有效的井字游戏/"},{"title":"1349. 参加考试的最大学生数","text":"方法就是每次求前n排的人数和前n-1排的人数的关系，重点在于相邻两排斜着的人是否都有，一排是否有相邻的，是否坐在坏的座位上。一一排除。遍历，所有的状态，一排最多2^8个状态。 class Solution &#123; public: int maxStudents(vector&lt;vector&lt;char&gt;&gt;&amp; seats) &#123; int m=seats.size(); int n=seats[0].size(); vector&lt;vector&lt;int&gt;&gt; dp(m+1,vector&lt;int&gt;(1&lt;&lt;n)); for(int i=1;i&lt;=m;i++) &#123; for(int j=0;j&lt;(1&lt;&lt;n);j++) &#123; bitset&lt;8&gt; bs(j); bool state=true; for(int k=0;k&lt;n;k++) &#123; if((seats[i-1][k]==&#x27;#&#x27;&amp;&amp;bs[k])||(k&lt;n-1&amp;&amp;bs[k]&amp;&amp;bs[k+1])) &#123; state=false; break; &#125; &#125; if(state==false) &#123; dp[i][j]=-1; continue; &#125; for(int k=0;k&lt;(1&lt;&lt;n);k++) &#123; if(dp[i-1][k]==-1) &#123; continue; &#125; bitset&lt;8&gt; lastbs(k); bool state1=true; for(int r=0;r&lt;n;r++) &#123; if(lastbs[r]&amp;&amp;(r&gt;0&amp;&amp;bs[r-1]||r&lt;n-1&amp;&amp;bs[r+1])) &#123; state1=false; break; &#125; &#125; if(state1==true) &#123; dp[i][j]=max(dp[i][j],dp[i-1][k]+int(bs.count())); &#125; &#125; &#125; &#125; int result=0; for(int i=0;i&lt;(1&lt;&lt;n);i++) &#123; result=max(result,dp[m][i]); &#125; return result; &#125; &#125;;","path":"2020/11/02/算法/1349. 参加考试的最大学生数/"},{"title":"1125. 最小的必要团队","text":"这个题一开始不会做，做出来一直超时，看的别人的思路先把某些技能树是别人子集的人去掉，然后做dp。class Solution &#123; public: vector&lt;int&gt; smallestSufficientTeam(vector&lt;string&gt;&amp; req_skills, vector&lt;vector&lt;string&gt;&gt;&amp; people) &#123; int bitmap=0;//代表技能，比如111这种 for(int i=0;i&lt;req_skills.size();i++) &#123; bitmap=bitmap|(1&lt;&lt;i); &#125; vector&lt;pair&lt;int,int&gt;&gt; peo2map; for(int i=0;i&lt;people.size();i++) &#123; int tmp=0; for(int j=0;j&lt;people[i].size();j++) &#123; for(int k=0;k&lt;req_skills.size();k++) &#123; if(people[i][j]==req_skills[k]) &#123; tmp=tmp|(1&lt;&lt;k); break; &#125; &#125; &#125; peo2map.push_back(&#123;i,tmp&#125;); &#125; vector&lt;bool&gt; issame(peo2map.size(),0); for(int i=0;i&lt;issame.size();i++) &#123; for(int j=i+1;j&lt;issame.size();j++) &#123; if((peo2map[i].second|peo2map[j].second)==peo2map[i].second) &#123; issame[j]=1; &#125; else if((peo2map[i].second|peo2map[j].second)==peo2map[j].second) &#123; issame[i]=1; &#125; &#125; &#125; decltype(peo2map) peo2map1; for(int i=0;i&lt;peo2map.size();i++) &#123; if(issame[i]==0) &#123; peo2map1.push_back(peo2map[i]); &#125; &#125; vector&lt;vector&lt;int&gt;&gt;res(bitmap+1);//每一个数组代表一组技能 vector&lt;int&gt;skill(bitmap+1,-1);//记录每种技能组合对应的人数，最低位表示没有技能 skill[0]=0;//位图为00000..的技能被获得，某个技能树需要的人数 for(int i=0;i&lt;peo2map1.size();i++) &#123; for(int j=0;j&lt;=bitmap;j++) &#123; if(skill[j]==-1) continue; int newskill=(peo2map1[i].second)|j; if(skill[newskill]==-1||skill[newskill]&gt;skill[j]+1) &#123; skill[newskill]=skill[j]+1;//从j那边技能树走人数会更少 res[newskill]=res[j]; res[newskill].push_back(peo2map1[i].first); &#125; &#125; &#125; return res[bitmap]; &#125; &#125;;","path":"2020/11/02/算法/1125. 最小的必要团队/"},{"title":"数据库的三级模式：外模式、模式和内模式","text":"一、模式（Schema） 定义：也称逻辑模式，是数据库中全体数据的逻辑结构和特征的描述，是所有用户的公共数据视图。 理解： ① 一个数据库只有一个模式； ② 是数据库数据在逻辑级上的视图； ③ 数据库模式以某一种数据模型为基础； ④ 定义模式时不仅要定义数据的逻辑结构（如数据记录由哪些数据项构成，数据项的名字、类型、取值范围等），而且要定义与数据有关的安全性、完整性要求，定义这些数据之间的联系。 二、外模式（External Schema） 定义：也称子模式（Subschema）或用户模式，是数据库用户（包括应用程序员和最终用户）能够看见和使用的局部数据的逻辑结构和特征的描述，是数据库用户的数据视图，是与某一应用有关的数据的逻辑表示。 理解： ① 一个数据库可以有多个外模式； ② 外模式就是用户视图； ③ 外模式是保证数据安全性的一个有力措施。 三、内模式（Internal Schema） 定义：也称存储模式（Storage Schema），它是数据物理结构和存储方式的描述，是数据在数据库内部的表示方式（例如，记录的存储方式是顺序存储、按照B树结构存储还是按hash方法存储；索引按照什么方式组织；数据是否压缩存储，是否加密；数据的存储记录结构有何规定）。 理解： ① 一个数据库只有一个内模式； ② 一个表可能由多个文件组成，如：数据文件、索引文件。 它是数据库管理系统(DBMS)对数据库中数据进行有效组织和管理的方法 其目的有： ① 为了减少数据冗余，实现数据共享； ② 为了提高存取效率，改善性能。","path":"2020/10/13/数据库/数据库的三级模式：外模式、模式和内模式/"},{"title":"MySQL - ON & WHERE 条件区别和执行顺序","text":"MySQL - ON &amp; WHERE 条件区别和执行顺序on是在生成临时表的时候使用的条件，不管on的条件是否起到作用，都会返回左表 (table_name1) 的行。where则是在生成临时表之后使用的条件，此时已经不管是否使用了left join了，只要条件不为真的行，全部过滤掉。 内连接，外连接，笛卡尔积连接自然连接和等值连接1、自然连接(Naturaljoin)是一种特殊的等值连接，它要求两个关系中进行比较的分量必须是相同的属性组，并且在结果中把重复的属性列去掉。而等值连接并不去掉重复的属性列。 2、自然连接：在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。 3、自然连接与等值连接 在连接运算当中，一种最常用的连接是自然连接。 所谓自然连接就是在等值连接的情况下，当连接属性X与Y具有相同属性组时，把在连接结果中重复的属性列去掉。 自然连接是在广义笛卡尔积R×S中选出同名属性上符合相等条件元组，再进行投影，去掉重复的同名属性，组成新的关系。 4、等值连接与自然连接的区别： 1）等值连接中不要求相等属性值的属性名相同，而自然连接要求相等属性值的属性名必须相同，即两关系只有在同名属性才能进行自然连接。 2）等值连接不将重复属性去掉，而自然连接去掉重复属性，也可以说，自然连接是去掉重复列的等值连接。 5、事实上，我们一般使用的都是自然连接。 select FirstName, LastName, City, State from Person left join Address on Person.PersonId =Address.PersonId; 很纠结的一点是为啥这个on不能是where，然后才发现其实因为是因为在address没有的情况下Address.PersonId;这个本身就是不对的，on因为是就算为空也会生成，所以是对的。","path":"2020/10/13/数据库/MySQL - ON & WHERE 条件区别和执行顺序/"},{"title":"486. 预测赢家","text":"我考虑的是在i，j区间中获胜的人的分数，题解考虑的是分数差值，更好一点。bool PredictTheWinner(vector&lt;int&gt;&amp; nums) &#123; int len=nums.size(); vector&lt;vector&lt;int&gt; &gt; sum(len,vector&lt;int&gt;(len,0)); vector&lt;vector&lt;int&gt; &gt; res(len,vector&lt;int&gt;(len,0)); for(int i=0;i&lt;len;i++) &#123; sum[i][i]=nums[i]; res[i][i]=nums[i]; &#125; for(int i=2;i&lt;=len;i++)//长度 &#123; for(int j=0;i+j-1&lt;len;j++)//左边起始位置 &#123; sum[j][i+j-1]=sum[j+1][i+j-1]+nums[j]; &#125; &#125; for(int i=2;i&lt;=len;i++)//长度 &#123; for(int j=0;i+j-1&lt;len;j++)//左边起始位置 &#123; res[j][i+j-1]=max(sum[j+1][i+j-1]-res[j+1][i+j-1]+nums[j],sum[j][i+j-2]-res[j][i+j-2]+nums[i+j-1]); &#125; &#125; if(res[0][len-1]&gt;=(sum[0][len-1]/2.0)) return true; else return false; &#125;","path":"2020/10/07/算法/486. 预测赢家/"},{"title":"837. 新21点","text":"我们以 N = 21，K = 17，W = 10 来思考。因为我们的结果是求手上点数为 0 时，赢得游戏的概率。 所以我们需要从后往前逆向求，比如在这里，我们就需要知道在手上点数为 16 时赢得游戏的概率，从而在往前求手上点数为 15 时的概率，最后求出手上点数为 0 时的赢得游戏的概率。 那我们怎么求点数为 16 时赢得游戏的概率呢？ 这里我们知道手上点数为 17 时赢得游戏的概率为 100%，所以 K ~ N 区间的赢得游戏的概率为 100%，超过 N 时赢得游戏概率为 0，那么手上点数为 16 时，赢得游戏的概率就是 手上点数为 17 ~ 17 + 10 - 1 的赢得游戏的概率和除以 W，即用一个表达式为 win[16] = sum(win[17] ~ win[26]) / W。 这里我们可以以 O(1) 的时间复杂度计算 sum(win[i + 1] ~ win[i + W - 1])。我们用一个sumProb = sum(win[17] ~ win[26])然后每次计算win[i] = sumProb / WsumProb = sumProb + win[i] - win[i + W] 这个题目如果用简单的dp会超时，需要从后向前dp，进行优化，考虑差分。double new21Game(int N, int K, int W) &#123; vector&lt;double&gt; res(K+W+1,0); res[0]=1; for(int i=K;i&lt;=N;i++) &#123; res[i]=1; &#125; double tmp=N-K+1; for(int i=K-1;i&gt;=0;i--) &#123; res[i]=tmp/W; tmp=tmp-res[i + W] + res[i]; &#125; return res[0]; &#125;","path":"2020/10/06/算法/837. 新21点/"},{"title":"808. 分汤","text":"即使将 N 除以 25 之后，仍然没法在短时间内得到答案，因此我们需要尝试一些别的思路。可以发现，分配操作有 (4, 0)，(3, 1)，(2, 2) 和 (1, 3) 四种，那么在一次分配中，汤 A 平均会少 (4 + 3 + 2 + 1) / 4 = 2.5 份，汤 B 平均会少 (0 + 1 + 2 + 3) / 4 = 1.5 份。因此在 N 非常大的时候，A 会有很大的概率比 B 先分配完，所有概率应该非常接近 1。事实上，当 N &gt;= 500 25 时，所求概率已经大于 0.999999 了（可以通过上面的动态规划方法求出），它和 1 的误差（无论是绝对误差还是相对误差）都小于 10^-6。因此在 N &gt;= 500 25 时，我们只需要输出 1 作为答案即可。在其它的情况下，我们使用动态规划计算出答案。 double soupServings(int N) &#123; N=N/25+(N%25&gt;0?1:0); if(N&gt;=500*25) return double(1); vector&lt;vector&lt;double&gt; &gt; res(N+1,vector&lt;double&gt;(N+1,0)); for(int i=1;i&lt;=N;i++) &#123; res[0][i]=1.0; &#125; res[0][0]=0.5; for(int i=1;i&lt;=N;i++) &#123; for(int j=1;j&lt;=N;j++) &#123; double tmp=res[(i-4)&lt;0?0:(i-4)][j]+res[(i-3)&lt;0?0:(i-3)][(j-1)&lt;0?0:(j-1)]; double tmp1=res[(i-2)&lt;0?0:(i-2)][(j-2)&lt;0?0:(j-2)]+res[(i-1)&lt;0?0:(i-1)][(j-3)&lt;0?0:(j-3)]; res[i][j]=0.25*(tmp+tmp1); &#125; &#125; return res[N][N]; &#125;","path":"2020/10/06/算法/808. 分汤/"},{"title":"957. N 天后的牢房","text":"为啥14总是一个循环呢？ 首先，经过一次变化之后，0位和7位的数字都会固定是0，不再改变？？？？？？？?|0 ？？？？？？0 其次，第n次的1357位的值决定了n+1次2468位的值，而n+1次的2468位的值又决定了n+2次1357位的值。因此可以得出，第n次的1357位的值可以决定n+2次1357位的值，并且，第n次的2468位的值可以决定n+2次2468位的值。 下面先考虑2468位的情况。因为，8位的值是固定的，所以，只需要考虑246位的值。按2^3=8的情况考虑，246的值可能的情况最多只有8种。然而，仔细观察后会发现，如果第n次的246位的值是001，那么n+2次246位的值也是001，所以001的情况下，246位的值保持不变，所以循环次数为1。如果246位值是其他的情况，那么他们会经历7次循环，因为每次循环需要变换两次，所以，总共需要的变化次数就是14。(1)111 -&gt; (2)010 -&gt; (3)110 -&gt; (4)000 -&gt; (5)011 -&gt; (6)100 -&gt; (7)101 -&gt; (8)111 因为1357位和2468位的地位相同，情况一样，同理，考虑1357位。100的情况下，135的值保持不变，其他情况下，7次循环，14次变化。(0)111 -&gt; (1)010 -&gt; (2)011 -&gt; (3)000 -&gt; (4)110 -&gt; (5)001 -&gt; (6)101 -&gt; (7)111 但是，注意，我们没有考虑到在每次变换中间，375位和246位的值。其实在中间位置时，它们也同样处于一个循环B中。还是先考虑246位，最好的情况就是，由246位初始决定的A循环，和由1357位的初始值决定的B循环，两个循环恰好互补，也就是下面的情况：（我们用A，B分别表示两个循环，A1表示第一个循环中的第一次，B1表示第二个循环中的第一次）(初始情况：A1)111 -&gt; (第一次变化：B1)011 -&gt; (第二次变化：A2)010 -&gt; (第三次变化：B2)100 -&gt; (第四次变化：A3)110 -&gt; (第五次变化：B3)101 -&gt; (第六次变化：A4)000 -&gt; (第七次变化：B4)111 -&gt; (第八次变化：A5)011 -&gt; (第九次变化：B5)010 -&gt; (第十次变化：A6)100 -&gt; (第十一次变化：B6)110 -&gt; (第十二次变化：A7)101 -&gt; (第十三次变化：B7)000 -&gt; (第十四次变化：A8)111这样，在第8次变化前，246位的值已经完成了一次循环。因为，A循环由246位初始决定，B循环由1357位的初始值决定，所以其实在上述情况下，1357位的值也是固定的。 因此，当1357位固定为0100并且2468位固定为0010时，即情况为{0,0,1,0,0,1,0,0}时，循环次数为1。当1357位和2468位出现最佳情况时，循环次数为7，有一下其中情况：1: {0, 1, 1, 1, 1, 1, 1, 0}2: {0, 0, 1, 1, 1, 1, 0, 0}3: {0, 0, 0, 1, 1, 0, 0, 0}4: {0, 1, 0, 0, 0, 0, 1, 0}5: {0, 1, 0, 1, 1, 0, 1, 0}6: {0, 1, 1, 0, 0, 1, 1, 0}7: {0, 0, 0, 0, 0, 0, 0, 0}其他情况下，循环次数为14。vector&lt;int&gt; prisonAfterNDays(vector&lt;int&gt;&amp; cells, int N) &#123; if(N==0) return cells; N=N%14; if(N==0)//当N为0的时候需要特别注意。 N=14; vector&lt;int&gt; res(8,0); int flag=1; for(int i=1;i&lt;=N;i++) &#123; for(int j=1;j&lt;=6;j++) &#123; if(flag==1) &#123; if(cells[j-1]==cells[j+1]) &#123; res[j]=1; &#125; else res[j]=0; &#125; else &#123; if(res[j-1]==res[j+1]) &#123; cells[j]=1; &#125; else cells[j]=0; &#125; &#125; if(flag==1) &#123; res[0]=0; res[7]=0; &#125; else &#123; cells[0]=0; cells[7]=0; &#125; flag=-flag; &#125; if(flag==1) return cells; else return res; &#125;","path":"2020/10/06/算法/957.N 天后的牢房/"},{"title":"auto和decltype之间的区别","text":"decltype推断表达式类型 1 如果是类成员方法，那么就算对应的类型信息 2 如果是函数，那么就是函数返回的类型 3 如果是右值，那么就是对应类型，如果是左值，那么是类型引用。 4 decltype使用一个不加括号的变量，得到的结果就是该变量的类型，如果加上一层或多层括号，则编译器将推断得到引用类型。 Auto1 自动推断类型 2 要求必须进行初始化 3 当声明为auto的时候，会忽略对象的CV还有引用属性 4 当声明为auto，const int *类型，会保留const，对 int *const会忽略const 5 对于auto&amp;,会保留表达式的CV属性，比如（const int p=1;auto&amp; x=p),p为const int &amp;; 6 对于 auto类型，如果希望保留int *const 需要声明为const auto","path":"2020/08/13/C++/auto和decltype之间的区别/"},{"title":"拉东变换","text":"","path":"2020/08/04/test/"},{"title":"拉东变换","text":"x射线在穿过人体传播的时候，它的衰减是这样的 $I=I_0 e^{-ux}$","path":"2020/08/03/医学图像/拉东变换/"},{"title":"attention机制","text":"attention机制这篇文章讲的很详细attention机制 这篇文章的例子讲的可以attention机制","path":"2020/07/31/深度学习/attention机制/"},{"title":"医学图像相关内容","text":"ASTRA Toolbox一个python的库，包含很多的医学图像的算法，比如fbp，sart，生成投影数据等问题。 还可以进行gpu加速，可以学习学习。","path":"2020/07/29/医学图像/医学图像相关内容/"},{"title":"memset赋值问题","text":"在memset的赋值问题中，是按字节赋值的，如果是menset(array,1,n*sizeof(int));结果不是每个int变成1，而是变成很大的数，它是将int的每一个字节赋值为1，因此最好只在赋值为0的时候使用。","path":"2020/07/29/C++/memset赋值问题/"},{"title":"状压dp","text":"状压dp状态压缩动态规划，就是我们俗称的状压DP，是利用计算机二进制的性质来描述状态的一种DP方式。 很多棋盘问题都运用到了状压，同时，状压也很经常和BFS及DP连用。 状压dp其实就是将状态压缩成2进制来保存 其特征就是看起来有点像搜索，每个格子的状态只有1或0 ，是另一类非常典型的动态规划 举个例子：有一个大小为n*n的农田，我们可以在任意处种田，现在来描述一下某一行的某种状态： 设n = 9； 有二进制数 100011011（九位），每一位表示该农田是否被占用，1表示用了，0表示没用，这样一种状态就被我们表示出来了。这表示的是一中状态，表示的是在这个状态下每个东西的情况。如果要用数组来表示，必须用很多空间表示这一个状态的集合。而在现实因为每个东西状态只有01 所以我们用一个数来表示这种集合状态。 leetcode 464. 我能赢吗采用状压dp来压缩状态。对于每次回溯来说，如果本次(第一个人)选择数字i达到了desiredTotal，说明当前状态下能赢，即返回true，又或者下一次(另一个人)输了，那么说明本次选择必赢。 用dp数组索引表示所选整数的累加和减1，而这个累加和又能体现整数元素选取的情况。dp数组的索引对应整数累加和状态，该整数累加和状态对应组合状态；dp数组元素的值表示整数组合状态对应的结果，为true表示该组合状态已存在并且能赢，直接返回；为false表示该组合状态已存在并且输了，直接返回；为空表示还没出现这种整数组合状态，是一个新状态，需要进行递归计算。 class Solution &#123; public: bool canIWin(int maxChoosableInteger, int desiredTotal) &#123; if(maxChoosableInteger&gt;=desiredTotal) return true; if((maxChoosableInteger+1)*maxChoosableInteger/2&lt;desiredTotal) return false; int *dp=new int[1&lt;&lt;(maxChoosableInteger)];//减法优先级更高 for(int i=0;i&lt;1&lt;&lt;(maxChoosableInteger);i++) dp[i]=-1; bool res= dfs(maxChoosableInteger,desiredTotal,dp,0); return res; &#125; bool dfs(int maxChoosableInteger,int desiredTotal,int *p,int state) &#123; if(p[state]!=-1) return p[state]; for(int i=1;i&lt;=maxChoosableInteger;i++) &#123; int s=1&lt;&lt;i-1; if((s&amp;state)==0)//位运算的优先级很低 &#123; if(desiredTotal-i&lt;=0||!dfs(maxChoosableInteger,desiredTotal-i,p,s|state)) &#123; p[state]=1; return true; &#125; &#125; &#125; p[state]=0; return false; &#125; &#125;; 526. 优美的排列这个题目使用两个数字来记录。第一个是代表哪些数字已经被使用，状态压缩记录，另一个代表的是这是第几个数字。 int countArrangement(int N) &#123; int *dp=new int[1&lt;&lt;N]; int res=0; for(int i=0;i&lt;(1&lt;&lt;N);i++) dp[i]=-1; res=dfs(N,dp,0,1); delete []dp; return res; &#125; int dfs(int N,int *dp,int state,int p) &#123; if(dp[state]!=-1) return dp[state]; int tmp=0; for(int i=1;i&lt;=N;i++) &#123; int s=1&lt;&lt;i-1; if((s&amp;state)==0) &#123; if((i%p==0||p%i==0)) &#123; if(p==N) return 1; tmp+=dfs(N,dp,state|s,p+1); &#125; &#125; &#125; // cout&lt;&lt;tmp&lt;&lt;endl; return tmp; &#125; 935. 骑士拨号器这道题目看起来不像是状压dp，就是让上一个情况递推到下一个，然后同时记录中间的结果。class Solution &#123; public: int a[10][5005]; const int C=pow(10,9)+7; int knightDialer(int N) &#123; vector&lt;int&gt; t(3,-1); vector&lt;vector&lt;int&gt; &gt; b(10,t); b[0][0]=4;b[0][1]=6; b[1][0]=6;b[1][1]=8; b[2][0]=7;b[2][1]=9; b[3][0]=4;b[3][1]=8; b[4][0]=3;b[4][1]=9;b[4][2]=0; b[6][0]=1;b[6][1]=7;b[6][2]=0; b[7][0]=2;b[7][1]=6; b[8][0]=3;b[8][1]=1; b[9][0]=2;b[9][1]=4; int res=0; for(int i=0;i&lt;10;i++) &#123; res=(fun(i,N-1,b)+res)%C; &#125; return res; &#125; int fun(int i,int N,vector&lt;vector&lt;int&gt;&gt; &amp;b) &#123; if(a[i][N]!=0) return a[i][N]; if(N==0) return 1; int tmp1=0; for(int t=0;t&lt;3;t++) &#123; int tmp=b[i][t]; if(tmp!=-1) tmp1=(fun(tmp,N-1,b)%C+tmp1%C)%C; &#125; a[i][N]=tmp1; return tmp1%C; &#125; &#125;; class Solution &#123; public: int a[8][1&lt;&lt;8]; int maxStudents(vector&lt;vector&lt;char&gt;&gt;&amp; seats) &#123; int len=seats.size(); if(len&lt;=0||seats[0].size()&lt;=0) return 0; int len1=seats[0].size(); vector&lt;int&gt; t(len1,-1); vector&lt;vector&lt;int&gt; &gt; tt(len,t);//这一行，以及上一行的状态 dfs(0,dp,0，0)//第几行，这一行的状态，由于只会往上和左右扩散，所以可以从一个方向走。 return res; &#125; int dfs(int len,vector&lt;vector&lt;int&gt; &gt; dp,int state，int state1) &#123; if(dp[len][state][state1]!=-1) return dp[len][state][state1]; int tmp=0; int rr=0; for(int i=0;i&lt;n;i++) &#123; int s1=state; int s2=state1; tmp=1&lt;&lt;i; if((i&amp;state)==0) &#123; s1=s1|tmp; if(i-1&gt;=0) &#123; s1=s1|(1&lt;&lt;i-1); s2=s2|(1&lt;&lt;i-1); &#125; if(i&lt;=len1) &#123; s1=s1|(1&lt;&lt;i+1); s2=s2|(1&lt;&lt;i+1); &#125; rr=max(rr,dfs(len,dp,s1,s2)); &#125; &#125; dp[len][s1][s2]=rr; return rr; &#125; &#125;;","path":"2020/07/29/算法/动态规划/状压dp/"},{"title":"树形dp","text":"树形dp543. 二叉树的直径这里就是对于每棵树判断两种情况，是选择自己作为深度，祖宗节点作为根节点穿过最长，还是就是自己作为根节点穿过最长呢。于是只需要求子节点的最长的节点长度，然后最后把节点长度减一就可以了。 class Solution &#123; public: int res=0; int dfs(TreeNode* root) &#123; if(root==nullptr) return 0; int l=dfs(root-&gt;left); int r=dfs(root-&gt;right); res=max(res,l+r+1); return max(l,r)+1; &#125; int diameterOfBinaryTree(TreeNode* root) &#123; if(root==nullptr) return 0; int a=dfs(root); return res-1; &#125; &#125;; LeetCode 337. House Robber III (medium)这个在打家劫舍系列里面，动态规划里面，这里就不重复写了。 124. 二叉树中的最大路径和这个题目的思路主要是就是我们在每个经过的路径肯定有一个最高的节点。如果自己这个节点就是最高的节点。那么就是比较结果和左子树加右子树加节点的值。这个地方要注意 一个节点的情况实际上是已经包含的了。 接下来就是两个节点的情况。左子树或者右子树，取大于0 的最大值。然后加上节点值返回。 一开始我不理解三个节点的情况，两个节点的情况，一个节点的情况的区别，有可能还有负数，我比较混乱，所以就写得很繁琐，都列举出来了。 较繁琐代码，可以参考。击败97%&lt;!—hexoPostRenderEscape:class Solution &#123;public: int res=0; int maxval=-0x7fffffff-1; int dfs(TreeNode* root) &#123; if(root==nullptr) &#123; return 0; &#125; if(root-&gt;val&gt;maxval) maxval=root-&gt;val; int L=dfs(root-&gt;left); int R=dfs(root-&gt;right); if(L&lt;0) &#123; if(R&lt;0) &#123; res=max(res,root-&gt;val); return root-&gt;val&gt;0?root-&gt;val:0; &#125; else &#123; res= max(res,R+max(0,root-&gt;val)); return R+root-&gt;val&gt;0?R+root-&gt;val:0; &#125; &#125; else &#123; if(R&lt;0) &#123; res= max(res,L+max(0,root-&gt;val)); return L+root-&gt;val&gt;0?L+root-&gt;val:0; &#125; else &#123; if(root-&gt;val&gt;=0||root-&gt;val+L&gt;0||root-&gt;val+R&gt;0) res=max(res,L+R+root-&gt;val); else res=max(res,max(L,R)); int tmp=max(R,L)+root-&gt;val; return tmp&gt;0?tmp:0; &#125; &#125; &amp;#125; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; maxPathSum(&lt;span class=&quot;hljs-type&quot;&gt;TreeNode&lt;/span&gt;* root) &amp;#123; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; a=dfs(root); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(maxval&amp;lt;=&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) return maxval; return res; &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt; 简化代码。int res=-0x7fffffff-1; int dfs(TreeNode* root) &#123; if(root==nullptr) &#123; return 0; &#125; int L=dfs(root-&gt;left); int R=dfs(root-&gt;right); int l=max(0,L); int r=max(0,R); res=max(res,r+l+root-&gt;val); return max(l,r)+root-&gt;val; &#125; int maxPathSum(TreeNode* root) &#123; dfs(root); return res; &#125; 代码差不多只是稍微简化了一点点。也是97% LeetCode 1245. Tree Diameter这道题是被锁住的。 题目描述给定一棵无向树，返回它的直径：树中最长路径的 边 的数量。 树用一个数组给出，数组为 edges[i] = [u, v]，每个元素代表一条双向边连接结点 u 和 v。每个结点的编号为 {0, 1, …, edges.length}。 样例 输入：edges = [[0,1],[0,2]]输出：2解释：这棵树上最长的路径是 1 - 0 - 2，边数为 2。 输入：edges = [[0,1],[1,2],[2,3],[1,4],[4,5]]输出：4解释：这棵树上最长的路径是 3 - 2 - 1 - 4 - 5，边数为 4。限制0 &lt;= edges.length &lt; 10^4edges[i][0] != edges[i][1]0 &lt;= edges[i][j] &lt;= edges.lengthedges 会形成一棵无向树。 遇到树的题目，多数要考虑到使用dfs或者bfs来解题。本题也不例外，从任意一点开始dfs整棵树，对于任意当前节点，它能组成的最大边长应该是从自身出发的所有路径中最长两条路径长度的和。因此，在每一步dfs中，我们需要记录下当前节点最长两条路径的长度，并求出和sum。同时返回最长的一条边的长度给上层dfs。全部dfs结束后，找到最大的sum即是结果。 之前我比较纠结的一点是为什么为什么走过来不会走回去，后来才发现，因为保证了不会走回头路，又是无环图所以一定不会走回去，最后写起来就和二叉树有点像。每次判断以当前节点为中间节点的路径和最长路径的大小。 int res=0; // 返回结果 public int treeDiameter(int[][] edges) &#123; // 利用边的信息构建出树的结构，即每个节点能和哪些节点相连接 List&lt;Integer&gt;[] tree = new List[edges.length+1]; // 初始化 for(int i=0;i&lt;tree.length;i++)&#123; tree[i] = new ArrayList&lt;&gt;(); &#125; // 构建树 for(int[] edge : edges)&#123; tree[edge[0]].add(edge[1]); tree[edge[1]].add(edge[0]); &#125; dfs(tree, 0, -1); // 开始dfs return res; &#125; // tree为树的结构图 // current为当前节点 // previous为前一个节点 // 返回值为：以当前节点为起点的一条最大路径长度 int dfs(List[] tree, int current, int previous)&#123; // 查看当前节点能与哪些节点连接 List&lt;Integer&gt; list = tree[current]; int max1=0; // 以当前节点为起点的一条最大路径长度 int max2=0; // 以当前节点为起点的一条次大路径长度 // 循环所有与当前节点相连的点 for(int next : list)&#123; // 防止走回头路 if(next != previous)&#123; // dfs得到下一个节点一条路径的最大长度 // 加一之后为当前节点一条路径的长度 int max = dfs(tree, next, current)+1; // 比较当路径长度与之前得到的max1，max2，并更新最大值 if(max&gt;=max1)&#123; max2=max1; max1=max; &#125;else if(max&gt;=max2)&#123; max2=max; &#125; // max1+max2得到当前节点最大边长,与返回结果比较，更新最大值 res=Math.max(res, max1+max2); &#125; &#125; // 返回当前节点一条路径的最大长度 return max1; &#125; [LeetCode] 333. Largest BST Subtree 最大的二分搜索子树Given a binary tree, find the largest subtree which is a Binary Search Tree (BST), where largest means subtree with largest number of nodes in it. Note:A subtree must include all of its descendants. Example: Input: [10,5,15,1,8,null,7] 10 / \\ 5 15 / \\ \\1 8 7 Output: 3Explanation: The Largest BST Subtree in this case is the highlighted one. The return value is the subtree’s size, which is 3.Follow up:Can you figure out ways to solve it with O(n) time complexity? Hint: You can recursively use algorithm similar to 98. Validate Binary Search Tree at each node of the tree, which will result in O(nlogn) time complexity. 找最大的二叉搜索子树首先肯定是需要子树的范围, 因为我们要判断当前结点为根的树是否为二叉搜索树就要满足当前结点大于左子树的最大值, 小于右子树的最小值. 再次我们还需要知道子树是否为二叉搜索树以及其二叉搜索树的大小. 有了这些信息我们就可以判断以当前结点为根的二叉树是否为二叉搜索树了. 但是这题很容易写的比较复杂.&lt;!—hexoPostRenderEscape:class Solution &#123;public: vector&lt;int&gt; DFS(TreeNode* root, int&amp; ans) &#123; if(!root) return vector&lt;int&gt;&#123;0, INT_MAX, INT_MIN&#125;; auto left=DFS(root-&gt;left, ans), right=DFS(root-&gt;right, ans); if(root-&gt;val &gt; left[2] &amp;&amp; root-&gt;val &lt; right[1]) &#123; int Min =min(root-&gt;val, left[1]), Max =max(root-&gt;val, right[2]); ans = max(ans, left[0] + right[0] + 1); return vector&lt;int&gt;&#123;left[0] +right[0] +1, Min , Max&#125;; &#125; return vector&lt;int&gt;&#123;0, INT_MIN, INT_MAX&#125;; &#125; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; largestBSTSubtree(TreeNode* root) &amp;#123; &lt;span class=&quot;hljs-built_in&quot;&gt;int&lt;/span&gt; ans = &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;; DFS(root, ans); &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; ans; &amp;#125; &lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2020/07/28/算法/动态规划/树形dp/"},{"title":"区间dp","text":"图像转CT值CT值的单位是Hounsfield，简称为Hu，范围是-1024-3071。用于衡量人体组织对X射线的吸收率，设定水的吸收率为0Hu。 在DICOM图像读取的过程中，我们会发现图像的像素值有可能不是这个范围，通常是0-4096，这是我们常见到的像素值或者灰度值，这就需要我们在图像像素值（灰度值）转换为CT值。 首先，需要读取两个DICOM Tag信息，（0028|1052）：rescale intercept和（0028|1053）：rescale slope. 然后通过公式： Hu = pixel * slope + intercept 计算得到CT值。 衰减系数相关此外，临床上常用的X射线能量范围在80-140KeV左右，也比较固定。因此，三个因素中的2个固定了，剩下的一个就是物质密度。由此可见，医学CT通常是通过物质密度来对物质进行区分的。现在来看看典型值：在临床X射线能量范围内，水的线性衰减系数为0.2cm-1，肌肉为0.2~0.21cm-1，脂肪为0.18cm-1左右，空气在0左右，骨头在0.3~0.4cm-1左右。记这些值比较麻烦，远不如记100,200这种整数来得容易。观察这些值可以发现，这些值都在水附近，所以临床上通常使用某物质与水之间的相对值来衡量物质的衰减能力，即 （物质衰减能力-水衰减能力）/（水衰减能力-空气衰减能力）*1000， 其中水衰减能力在0.2左右，空气为0左右。为了纪念第一个发明CT机的科学家Housfield，我们将这个相对值的单位记为HU。而这个相对值即为CT值。这样一来，可以得出：空气的CT值为-1000HU左右，水是0HU，脂肪是-100HU左右，肌肉是50HU左右，骨头则是500~1000HU左右。这些值就好记多了。所以，结论是：1：在医学上，由于X射线能量比较固定，有效原子序数也比较固定，CT值就基本上刻画的是不同组织的密度差异性。2：如何测量？这是CT图像重建的范畴了。X射线扫描得到投影图像，根据投影图像反演出人体每点的线性衰减系数，带入上述公式，计算得到每一个点的CT值。（注意，上述所有的值都是一些粗略的近似，实际情况则需要实际考察。例如不同部位所使用的X射线能量不同等等。为了易于理解，上述表述也不尽严谨，欢迎讨论~） 转Hu值B. Window-leveling 算法: W/L 是专门为 CT 设计的。原理很简单：CT 图像里不同组织的密度 (用 Hounsfield 单位) 是在固定的值域， 与具体设备和成像软件没有关系。因此，要看头颅时， 我们只需将头颅的值域转换到 0-255 就行了。 CT W/L 不讲头颅值域的 min 和 max, 而说 max - min (即 window_width) 和 (max+min)/2 (即 window_center)。 我们还可以用原来的公式，只是 min 和 max 的算法不一样。 // 先算图像的最大和最小值min = (2window_center - window_width)/2.0 + 0.5;max = (2window_center + window_width)/2.0 + 0.5;for (i = 0; i &lt; nNumPixels; i++) disp_pixel_val = (pixel_val - min)*255.0/(double)(max - min); 请注意，CT 图像必须先转换成 Hounsfield 值再做 window-level。 这个转换包括将多余高位 bits 变成 0 (clipping), 和用 recale slope 和 rescale intercept 来做单位转换。 HU = pixel_val*rescale_slope + rescale_intercept","path":"2020/07/27/医学图像/Dicom医学图像相关内容/"},{"title":"区间dp","text":"区间dp是线性动态规划的扩展，它在分阶段地划分问题时，与阶段中元素出现的顺序和由前一阶段的哪些元素合并而来由很大的关系。令状态f(i,j)表示将下标位置 i 到 j 的所有元素合并能获得的价值的最大值，那么 f(i,j) = max{f(i,k) + f(k+1, j) + cost}, cost 为将这两组元素合并起来的代价。 区间 DP 的特点： 合并：即将两个或多个部分进行整合，当然也可以反过来；特征：能将问题分解为能两两合并的形式；求解：对整个问题设最优值，枚举合并点，将问题分解为左右两个部分，最后合并两个部分的最优值得到原问题的最优值。一般用二维数组表示区间区间问题只需要考虑 区间头和区间尾 87. 扰乱字符串给定一个字符串 s1，我们可以把它递归地分割成两个非空子字符串，从而将其表示为二叉树。 下图是字符串 s1 = “great” 的一种可能的表示形式。 great / \\ gr eat / \\ / \\g r e at / \\ a t在扰乱这个字符串的过程中，我们可以挑选任何一个非叶节点，然后交换它的两个子节点。 例如，如果我们挑选非叶节点 “gr” ，交换它的两个子节点，将会产生扰乱字符串 “rgeat” 。 rgeat / \\ rg eat / \\ / \\r g e at / \\ a t我们将 “rgeat” 称作 “great” 的一个扰乱字符串。 同样地，如果我们继续交换节点 “eat” 和 “at” 的子节点，将会产生另一个新的扰乱字符串 “rgtae” 。 rgtae / \\ rg tae / \\ / \\r g ta e / \\ t a我们将 “rgtae” 称作 “great” 的一个扰乱字符串。 给出两个长度相等的字符串 s1 和 s2，判断 s2 是否是 s1 的扰乱字符串。 dp[i][j][k][h] 表示 T[k..h]T[k..h] 是否由 S[i..j]S[i..j] 变来。由于变换必须长度是一样的，因此这边有个关系 j - i = h - kj−i=h−k ，可以把四维数组降成三维。dp[i][j][len]dp[i][j][len] 表示从字符串 SS 中 ii 开始长度为 lenlen 的字符串是否能变换为从字符串 TT 中 jj 开始长度为 lenlen 的字符串 class Solution &#123; public: bool isScramble(string s1, string s2) &#123; int len1=s1.size(); int len2=s2.size(); if(len1!=len2) return false; vector&lt;vector&lt;vector&lt;bool&gt;&gt;&gt; res(len1+1,vector&lt;vector&lt;bool&gt; &gt;(len1+1,vector&lt;bool&gt;(len1+1,false))); for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len1;j++) &#123; res[i][j][1]=s1[i]==s2[j]; &#125; &#125; for(int i=2;i&lt;=len1;i++) &#123; for(int j=0;j&lt;=len1-i;j++) &#123; for(int k=0;k&lt;=len1-i;k++) &#123; for(int r=1;r&lt;i;r++) &#123; if(res[j][k][r]&amp;&amp;res[j+r][k+r][i-r]) &#123; res[j][k][i]=true; break; &#125; if(res[j][k+i-r][r]&amp;&amp;res[j+r][k][i-r]) &#123; res[j][k][i]=true; break; &#125; &#125; &#125; &#125; &#125; return res[0][0][len1]; &#125; &#125;; 312. 戳气球DP思路是这样的，就先别管前面是怎么戳的，你只要管这个区间最后一个被戳破的是哪个气球这最后一个被戳爆的气球就是 k 注意！！！！！k是这个区间 最后一个 被戳爆的气球！！！！！ 假设我们戳i到j的气球，注意不包括i，j，那么假设最后破的气球为ktotal=dp[i][k]+val[i] val[k] val[j]+dp[k][j] 注：val[i] 表示 i 位置气球的数字然后 (i,k) 和 (k,j) 也都是开区间 int maxCoins(vector&lt;int&gt;&amp; nums) &#123; int len=nums.size(); vector&lt;vector&lt;int&gt; &gt; res(len+2,vector&lt;int&gt; (len+2,0)); vector&lt;int&gt; s(len+2,0); s[0]=1; s[len+1]=1; for(int i=0;i&lt;len;i++) &#123; s[i+1]=nums[i]; &#125; for(int i=3;i&lt;=len+2;i++)//作为长度 &#123; for(int j=0;j&lt;=len+2-i;j++) &#123; for(int k=j+1;k&lt;j+i-1;k++) &#123; res[j][j+i-1]=max(res[j][k]+res[k][j+i-1]+s[j+i-1]*s[j]*s[k],res[j][j+i-1]); &#125; &#125; &#125; return res[0][len+1]; 546. 移除盒子这个题目挺难的，用的是区间dp加回溯法，讲道理不太会，下次看这个专题还是有必要重新做。 例如 [9, 5, 3, 5, 3, 3, 9, 8, 8, 5, 3, 9]，对于一个区间，我判断这个区间的第一个连续色块，9，它后面与他相同的色块位置在6和11位置，那么对于9这个色块的处理有3种方法：1、自己直接干掉，消除他后面的，获得1+[5, 3, 5, 3, 3, 9, 8, 8, 5, 3, 9]分2、留着，先把他到他后面第一个9的区间，即[5, 3, 5, 3, 3]干掉，然后再处理9+[9, 8, 8, 5, 3, 9]3、留着，但是跳过他后面第一个9的区间，即把[5, 3, 5, 3, 3, 9, 8, 8, 5, 3]都干掉之后，再去处理9+[9]那么可以看出来状态转移方程了，next[i]表示后面第一个与boxes[i]相等的位置，presame表示前面有几个数字与当前第一个位置的数字相等：dp(presame, i, j) = max(max[dp(0, i+1, nexti-1) + dp(presame+1, nexti, j) for every nexti in next[i]], (presame+1)^2 + dp(0, i+1, j)注意这里的presame会和当前的第一个位置数字一起去当做整体去处理。 int removeBoxes(vector&lt;int&gt;&amp; boxes) &#123; int n=boxes.size(); vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt; dp(n,vector&lt;vector&lt;int&gt;&gt;(n,vector&lt;int&gt;(n+1,0))); return dfs(0,n-1,0,dp,boxes); &#125; int dfs(int l,int r,int k,vector&lt;vector&lt;vector&lt;int&gt;&gt;&gt;&amp; dp,vector&lt;int&gt;&amp; boxes) &#123; if(r&lt;l) return 0; if(dp[l][r][k]!=0) return dp[l][r][k]; while(r&gt;l&amp;&amp;boxes[r]==boxes[r-1]) &#123; k++; r--; &#125; dp[l][r][k]=dfs(l,r-1,0,dp,boxes)+(k+1)*(k+1); for(int i=l;i&lt;r;i++) &#123; if(boxes[r]==boxes[i]) &#123; dp[l][r][k]=max(dp[l][r][k],dfs(l,i,k+1,dp,boxes)+dfs(i+1,r-1,0,dp,boxes)); &#125; &#125; return dp[l][r][k]; &#125; 877. 石子游戏这道题我们采用dp[i][j]来判断先手赢的数目，每次有两种选择选最前面的或者最后面的。然后需要减去下一次先手的结果，因为下一次先手是另外一个人的回合了。大于0就是true.bool stoneGame(vector&lt;int&gt;&amp; piles) &#123; int len=piles.size(); int sum=0; vector&lt;vector&lt;int&gt; &gt; res(len+1,vector&lt;int&gt; (len+1,0)); for(int i=0;i&lt;len;i++) &#123; res[i][i]=piles[i]; &#125; for(int i=2;i&lt;=len;i++) &#123; for(int j=0;j+i&lt;=len;j++) &#123; res[j][j+i-1]=max(piles[j]-res[j+1][j+i-1],piles[j+i-1]-res[j][j+i-2]); &#125; &#125; return res[0][len-1]&gt;0; &#125; 1000. 合并石头的最低成本这个题目四个循环包括的是区间长度从2到n，然后每个res[j][j+i-1][k]每个区间合并成k团的结果，可以考虑把前面合成k-1团，后面认成一团。最后求出每个区间合并成一团的结果。最后求出的值就是结果。 int mergeStones(vector&lt;int&gt;&amp; stones, int K) &#123; int len=stones.size(); if(!(len%(K-1)==1||K==2)) return -1; vector&lt;vector&lt;vector&lt;int&gt; &gt; &gt; res(len+1,vector&lt;vector&lt;int&gt;&gt; (len+1,vector&lt;int&gt; (len+1,1000000))); vector&lt;int&gt; sum(len+1,0); for(int i=1;i&lt;=len;i++) &#123; sum[i]=sum[i-1]+stones[i-1]; res[i-1][i-1][1]=0; &#125; for(int i=2;i&lt;=len;i++) &#123; for(int j=0;j+i&lt;=len;j++) &#123; for(int t=2;t&lt;=K;t++) &#123; for(int r=j;r&lt;=j+i-1;r++) &#123; res[j][j+i-1][t]=min(res[j][j+i-1][t],res[j][r][t-1]+res[r+1][i+j-1][1]); &#125; &#125; res[j][j+i-1][1]=min(res[j][j+i-1][1],sum[j+i]-sum[j]+res[j][j+i-1][K]); &#125; &#125; return res[0][len-1][1]; &#125;","path":"2020/07/27/算法/动态规划/区间dp/"},{"title":"矩阵动态规划","text":"矩阵动态规划的思路方法方法都是用 dp(i, j)dp(i,j) 表示以 (i, j)(i,j) 为右下角，且只包含 11 的正方形的边长最大值。如果我们能计算出所有 dp(i, j)dp(i,j) 的值，那么其中的最大值即为矩阵中只包含 11 的正方形的边长最大值，其平方即为最大正方形的面积。 那么如何计算 dpdp 中的每个元素值呢？对于每个位置 (i, j)(i,j)，检查在矩阵中该位置的值： 如果该位置的值是 00，则 dp(i, j) = 0dp(i,j)=0，因为当前位置不可能在由 11 组成的正方形中； 如果该位置的值是 11，则 dp(i, j)dp(i,j) 的值由其上方、左方和左上方的三个相邻位置的 dpdp 值决定。具体而言，当前位置的元素值等于三个相邻位置的元素中的最小值加 11，状态转移方程如下： dp(i, j)=min(dp(i−1, j), dp(i−1, j−1), dp(i, j−1))+1dp(i,j)=min(dp(i−1,j),dp(i−1,j−1),dp(i,j−1))+1 很巧妙的方法 统计全为 1 的正方形子矩阵给你一个 m * n 的矩阵，矩阵中的元素不是 0 就是 1，请你统计并返回其中完全由 1 组成的 正方形 子矩阵的个数。 示例 1： 输入：matrix =[ [0,1,1,1], [1,1,1,1], [0,1,1,1]]输出：15解释：边长为 1 的正方形有 10 个。边长为 2 的正方形有 4 个。边长为 3 的正方形有 1 个。 class Solution &#123; public: int countSquares(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) &#123; int len=matrix.size(); if(len==0||matrix[0].size()==0) return 0; vector&lt;int&gt; t(matrix[0].size()+1,0); int num=0; vector&lt;vector&lt;int&gt;&gt; res1(len+1,t); for(int i=0;i&lt;len;i++) &#123; for(int j=0;j&lt;matrix[0].size();j++) &#123; if(matrix[i][j]==1) &#123; int r=min(res1[i][j+1],min(res1[i][j],res1[i+1][j]))+1; res1[i+1][j+1]=r; &#125; else &#123; res1[i+1][j+1]=0; &#125; num+=res1[i+1][j+1]; // cout&lt;&lt;res[i+1][j+1]&lt;&lt;&quot; &quot;; &#125; // cout&lt;&lt;endl; &#125; return num; &#125; &#125;; 221. 最大正方形在一个由 0 和 1 组成的二维矩阵内，找到只包含 1 的最大正方形，并返回其面积。 示例: 输入: 1 0 1 0 01 0 1 1 11 1 1 1 11 0 0 1 0 输出: 4 class Solution &#123; public: int maximalSquare(vector&lt;vector&lt;char&gt;&gt;&amp; matrix) &#123; int len=matrix.size(); if(len&lt;=0||matrix[0].size()&lt;=0) &#123; return 0; &#125; int maxsize=0; vector&lt;int&gt; t(matrix[0].size()+1,0); vector&lt;vector&lt;int&gt;&gt; res(len+1,t); for(int i=0;i&lt;len;i++) &#123; for(int j=0;j&lt;matrix[0].size();j++) &#123; if(matrix[i][j]==&#x27;1&#x27;) res[i+1][j+1]=min(min(res[i][j+1],res[i+1][j]),res[i][j])+1; else res[i+1][j+1]=0; //cout&lt;&lt;res[i+1][j+1]&lt;&lt;&quot; &quot;; maxsize=max(maxsize,res[i+1][j+1]); &#125; //cout&lt;&lt;endl; &#125; return maxsize*maxsize; &#125; &#125;;","path":"2020/07/22/算法/动态规划/矩阵动态规划/"},{"title":"排序算法稳定性","text":"堆排序、快速排序、希尔排序、直接选择排序是不稳定的排序算法，而基数排序、冒泡排序、直接插入排序、折半插入排序、归并排序是稳定的排序算法。首先，排序算法的稳定性大家应该都知道，通俗地讲就是能保证排序前2个相等的数其在序列的前后位置顺序和排序后它们两个的前后位置顺序相同。在简单形式化一下，如果Ai = Aj, Ai原来在位置前，排序后Ai还是要在Aj位置前。其次，说一下稳定性的好处。排序算法如果是稳定的，那么从一个键上排序，然后再从另一个键上排序，第一个键排序的结果可以为第二个键排序所用。基数排序就 是这样，先按低位排序，逐次按高位排序，低位相同的元素其顺序再高位也相同时是不会改变的。回到主题，现在分析一下常见的排序算法的稳定性，每个都给出简单的理由。 (1)冒泡排序冒泡排序就是把小的元素往前调或者把大的元素往后调。比较是相邻的两个元素比较，交换也发生在这两个元素之间。所以，如果两个元素相等，我想你是不会再无聊地把他们俩交换一下的；如果两个相等的元素没有相邻，那么即使通过前面的两两交换把两个相邻起来，这时候也不会交换，所以相同元素的前后顺序并没有改 变，所以冒泡排序是一种稳定排序算法。 (2)选择排序选择排序是给每个位置选择当前元素最小的，比如给第一个位置选择最小的，在剩余元素里面给第二个元素选择第二小的，依次类推，直到第n-1个元素，第n个 元素不用选择了，因为只剩下它一个最大的元素了。那么，在一趟选择，如果当前元素比一个元素小，而该小的元素又出现在一个和当前元素相等的元素后面，那么 交换后稳定性就被破坏了。比较拗口，举个例子，序列5 8 5 2 9， 我们知道第一遍选择第1个元素5会和2交换，那么原序列中2个5的相对前后顺序就被破坏了，所以选择排序不是一个稳定的排序算法。 (3)插入排序插入排序是在一个已经有序的小序列的基础上，一次插入一个元素。当然，刚开始这个有序的小序列只有1个元素，就是第一个元素。比较是从有序序列的末尾开 始，也就是想要插入的元素和已经有序的最大者开始比起，如果比它大则直接插入在其后面，否则一直往前找直到找到它该插入的位置。如果碰见一个和插入元素相 等的，那么插入元素把想插入的元素放在相等元素的后面。所以，相等元素的前后顺序没有改变，从原无序序列出去的顺序就是排好序后的顺序，所以插入排序是稳 定的。 (4)快速排序快速排序有两个方向，左边的i下标一直往右走，当a[i] &lt;= a[center_index]，其中center_index是中枢元素的数组下标，一般取为数组第0个元素。而右边的j下标一直往左走，当a[j] &gt; a[center_index]。如果i和j都走不动了，i &lt;= j, 交换a[i]和a[j],重复上面的过程，直到i&gt;j。 交换a[j]和a[center_index]，完成一趟快速排序。在中枢元素和a[j]交换的时候，很有可能把前面的元素的稳定性打乱，比如序列为 5 3 3 4 3 8 9 10 11， 现在中枢元素5和3(第5个元素，下标从1开始计)交换就会把元素3的稳定性打乱，所以快速排序是一个不稳定的排序算法，不稳定发生在中枢元素和a[j] 交换的时刻。 (5)归并排序归并排序是把序列递归地分成短序列，递归出口是短序列只有1个元素(认为直接有序)或者2个元素(1次比较和交换),然后把各个有序的段序列合并成一个有 序的长序列，不断合并直到原序列全部排好序。可以发现，在1个或2个元素时，1个元素不会交换，2个元素如果大小相等也没有人故意交换，这不会破坏稳定 性。那么，在短的有序序列合并的过程中，稳定是否受到破坏？没有，合并过程中我们可以保证如果两个当前元素相等时，我们把处在前面的序列的元素保存在结 果序列的前面，这样就保证了稳定性。所以，归并排序也是稳定的排序算法。 (6)基数排序基数排序是按照低位先排序，然后收集；再按照高位排序，然后再收集；依次类推，直到最高位。有时候有些属性是有优先级顺序的，先按低优先级排序，再按高优 先级排序，最后的次序就是高优先级高的在前，高优先级相同的低优先级高的在前。基数排序基于分别排序，分别收集，所以其是稳定的排序算法。 (7)希尔排序(shell)希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小， 插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比o(n^2)好一些。由于多次插入排序，我们知道一次插入排序是稳定的，不会改变相同元 素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以shell排序是不稳定的。 (8)堆排序我们知道堆的结构是节点i的孩子为2i和2i+1节点，大顶堆要求父节点大于等于其2个子节点，小顶堆要求父节点小于等于其2个子节点。在一个长为n 的序列，堆排序的过程是从第n/2开始和其子节点共3个值选择最大(大顶堆)或者最小(小顶堆),这3个元素之间的选择当然不会破坏稳定性。但当为n /2-1, n/2-2, …1这些个父节点选择元素时，就会破坏稳定性。有可能第n/2个父节点交换把后面一个元素交换过去了，而第n/2-1个父节点把后面一个相同的元素没 有交换，那么这2个相同的元素之间的稳定性就被破坏了。所以，堆排序不是稳定的排序算法。综上，得出结论: 选择排序、快速排序、希尔排序、堆排序不是稳定的排序算法，而冒泡排序、插入排序、归并排序和基数排序是稳定的排序算法。","path":"2020/07/21/算法/排序/排序算法稳定性/"},{"title":"桶排序基数排序相关题目","text":"164. 最大间距桶排序第一种方法采用的是桶排序，方法很巧妙。我们可以知道比较排序最好都是nlogn的，所以不能使用，使用桶排序让我们忽略桶中的顺序，只比较桶之间的大小就可以获得On的复杂度。 那么怎么得到呢，可以得到max,min 然后如果有n个，取一个比平均距离小的内容，为（max-min）/（n）+1,其实也可以加三加四都可以，只需要保证桶内的距离比平均距离小，插值一定在桶间取到就可以，如果每个每个桶的大小对平均距离向下取整，那么相差最大的两个值一定不会在桶中。所以我们只需要记录桶的最大值和最小值，然后比较桶之间的距离就行了。 int maximumGap(vector&lt;int&gt;&amp; nums) &#123; int len=nums.size(); if(len&lt;2) return 0; vector&lt;int&gt; maxnum(len,-1); vector&lt;int&gt; minnum(len,-1); int maxval=-1,minval=nums[0]; for(int i=0;i&lt;len;i++) &#123; if(nums[i]&gt;maxval) maxval=nums[i]; if(nums[i]&lt;minval) minval=nums[i]; &#125; int sizen=(maxval-minval)/(len)+1; for(int i=0;i&lt;len;i++) &#123; int t=(nums[i]-minval)/sizen; if(nums[i]&gt;maxnum[t]) maxnum[t]=nums[i]; if(minnum[t]==-1||nums[i]&lt;minnum[t]) minnum[t]=nums[i]; // cout&lt;&lt;minnum[t]&lt;&lt;&quot; &quot;&lt;&lt;maxnum[t]&lt;&lt;&quot; &quot;&lt;&lt;t&lt;&lt;endl; &#125; int res=0; int tmp=-1; for(int i=0;i&lt;len;i++) &#123; if(maxnum[i]==-1) continue; if(tmp==-1) &#123; tmp=maxnum[i]; continue; &#125; if(minnum[i]-tmp&gt;res) &#123; res=minnum[i]-tmp; // cout&lt;&lt;i&lt;&lt;&quot; &quot;&lt;&lt;minnum[i]&lt;&lt;&quot; &quot;&lt;&lt;tmp&lt;&lt;&quot; &quot;&lt;&lt;res&lt;&lt;endl; &#125; tmp=maxnum[i]; &#125; return res; &#125; 164. 最大间距基数排序基数排序这个是从低位到高位很适合，复杂度是d(n+k),d是位数，k是基数10.这个以前不理解为啥低位到高位可行，其实原因是因为这样是稳定的，例如一个44，41，52.个位数排41，52，44排好，然后排个位就是41，44，52，为什么41一定在前面呢，就是因为，个位的时候已经在前面了，所以要保持稳定性，下次还是在前面。 class Solution &#123; public: int maximumGap(vector&lt;int&gt;&amp; nums) &#123; int len=nums.size(); if(len&lt;2) return 0; vector&lt;int&gt; t(len); vector&lt;vector&lt;int&gt;&gt; res(10,t); int maxnum=-1; for(int i=0;i&lt;len;i++) &#123; maxnum=max(maxnum,nums[i]); &#125; int e=1; while(maxnum!=0) &#123; for(int i=0;i&lt;10;i++) res[i].clear(); for(int i=0;i&lt;len;i++) &#123; int t=nums[i]/e%10; res[t].push_back(nums[i]); &#125; int index=0; for(int i=0;i&lt;10;i++) &#123; for(int j=0;j&lt;res[i].size();j++) &#123; nums[index]=res[i][j]; index++; &#125; &#125; maxnum/=10; e*=10; &#125; int result=0; for(int i=1;i&lt;len;i++) &#123; result=max(result,nums[i]-nums[i-1]); &#125; return result; &#125; &#125;;","path":"2020/07/21/算法/排序/桶排序基数排序相关题目/"},{"title":"C++中取INF","text":"int型是4个字bai节 一个字节8个位 0x7fffffff 是十六进制 最大也就是4个0x7f ,一个0x7f 转化为二进制就zhi是 01111111因为是int型 第一个位是符号位，因而在int 型中0x7fffffff也就是无穷大的意思通过 #define 将 “INF” 转化为符号常量 代表 0x7fffffff最小可以用0x80000000","path":"2020/07/17/C++/C++中取INF/"},{"title":"计数排序基数排序和桶排序","text":"计数排序基数排序和桶排序 这三种方法我经常容易忘记，不太熟悉。总结一下。 计数排序原理很容易懂就是排序元素的范围我们知道，那么就可以将其放到一个这么大的数组中，然后直接每次从数组中取数丢进排序数组中，这个不是一个比较排序的方法。最坏时间复杂度为O(n+k),空间复杂度也为O(n+k) 空间复杂度容易理解，但是时间复杂度我一开始以为的是O(n),实际上这是不对的，因为需要考虑到n很小而k很大 n很大而k很小的情况，综合起来就是O(n+k). 桶排序假设:它使用了具有固定范围的“桶”。它假设每一个元素都会落在这些桶内。每一个桶的范围是固定的。如果桶的范围是1，则该算法就与计数排序很相似了，唯一的不同之处是，它存储的是元素本身而不是它们的计数。 算法： 假设有k个桶：B0, B1, … Bk-1 对于数组a中的每一个元素e： 当e属于Bi时，将其插入Bi中 对于B中的每一个桶b： sort b 令finalarray = {} 对于B中的每一个桶b： finalarray = concat(finalarray, b) 时间复杂度：O(n)，最坏情况O(n n)或者O(n logn)取决于其对桶使用的排序算法。最坏情况下所有元素都落入同一个桶内。 其时间复杂度还与桶的大小和范围有关。如果桶的大小和范围选择不当，可能使得所有元素都落入同一个桶中。如果元素均匀的分布在各个桶内，则时间复杂度就是O(n) 空间复杂度：O(n) 大体讲就是将数分到很多个桶中，每个桶中的排序复杂度很小，然后将数连起来。排序完成，最坏情况大家都在一个桶中效果就很差。 基数排序基数排序的主要思路是,将所有待比较数值(注意,必须是正整数)统一为同样的数位长度,数位较短的数前面补零. 然后, 从最低位开始, 依次进行一次稳定排序(我们常用上一篇blog介绍的计数排序算法, 因为每个位可能的取值范围是固定的从0到9).这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列. 基数排序的时间复杂度是O(n*k)，其中n是排序元素的底，如是十进制就是10，k是数字位数。","path":"2020/07/13/算法/排序/计数排序基数排序和桶排序/"},{"title":"背包九讲","text":"背包九讲01背包问题有 N 件物品和一个容量为 V 的背包。放入第 i 件物品耗费的费用是 Ci1，得到的价值是 Wi。求解将哪些物品装入背包可使价值总和最大。递推方程应该是res[i][V]=max(res[i-1][V-ci]+wi,res[i-1][V]); 可以用滚动数组优化成O(V)空间 这个空间优化的过程，应该逆序得到，顺序不可以。 res[V]=max(res[V-ci],res[V]); V=V……1； 还可以进行常数优化res[V]=max(res[V-ci],res[V]); $a_1$ $V=V……max(V-\\sum^{n}_{i+1}ci+1,ci)$ 为什么是循环到i+1就可以停下来呢？如果是ci较大，那么对于一维空间优化的情况下，表示的是res[i-1][V],对于继续向下循环是不会改变结果的。 如果是V-\\sum^{n}_{i+1}ci+1较大，说明剩下的空间已经不够装ci了，自然也没必要再继续了。 完全背包问题有 N 种物品和一个容量为 V 的背包，每种物品都有无限件可用。放入第 i 种物品的费用是 Ci，价值是 Wi。求解：将哪些物品装入背包，可使这些物品的耗费的费用总和不超过背包容量，且价值总和最大。 这个题目一看很容易认为是贪心问题，但是这个物品是不能分的所以不是贪心的，需要注意。这个我们考虑的就是还是某个物品选不选，但是是可以再次选它的。 二维形式 res[i][V]=max(res[i-1][V],res[i][V-ci]+wi); 一维形式为res[V]=max(res[V],res[V-ci]+wi) v=1……V;在优化的情况下，体积大于V可以直接去掉。O(n) 另外对于任何的体积更大的，但是价值更低的，也可以优化掉。O(n^2) 还可以将体积相同的物品，都用其价值最大的代替。O(V+N)类似计数排序 for i……n if(store[V[i]]&lt;wi) store[V[i]]=wifor i ……v 把这些物品丢进去 多重背包问题有 N 种物品和一个容量为 V 的背包。第 i 种物品最多有 Mi 件可用，每件耗费的空间是 Ci，价值是 Wi。求解将哪些物品装入背包可使这些物品的耗费的空间总和不超过背包容量，且价值总和最大。 这个首先有两个朴素的想法 01背包的想法这个想法是把M[i]个相同的物品看成很多个不同的物品，然后用01背包方法求解。 完全背包的想法这个方法就是对于任何一个物品，每次都有许多个选择，然后选取其中的k个进行空间优化之后和01背包的思路相同。复杂度也相同int mutibackpack()//类似完全背包的方法 &#123; for (int i = 0; i &lt;N; i++) &#123; for (int j = 1; j &lt;=M[i]; j++) &#123; for (int k = C[i]*j; k &lt;=V; k++) &#123; res[k] =max(res[k], res[k-j*C[i]]+j*W[i]); &#125; &#125; &#125; return res[V]; &#125; 二进制优化二进制思想： 假设有 1000 个苹果，现在要取n个苹果，如何取？朴素的做法应该是将苹果一个一个拿出来，直到n个苹果被取出来。再假设有 1000 个苹果和10只箱子，利用箱子进行某些预工作，然后如何快速的取出n个苹果呢？So..可以在每个箱子中放 2^i (i&lt;=0&lt;=n)个苹果，也就是 1、2、4、8、16、32、64、128、256、489（n减完之前的数之后不足 2^i，取最后剩余的数），相当于把十进制的数用二进制来表示，取任意n个苹果时，只要推出几只箱子就可以了。 再次分析： 只看上面是不好理解的，比如：7的二进制 7 = 111, 它可以分解成 001, 010, 100. 这三个数可以组合成任意小于等于 7 的数，而且每种组合都会得到不同的数。再比如，13 = 1101, 则分解为 0001, 0010, 0100, 0110. 前三个数字可以组合成 7 以内任意一个数，每个数再加上0110(= 6) 之后可以组合成任意一个大于等于 6 小于等于 13 的数，所以依然能组成任意小于等于 13 的数，很明显 6,7 会多重复 1 次，但对于求解背包问题是没有影响的，基于这种思想把一种多件物品转换为，多件一种物品，然后用01背包求解即可。 这个想法可以视为从以前我们对于某种物品取它的n数量，会考虑n-1数量的情况，现在我们不是间隔为1进行考虑，而是用二进制的方法来考虑int mutibackpack2()//二进制优化 &#123; int ste = 1; int num; for (int i = 0; i &lt; N; i++) &#123; num = M[i]; while(num&gt;0) &#123; if(num&gt;ste) num -= ste; else &#123; ste = num; num -= ste; &#125; for (int k = C[i] * ste; k &lt;= V; k++) &#123; res[k] = max(res[k], res[k - ste * C[i]] + ste * W[i]); &#125; ste *= 2; &#125; &#125; return res[V]; &#125; 可行性问题多重背包可行性问题指的是：每种有若干件的物品能否填满给定容量的背包，此时不考虑价值最大问题 F(i,j)表示使用前i个物品，填充容量为jjj的背包，第i个物品最多能够剩余多少个，如果无法填充容量为j的背包，则值为-1. F[i-1][j]&gt;0res[i][j]=M[i] F[i][j-C[i]]&lt;=0 || j&lt;C[i]res[i][j]=-1 其他res[i][j]=res[i][j-C[i]]-1 int mutibackpack3()//res[i][j]表示前i中物品填满j大小的空间最大的剩余物品数量,进行了空间优化 &#123; res[0] = M[0]; for (int i = 0; i &lt; V; i++) &#123; res[V] = -1; &#125; for (int i = 0; i &lt; N; i++) &#123; for (int j = 0; j &lt; V; j++) &#123; if (res[j] &gt; 0) res[j] = M[i]; else if (res[j - C[i]] &lt;= 0 || j &lt; C[i]) res[j] = -1; else res[j] = res[j - W[i]] - 1; &#125; &#125; return res[V]; &#125; 单调队列求解这个比较难，暂时没写 混合背包问题01 背包与完全背包的混合考虑到 01 背包和完全背包中给出的伪代码只有一处不同，故如果只有两类物品：一类物品只能取一次，另一类物品可以取无限次，那么只需在对每个物品应用转移方程时，根据物品的类别选用顺序或逆序的循环即可，复杂度是 O(V N)。 再加上多重背包如果再加上最多可以取有限次的多重背包式的物品，那么利用单调队列，也可以给出均摊 O(V N) 的解法。但如果不考虑单调队列算法的话，用将每个这类物品分成 O(logMi) 个 01 背包的物品的方法也已经很优了。最清晰的写法是调用我们前面给出的三个过程。 二维费用的背包问题二维费用的背包问题是指：对于每件物品，具有两种不同的费用，选择这件物品必须同时付出这两种费用。对于每种费用都有一个可付出的最大值（背包容量）。问怎样选择物品可以得到最大的价值。设第 i 件物品所需的两种费用分别为 Ci 和 Di。两种费用可付出的最大值（也即两种背包容量）分别为 V 和 U。物品的价值为 Wi。 算法可以写成res[i][j][k]=max(res[i-1][j][k],res[i][j-ci][k-di]+2i) 有时，“二维费用”的条件是以这样一种隐含的方式给出的：最多只能取 U 件物品。这事实上相当于每件物品多了一种“件数”的费用，每个物品的件数费用均为 1，可以付出的最大件数费用为 U。换句话说，设 F[v, u] 表示付出费用 v、最多选 u 件时可得到的最大价值，则根据物品的类型（01、完全、多重）用不同的方法循环更新，最后在f[0 . . . V, 0 . . . U] 范围内寻找答案。 分组背包有 N 件物品和一个容量为 V 的背包。第 i 件物品的费用是 Ci，价值是 Wi。这些物品被划分为 K 组，每组中的物品互相冲突，最多选一件。求解将哪些物品装入背包可使这些物品的费用总和不超过背包容量，且价值总和最大。 这个问题变成了每组物品有若干种策略：是选择本组的某一件，还是一件都不选。也就是说设 F[k, v] 表示前 k 组物品花费费用 v 能取得的最大权值 res[k][v]=max(res[k-1][v],res[k][v-c[i]]+wi),ci,wi 为组中的东西 依赖背包这个问题由 NOIP2006 中“金明的预算方案”一题扩展而来。遵从该题的提法，将不依赖于别的物品的物品称为“主件”，依赖于某主件的物品称为“附件”。由这个问题的简化条件可知所有的物品由若干主件和依赖于每个主件的一个附件集合组成。按照背包问题的一般思路，仅考虑一个主件和它的附件集合。可是，可用的策略非常多，包括：一个也不选，仅选择主件，选择主件后再选择一个附件，选择主件后再选择两个附件……无法用状态转移方程来表示如此多的策略。事实上，设有 n 个附件，则策略有 2n + 1 个，为指数级。 考虑到所有这些策略都是互斥的（也就是说，你只能选择一种策略），所以一个主件和它的附件集合实际上对应于依赖背包中的一个物品组，每个选择了主件又选择了若干个附件的策略对应于这个物品组中的一个物品，其费用和价值都是这个策略中的物品的值的和。但仅仅是这一步转化并不能给出一个好的算法，因为物品组中的物品还是像原问题的策略一样多。 再考虑对每组内的物品应用完全背包中的优化。我们可以想到，对于第 k 个物品组中的物品，所有费用相同的物品只留一个价值最大的，不影响结果。所以，可以对主件 k 的“附件集合”先进行一次 01 背包，得到费用依次为 0. . .V − Ck 所有这些值时相应的最大价值 Fk[0 . . . V − Ck]。那么，这个主件及它的附件集合相当于 V − Ck + 1 个物品的物品组，其中费用为 v 的物品的价值为 Fk[v − Ck] + Wk，v 的取值范围是 Ck ≤ v ≤ V 。 也就是说，原来指数级的策略中，有很多策略都是冗余的，通过一次 01 背包后，将主件 k 及其附件转化为 V − Ck + 1 个物品的物品组，就可以直接应用6的算法解决问题了。 在树形依赖的背包问题中，我们将每颗子树作为一个泛化物品来看。同样，我们可以对每个主件的附件集合进行处理，合成一个新的泛化物品。即对每个主件的附件集合做一次01背包，得到res[j],j为0……v-wi,wi为第i个主件的空间，表示该附件集合在分配体积为j的情况下该附件总和的最优值。 更一般的问题是：依赖关系以图论中“森林”3的形式给出。 也就是说，主件的附件仍然可以具有自己的附件集合。限制只是每个物品最多只依赖于一个物品（只有一个主件）且不出现循环依赖。解决这个问题仍然可以用将每个主件及其附件集合转化为物品组的方式。唯一不同的是，由于附件可能还有附件，就不能将每个附件都看作一个一般的 01 背包中的物品了。若这个附件也有附件集合，则它必定要被先转化为物品组，然后用分组的背包问题解出主件及其附件集合所对应的附件组中各个费用的附件所对应的价值。事实上，这是一种树形动态规划，其特点是，在用动态规划求每个父节点的属性之前，需要对它的各个儿子的属性进行一次动态规划式的求值。这已经触及到了“泛化物品”的思想。看完泛化物品后，你会发现这个“依赖关系树”每一个子树都等价于一件泛化物品，求某节点为根的子树对应的泛化物品相当于求其所有儿子的对应的泛化物品之和。 泛化物品考虑这样一种物品，它并没有固定的费用和价值，而是它的价值随着你分配给它的费用而变化。这就是泛化物品的概念。更严格的定义之。在背包容量为 V 的背包问题中，泛化物品是一个定义域为 0 . . . V中的整数的函数 h，当分配给它的费用为 v 时，能得到的价值就是 h(v)。这个定义有一点点抽象，另一种理解是一个泛化物品就是一个数组 h[0 . . . V ]，给它费用 v，可得到价值 h[v]。一个费用为 c 价值为 w 的物品，如果它是 01 背包中的物品，那么把它看成泛化物品，它就是除了 h(c) = w 外，其它函数值都为 0 的一个函数。如果它是完全背包中的物品，那么它可以看成这样一个函数，仅当 v 被 c 整除时有 h(v) = w ·v c，其它函数值均为 0。如果它是多重背包中重复次数最多为 m 的物品，那么它对应的泛化物品的函数有 h(v) = w ·vc 仅当 v 被 c 整除且 vc ≤ n，其它情况函数值均为 0。 一个物品组可以看作一个泛化物品 h。对于一个 0 . . . V 中的 v，若物品组中不存在费用为 v 的物品，则 h(v) = 0，否则 h(v) 取值为所有费用为 v 的物品的最大价值。6中每个主件及其附件集合等价于一个物品组，自然也可看作一个泛化物品。 泛化物品的和如果给定了两个泛化物品 h 和 l，要用一定的费用从这两个泛化物品中得到最大的价值，这个问题怎么求呢？事实上，对于一个给定的费用 v，只需枚举将这个费用如何分配给两个泛化物品就可以了。同样的，对于 0. . .V 中的每一个整数 v，可以求得费用v 分配到 h 和 l 中的最大价值 f(v)。 f(v)=max(h(k)+l(v-k)) k=1……v 由泛化物品的定义可知：在一个背包问题中，若将两个泛化物品代以它们的和，不影响问题的答案。事实上，对于其中的物品都是泛化物品的背包问题，求它的答案的过程也就是求所有这些泛化物品之和的过程。若问题的和为 s，则答案就是 s(0 . . . V ) 中的最大值。 搜索还是DP?在看到一道背包问题时，应该用搜索还是动态规划呢？ 首先，可以从数据范围中得到命题人意图的线索。如果一个背包问题可以用DP解，V一定不能很大，否则O(VN)的算法无法承受，而一般的搜索解法都是仅与N有关，与V无关的。所以，V很大时（例如上百万），命题人的意图就应该是考察搜索。另一方面，N较大时（例如上百），命题人的意图就很有可能是考察动态规划了。 另外，当想不出合适的动态规划算法时，就只能用搜索了。例如看到一个从未见过的背包中物品的限制条件，无法想出DP的方程，只好写搜索以谋求一定的分数了。","path":"2020/07/13/算法/动态规划/背包九讲/"},{"title":"打家劫舍","text":"粉刷房子1这个题目leetcode需要会员，题干如下。假如有一排房子，共 n 个，每个房子可以被粉刷成红色、蓝色或者绿色这三种颜色中的一种，你需要粉刷所有的房子并且使其相邻的两个房子颜色不能相同。 当然，因为市场上不同颜色油漆的价格不同，所以房子粉刷成不同颜色的花费成本也是不同的。每个房子粉刷成不同颜色的花费是以一个 n x 3 的矩阵来表示的。 例如，costs[0][0] 表示第 0 号房子粉刷成红色的成本花费；costs[1][2] 表示第 1 号房子粉刷成绿色的花费，以此类推。请你计算出粉刷完所有房子最少的花费成本。 注意： 所有花费均为正整数。 示例： 输入: [[17,2,17],[16,16,5],[14,3,19]]输出: 10解释: 将 0 号房子粉刷成蓝色，1 号房子粉刷成绿色，2 号房子粉刷成蓝色。 最少花费: 2 + 5 + 3 = 10。 选取第i个房子涂不同颜色的最小值public int minCostII(vector&lt;vector&lt;int&gt;&gt; costs) &#123; int n=costs.size(); if(n==0) return 0; int a=costs[0][0],b=costs[0][1],c=costs[0][2]; int t1,t2,t3; for(int i=0;i&lt;n;i++) &#123; t1=a; t2=b; t3=c; a=min(b,c)+costs[i][0];//刷成红色的最大值 b=min(t1,t3)+costs[i][1]; c=min(t1,t2)+costs[i][2];//刷成蓝色 &#125; return min((min(a,b)),c); &#125; 粉刷房子2假如有一排房子，共 n 个，每个房子可以被粉刷成 k 种颜色中的一种，你需要粉刷所有的房子并且使其相邻的两个房子颜色不能相同。 当然，因为市场上不同颜色油漆的价格不同，所以房子粉刷成不同颜色的花费成本也是不同的。每个房子粉刷成不同颜色的花费是以一个 n x k 的矩阵来表示的。 例如，costs[0][0] 表示第 0 号房子粉刷成 0 号颜色的成本花费；costs[1][2] 表示第 1 号房子粉刷成 2 号颜色的成本花费，以此类推。请你计算出粉刷完所有房子最少的花费成本。 注意： 所有花费均为正整数。 示例： 输入: [[1,5,3],[2,9,4]]输出: 5解释: 将 0 号房子粉刷成 0 号颜色，1 号房子粉刷成 2 号颜色。最少花费: 1 + 4 = 5; 或者将 0 号房子粉刷成 2 号颜色，1 号房子粉刷成 0 号颜色。最少花费: 3 + 2 = 5. 这个题目如果用正常的思路，那么应该是对每个位置的房子，选取不同的颜色k，然后取其颜色不为k最小值。O(nkk). 会导致超时，复杂度过高。 可以优化每次选上一个的最短花费和次短花费。如果颜色和最短花费不一样，则选最短花费，否则选次短花费。这个地方应该注意一点，我之前很迷惑如果最短和次短都是和它一个颜色怎么办呢，后来才发现其实选的是在上一个位置颜色不同的最短花费和次短花费。这个地方比较巧妙，需要额外注意。 public int minCostII(vector&lt;vector&lt;int&gt;&gt; costs,int k) &#123; int n=costs.size(); if(n==0||costs[0].size()==0) return 0; auto res=costs; int tmp1=0,tmp2=1; int a1=-1,a2=-1; for(int i=0;i&lt;n;i++) &#123; a1=-1; a2=-1; for(int j=0;j&lt;k;j++) &#123; if(j==tmp1) &#123; res[i][j]=(i==0?costs[i][j]:res[i-1][tmp1]+costs[i][j]); &#125; else &#123; res[i][j]=(i==0?costs[i][j]:res[i-1][tmp2]+costs[i][j]); &#125; if(a2&lt;0||res[i][j]&lt;res[i][a2]) &#123; a2=j; if(a2&lt;0||res[i][a2]&lt;res[i][a1]) &#123; swap(a2,a1); &#125; &#125; &#125; tmp1=a1; tmp2=a2; &#125; return res[n-1][tmp1]; &#125;","path":"2020/07/13/算法/动态规划/粉刷房子/"},{"title":"打家劫舍","text":"打家劫舍1递推公式为d0[i]=d1[i-1]+price,d1[i]=max(d1[i-1],d0[i-1]);可以进行空间优化class Solution &#123; public: int rob(vector&lt;int&gt;&amp; nums) &#123; if(nums.size()==0) return 0; int a=nums[0]; int b=0; int len=nums.size(); int t; for(int i=1;i&lt;len;i++) &#123; t=a; a=b+nums[i]; b=max(b,t); &#125; return max(a,b); &#125; &#125;; 打家劫舍2只需要保证最后一个和第一个不会被同时取到，注意这个不是约瑟夫问题那样可以循环的。所以只需要求两次然后考虑删除第一个和删除最后一个的情况。 int rob(vector&lt;int&gt;&amp; nums) &#123;//不能来回偷 int len=nums.size(); if(len==0) return 0; if(len==1) return nums[0]; vector&lt;int&gt; res1; res1.assign(nums.begin()+1, nums.end()); vector&lt;int&gt; res2; res2.assign(nums.begin(),nums.end()-1); int a=res2[0]; int b=0; int t; for(int i=1;i&lt;len-1;i++) &#123; t=a; a=b+res2[i]; b=max(t,b); &#125; int res=max(a,b); a=res1[0]; b=0; for(int i=1;i&lt;len-1;i++) &#123; t=a; a=b+res1[i]; b=max(t,b); &#125; int tt=max(a,b); return max(res,tt); &#125; 打家劫舍3这个结构是树形的，相比数组的要难一些，所以第一种方法就是考虑根节点偷和不偷的情况，然后返回之，我第一次做是用的递归返回的是偷和随便偷不偷，这样是不行的，应该要明确状态。 vector&lt;int&gt; dp0(TreeNode* root) &#123; vector&lt;int&gt; res(2,0); if(root==nullptr) return res; vector&lt;int&gt; res1=dp0(root-&gt;left); vector&lt;int&gt; res2=dp0(root-&gt;right); res[0]=root-&gt;val+res1[1]+res2[1];//偷这个根节点的选项 res[1]=max(res1[0],res1[1])+max(res2[0],res2[1]);//不偷的选项 return res; &#125; int rob(TreeNode* root) &#123; if(root==nullptr) return 0; vector&lt;int&gt; res=dp0(root); return max(res[0],res[1]); &#125; 事实上确实有一种考虑随便偷不偷的方法的。在区分偷不偷的时候，我们事实上考虑的是偷目前节点加上随便偷不偷孙子节点，以及不偷目前节点，随便偷不偷儿子节点。为了防止超时，用哈希表把求得的信息存起来。unordered_map&lt;TreeNode*,int&gt; m; int dp0(TreeNode* root,unordered_map&lt;TreeNode*,int&gt;&amp; m) &#123; int value=0; if(root==nullptr) return 0; if(m.count(root)) return m[root]; if(root-&gt;left!=nullptr) value+=dp0(root-&gt;left-&gt;left,m)+dp0(root-&gt;left-&gt;right,m); if(root-&gt;right!=nullptr) value+=dp0(root-&gt;right-&gt;left,m)+dp0(root-&gt;right-&gt;right,m); int t=max(root-&gt;val+value,dp0(root-&gt;right,m)+dp0(root-&gt;left,m)); m[root]=t; return t; &#125; int rob(TreeNode* root) &#123; if(root==nullptr) return 0; return dp0(root,m); &#125;","path":"2020/07/13/算法/动态规划/打家劫舍/"},{"title":"股票买卖问题","text":"股票买卖问题1当前的最大收益只依赖于之前的最小买入价格。只需要记住到目前为止的最小值，然后可以得到每个位置的收益。O(n)class Solution &#123; public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int max=0; int len=prices.size(); if(len==0) return 0; int min=prices[0]; for(int i=0;i&lt;len;i++) &#123; if(prices[i]&gt;min) &#123; int t=prices[i]-min; if(max&lt;t) max=t; &#125; else &#123; min=prices[i]; &#125; &#125; return max; &#125; &#125;; 股票买卖问题2这个题目朴素的想法就是找到每个峰谷和峰顶，然后求差异获得利润。但是由于可以进行多次交易，那么只要明天比今天价格高就有得赚，就可以进行交易。不需要去找波峰波谷，因为day2-day1+day3-day2 == day3-day1 class Solution &#123; public: int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int res=0; int len=prices.size(); for(int i=1;i&lt;len;i++) &#123; if(prices[i]&gt;prices[i-1]) res+=prices[i]-prices[i-1]; &#125; return res; &#125; &#125;; 股票买卖问题3int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int len=prices.size(); if(len==0) return 0; vector&lt;int&gt; res1(3,0); vector&lt;int&gt; res2(3,0); for(int i=0;i&lt;3;i++) res2[i]=-prices[0]; for(int i=1;i&lt;len;i++) &#123; res2[0]=max(res2[0],-prices[i]); for(int j=1;j&lt;=2;j++) &#123; res1[j]=max(res1[j],res2[j-1]+prices[i]); res2[j]=max(res1[j]-prices[i],res2[j]); &#125; &#125; return res1[2]; &#125; 股票买卖问题4买卖k次 当前处于第几天；已经交易的次数；手头是否持有股票；即根据手头是否持有股票，我们定义两个二维数组来定义状态： dp0[i][j]: 第i天结束，已有j次买卖，手头没有股票时的最大利润dp1[i][j]: 第i天结束，已有j次买卖，手头有股票时的最大利润因此，dp0[0][j]对于所有j都要初始化为0，而dp1[0][j]对于所有j都要初始化为-prices[i]。如果我们将dp0所有值都求出来了，那么很明显dp0[n-1][k]就是在最后一天结束时已进行k次交易且手头无股票时的最大收益，也即返回结果。 先看初始状态: 当i==0 &amp;&amp; j&gt;=0: dp0[0][j] = 0, dp1[0][j] = -prices[0];当i&gt;0 &amp;&amp; j==0: dp0[i][0] = 0, dp1[i][0] = max(dp1[i-1][0], -prices[i]);再来考虑状态转移方程，当i&gt;0且j&gt;0时有 dp0[i][j] = max(dp0[i-1][j], dp1[i-1][j-1] + prices[i]) # 保持 or 卖出dp1[i][j] = max(dp1[i-1][j], dp0[i-1][j] - prices[i]) # 保持 or 买入有了状态定义及转移方程，剩下就好办了。 int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int k=2;//可以改变k值 int len=prices.size(); if(len==0) return 0; vector&lt;int&gt; a(k+1,0); vector&lt;vector&lt;int&gt;&gt; res1(len,a);//没有股票在手中 vector&lt;vector&lt;int&gt;&gt; res2(len,a);//有股票在手中 int min=prices[0]; for(int i=0;i&lt;k;i++) res2[0][i]=-prices[0]; for(int i=1;i&lt;len;i++) &#123; res2[i][0]=max(res2[i-1][0],-prices[i]); &#125; for(int i=1;i&lt;len;i++) &#123; for(int j=1;j&lt;=k;j++) &#123; res1[i][j]=max(res1[i-1][j],res2[i-1][j-1]+prices[i]); res2[i][j]=max(res1[i-1][j]-prices[i],res2[i-1][j]); &#125; &#125; return res1[len-1][k]; &#125; 但是这个效率不高，可以知道，当k&gt;2/n的时候。就是买卖无数次了。并且可以进行空间优化。int maxProfit(int k, vector&lt;int&gt;&amp; prices) &#123; int len=prices.size(); if(len==0||k==0) return 0; if(k&gt;len/2) &#123; int result=0; for(int i=1;i&lt;len;i++) &#123; if(prices[i]&gt;prices[i-1]) result+=prices[i]-prices[i-1]; &#125; return result; &#125; vector&lt;int&gt; res1(k+1,0); vector&lt;int&gt; res2(k+1,0); int min=prices[0]; for(int i=0;i&lt;k;i++) res2[i]=-prices[0]; for(int i=1;i&lt;len;i++) &#123; res2[0]=max(res2[0],-prices[i]); for(int j=1;j&lt;=k;j++) &#123; res1[j]=max(res1[j],res2[j-1]+prices[i]); res2[j]=max(res1[j]-prices[i],res2[j]); &#125; &#125; return res1[k]; &#125; 股票买卖问题5这里需要注意的就是当不持股，不在冷冻期的可能就是，上一个是冷冻期，然后这一天啥也没干，还有可能就是直接就是上一天。int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int len=prices.size(); if(len==0) return 0; vector&lt;int&gt; res1(len,0);//不持股，不在冷冻期 vector&lt;int&gt; res2(len,0);//持股，不在冷冻期 res2[0]=-prices[0]; vector&lt;int&gt; res3(len,0);//不持股，在冷冻期 for(int i=1;i&lt;len;i++) &#123; res1[i]=max(res1[i-1],res3[i-1]); res2[i]=max(res1[i-1]-prices[i],res2[i-1]); res3[i]=res2[i-1]+prices[i]; &#125; return max(res3[len-1],res1[len-1]); &#125; 优化空间 int maxProfit(vector&lt;int&gt;&amp; prices) &#123; int len=prices.size(); if(len==0) return 0; int res1=0;//不持股，不在冷冻期 int res2=-prices[0];//持股，不在冷冻期 int res3=0;//不持股，在冷冻期 for(int i=1;i&lt;len;i++) &#123; int a=res1; int b=res2; res1=max(a,res3); res2=max(a-prices[i],b); res3=b+prices[i]; &#125; return max(res3,res1); &#125; 股票买卖问题6也是和之前的类似，选取两个状态，持有股票，不持有股票，在卖出时还需要减去手续费。 int maxProfit(vector&lt;int&gt;&amp; prices, int fee) &#123; int len=prices.size(); int res1=0; int res2=-prices[0]; int t; for(int i=0;i&lt;len;i++) &#123; t=res1; res1=max(res1,res2+prices[i]-fee); res2=max(res2,t-prices[i]); &#125; return res1; &#125;","path":"2020/07/12/算法/动态规划/股票买卖问题/"},{"title":"动态规划题型总结","text":"因为动态规划毕竟要满足： 阶段性无后效性子问题重叠性因此，能够利用DP来解决的问题实际上是有限的，大部分题目都是针对现有的模型的一些变种，改改题目描述，或者加点限制条件。所以要想攻克DP题目，最根本的就是要充分理解几个常见的DP模型。而要充分理解常见经典DP模型，就需要通过大量的做题和总结，而且二者不可偏废。通过做题进行思考和量的积累，通过总结加深理解和融会贯通进而完成质的提升。 动态规划是求解一个最优化问题，而最核心的思想就是： 分而治之想办法记录下中间的计算结果避免重复计算解一道DP题目，先问自己几个问题： 我需要最少哪些数据，然后经过一些比较就能得出最终结果？这些数据的求解是否可以用同样的方法分而治之？过程中的运算结果如何保存复用？当然以上内容看起来比较抽象，虽然它深刻地揭露了动态规划的本质，但是如果临场要去想明白这些问题，还是有些难度。如果只是针对比赛和面试，就像前面说的，DP题型是有限的。只要刷的题目足够多，总结出几个经典模型，剩下的都是些变种+优化而已。 一般来说，动态规划可以分成4个大类: 线性DP数位dp概率dp等区间DP树型DP背包线性DP就是阶段非常线性直观的模型，比如：最长（上升|下降）序列，最长公共子序列(LCS)等，也有一些简单的递推，甚至都算不上是经典模型。 线性dp最长上升序列最长上升序列是一个非常经典的线性模型。说它是个模型，是因为它是一类题的代表，很多题目都只是换个说法，或者要求在这基础上进一步优化而已。最长上升序列最基础的转移方程就是f[i] = max{f[j]}+1 (a[i] &gt; a[j]),f[i]表示一定要以a[i]结尾的序列，最长长度是多少。很显然就是在前面找到一个最大的f[j]同时满足a[j]&lt;a[i]。因此是N^2的时间复杂度和N的空间复杂度。这种方法是最朴素直观的，一定要理解。它非常简单，因此很少有题目直接能够这么做。大部分相关题目需要进一步优化，也就是有名的单调队列优化，能够把复杂度优化到nlogn。相关题目比如： 300. 最长上升子序列，裸题，但是要击败100%的话，需要单调队列优化。 354. 俄罗斯套娃信封问题，这道题还是hard。之前的最长上升序列是一维的，这道题是二维的上升序列，满足Ax&lt;Bx且Ay&lt;By，才可以构成上升序列。那么我们可以根据x进行排序，然后对y求解最长上升子序列。但是这里有个地方需要注意，因为x必须要严格升序，排序之后可能存在(1,1) (1,2) (1,3) (2,4)这样的序列，如果对y进行求解上升序列，会得到4，但是实际应该只是2。为了避免这个问题，在排序时，如果x相等，则y按照降序排列，就可以规避这个问题。 合唱队形，这道题是要求一个形如1 3 4 7 9 8 6 5 2这样的子序列。先上升再下降，最后求最长的长度。其实解决办法也很简单，先从左到右求出所有的最长上升序列asc[i]，再从右到左求出所有的最长上升序列reverseAcc[i]，最大值就是max(asc[i]+reverseAcc[i])。对算法要能够灵活运用。 LCS 最长公共子序列最长公共子序列也是线性DP中的一种比较常见的模型。说它是一种“模型”其实有点拔高了，其实它就是一类比较常见的题目。很多题目都是在LCS的基础上进行简单的扩展，或者仅仅就是换一个说法而已。求两个数组的最长公共子序列，最直观地做法就是：设f[i][j]表示S[..i]和T[..j]的最长公共子序列，则有: f[i][j] = f[i-1][j-1] + 1 …… S[i]==T[j]f[i][j] = max(f[i-1][j], f[i][j-1]) …… S[i]≠T[j]这个转移方程也非常好理解，时间复杂度是N^2，空间复杂度也是N^2。不过仔细观察你可以发现，当我们计算第i行时只与i-1和i行有关。因此我们可以利用01滚动来优化空间复杂度为2N。相关题目： 1143. Longest Common Subsequence：这道题就是裸的LCS 583. Delete Operation for Two Strings：两个字符串要删除成一样的，所以先找出最长公共序列，然后剩下的都删了。 718. Maximum Length of Repeated Subarray：这道题其实本质上不是LCS，它是寻找最长子数组，而不是子序列（子数组要求连续）。需要搞清它们的区别。找子数组就更简单了，因为必须连续，所以f[i][j] = f[i-1][j-1]+1 : 0 ? S[i]==T[j]。通过倒序枚举能够把空间优化为O(N)。 1092. Shortest Common Supersequence：这道题是hard，实际上也不算很hard。其实就是找到最长公共子序列，然后，对于A字符串，把除了LCS以外的字符插入到对应的位置；对于B字符串也做同样的操作。这道题大家需要掌握一个新姿势，就是除了求最长公共子序列有多长，还要会打印最长公共子序列（follow up：打印所有可能的最长公共子序列）。同时，要把剩余的字符插入到对应的位置其实可以想办法把原字符串按照LCS切分成k+1段，比如对于字符串A abcxdef，其lcs为bde，那么我们可以把原字符串切成4段 a bcx d ef，同样对于B字符串，也能切成4段，然后对应插入构成新字符串即可，需要注意的就是，从第1段开始，第一个字符是lcs字符，所以只插一次。 股票买卖问题 Best Time to Buy and Sell Stock：当前的最大收益只依赖于之前的最小买入价格。因此只需要一个变量保存截至目前的最低价即可，每次更新最大收益。 Best Time to Buy and Sell Stock II：由于可以进行多次交易，那么只要明天比今天价格高就有得赚，就可以进行交易。不需要去找波峰波谷，因为day2-day1+day3-day2 == day3-day1。 可以买卖两次股票三个状态，已经买卖2次，持有 不持有股票，第k天为结束天 可以买卖k次股票三个状态，已经买卖k次，持有 不持有股票，第k天为结束天 卖出股票之后有冷冻期选择三个状态，持有股票，不持有股票，处于冷冻期 卖出股票之后有手续费选择两个状态，持有股票，不持有股票 打家劫舍粉刷房子背包九讲图形问题区间dp树形dp","path":"2020/07/12/算法/动态规划/动态规划/"},{"title":"1143. 最长公共子序列","text":"最长公共子序列最长公共子序列也是线性DP中的一种比较常见的模型。说它是一种“模型”其实有点拔高了，其实它就是一类比较常见的题目。很多题目都是在LCS的基础上进行简单的扩展，或者仅仅就是换一个说法而已。求两个数组的最长公共子序列，最直观地做法就是：设f[i][j]表示S[..i]和T[..j]的最长公共子序列，则有: f[i][j] = f[i-1][j-1] + 1 …… S[i]==T[j]f[i][j] = max(f[i-1][j], f[i][j-1]) …… S[i]≠T[j]这个转移方程也非常好理解，时间复杂度是N^2，空间复杂度也是N^2。不过仔细观察你可以发现，当我们计算第i行时只与i-1和i行有关。因此我们可以利用01滚动来优化空间复杂度为2N。 class Solution &#123; public://使用了2N的空间的动态优化 int longestCommonSubsequence(string text1, string text2) &#123; int len1=text1.size(); int len2=text2.size(); vector&lt;int&gt; a1(len2+1,0); vector&lt;int&gt; a2(len2+1,0); int flag=2; for(int i=0;i&lt;len1;i++) &#123; for(int j=0;j&lt;len2;j++) &#123; if(text1[i]==text2[j]) &#123; if(flag==2) a2[j+1]=a1[j]+1; else a1[j+1]=a2[j]+1; &#125; else &#123; if(flag==2) a2[j+1]=max(a2[j],a1[j+1]); else a1[j+1]=max(a2[j+1],a1[j]); &#125; &#125; flag=-flag; &#125; if(flag==2) return a1[len2]; else return a2[len2]; &#125; &#125;;","path":"2020/07/12/算法/1143.最长公共子序列/"},{"title":"300. 最长上升子序列","text":"最长上升序列最长上升序列是一个非常经典的线性模型。说它是个模型，是因为它是一类题的代表，很多题目都只是换个说法，或者要求在这基础上进一步优化而已。最长上升序列最基础的转移方程就是f[i] = max{f[j]}+1 (a[i] &gt; a[j]),f[i]表示一定要以a[i]结尾的序列，最长长度是多少。很显然就是在前面找到一个最大的f[j]同时满足a[j]&lt;a[i]。因此是N^2的时间复杂度和N的空间复杂度。这种方法是最朴素直观的，一定要理解。它非常简单，因此很少有题目直接能够这么做。大部分相关题目需要进一步优化，也就是有名的单调队列优化，能够把复杂度优化到nlogn。 说单调队列优化之前必须明白一个贪心策略。因为要求的是最长上升序列，那么很显然长度为k的上升序列的最大值（最后一个数）越小越好，这样后面的数才有更大的概率比它大。如果我们记录下来不同长度的上升序列的最后一个数能达到的最小值，那么对于后续每个数t，它要么能放到某个长度为y的序列之后，组成长度为y+1的上升序列，要么放到某个长度为x的序列后面，把长度为x+1的序列的最大值替换成t。同时我们可以发现，如果x&lt;y，那么长度为x序列的最后一个数一定比长度为y的序列最后一个数小。因此这个上升序列我们可以用一个数组来维护（所谓的单调队列），数组下标就代表序列长度。opt[i]=t表示长度为i的上升序列最后一个数最小是t。那么当我们在面对后续某个数x时，可以对单调队列opt进行二分，把它插到对应的位置。因此总体复杂度就是NlogN。 class Solution &#123; public: // int lengthOfLIS(vector&lt;int&gt;&amp; nums) // &#123;//dp，不用单调队列,递推方程res[i]=max(res[j])+1 (nums[j]&lt;nums[i]) // int len=nums.size(); // if(len==0) // return 0; // vector&lt;int&gt; res(len,0); // res[0]=1; // int result=1; // for(int i=1;i&lt;len;i++) // &#123; // int maxnum=1; // for(int j=0;j&lt;i;j++) // &#123; // if(res[j]+1&gt;maxnum&amp;&amp;nums[j]&lt;nums[i]) // maxnum=res[j]+1; // &#125; // res[i]=maxnum; // if(res[i]&gt;result) // result=res[i]; // &#125; // return result; // &#125; int lengthOfLIS(vector&lt;int&gt;&amp; nums) &#123;//dp，用单调队列,递推方程res[i]=max(res[j])+1 (nums[j]&lt;nums[i]) int len=nums.size(); if(len==0) return 0; vector&lt;int&gt; res; for(int i=0;i&lt;len;i++) &#123; if(res.size()==0||res[res.size()-1]&lt;nums[i]) res.push_back(nums[i]); else //if(res[res.size()-1]&lt;nums[i]) &#123; int p=BinSearch(res,nums[i]); res[p]=nums[i]; &#125; &#125; return res.size(); &#125; int BinSearch(vector&lt;int&gt;&amp; a,int b) &#123; int len=a.size(); int l=0,r=len-1; int mid=l+(r-l)/2; while(a[mid]!=b) &#123; if(r==l) return r; if(a[mid]&lt;b) &#123; l=mid+1; &#125; else &#123; r=mid; &#125; mid=mid=l+(r-l)/2; &#125; return mid; &#125; &#125;;","path":"2020/07/12/算法/动态规划/300. 最长上升子序列/"},{"title":"65. 有效数字","text":"题目使用有穷自动机来解决，画出DFA就可以很好的解决。有穷自动机可见 代码如下：100%内存100%速度&lt;!—hexoPostRenderEscape:class Solution &#123;public: bool isNumber(string s) &#123; int sta; if(s.size()&lt;=0) return false; if(isdigit(s[0])) sta=2; else if(s[0]==&#x27;.&#x27;) sta=4; else if(s[0]==&#x27; &#x27;) sta=1; else if(s[0]==&#x27;-&#x27;||s[0]==&#x27;+&#x27;) sta=3; else return false; for(int i=1;i&lt;s.size();i++) &#123; switch(sta) &#123; case 1: if(isdigit(s[i])) sta=2; else if(s[i]==&#x27;.&#x27;) sta=4; else if(s[i]==&#x27; &#x27;) sta=1; else if(s[i]==&#x27;-&#x27;||s[i]==&#x27;+&#x27;) sta=3; else return false; break; case 2: if(isdigit(s[i])) sta=2; else if(s[i]==&#x27;.&#x27;) sta=5; else if(s[i]==&#x27;e&#x27;) sta=7; else if(s[i]==&#x27; &#x27;) sta=6; else return false; break; case 3: if(isdigit(s[i])) sta=2; else if(s[i]==&#x27;.&#x27;) sta=4; else return false; break; case 4: if(isdigit(s[i])) sta=5; else return false; break; case 5: if(isdigit(s[i])) sta=5; else if(s[i]==&#x27;e&#x27;) sta=7; else if(s[i]==&#x27; &#x27;) sta=6; else return false; break; case 6: if(s[i]==&#x27; &#x27;) sta=6; else return false; break; case 7: if(s[i]==&#x27;+&#x27;||s[i]==&#x27;-&#x27;) sta=8; else if(isdigit(s[i])) sta=9; else return false; break; case 8: if(isdigit(s[i])) sta=9; else return false; break; case 9: if(isdigit(s[i])) sta=9; else if(s[i]==&#x27; &#x27;) sta=6; else return false; break; &#125; &#125; cout&lt;&lt;sta; if(sta==2||sta==5||sta==9||sta==6) return true; else return false; &amp;#125; &#125;;&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2020/07/03/算法/[LeetCode] 65. 有效数字/"},{"title":"验证集和测试集的区别","text":"验证集和测试集 类别 验证集 测试集 是否被训练到 否 否 作用 用于调整超参数 用于验证泛化能力 使用次数 多次使用，以不断调参 仅仅一次使用 缺陷 模型在一次次重新手动调参并继续训练后所逼近的验证集，可能只代表一部分非训练集，导致最终训练好的模型泛化性能不够 测试集为了具有泛化代表性，往往数据量比较大，测试一轮要很久，所以往往只取测试集的其中一小部分作为训练过程中的验证集 互相转化 验证集具有足够泛化性（一般来说，如果验证集足够大到包括大部分非训练集时，也等于具有足够泛化性了） 验证集具有足够泛化性时，测试集就没有存在的必要了 类比 校内答辩（如果校内答辩比多校联合答辩还有泛化性说服力，那么就没有必要再搞个多校联合答辩了） 多校联合答辩 附言说到底：验证集是一定需要的；如果验证集具有足够泛化代表性，是不需要再整出什么测试集的；整个测试集往往就是为了在验证集只是非训练集一个小子集的情况下，好奇一下那个靠训练集（训练）和验证集（调参）多次接力训练出来的模型是不是具有了泛化性能，因而加试一下图个确定。","path":"2020/07/03/深度学习/验证集和测试集的区别/"},{"title":"166. 分数到小数","text":"166. 分数到小数这道题我认为需要注意的有几个地方 第一个地方在于除法如何计算，这里我选择的方法是当被除数相同的时候认为是循环小数。 第二个地方在于结果可能有负数，负数的求模和正数有所不同，需要注意。负数求模是a-(a/b)*b的，有个时候因此会有正负的区分。 第三个地方在于数字溢出的问题，a=-2147483648, b=-1,a*b是会溢出的，因为会先转成一个整形的数，因此需要转一下long. 第四个地方是在判断两个数是否是同号的时候最好采用异或的方法，而不要采用相乘符号的方法，这样会导致溢出，还有一个我以前没注意的地方就是异或等位运算的优先级是要低于等于符号的，因此最好加上括号。 代码如下class Solution &#123; public: string fractionToDecimal(int numerator, int denominator) &#123; long a1=long(numerator)%denominator; long a2=long(numerator)/denominator; if(a1==0) return to_string(a2); else &#123; int i=0; int quo=abs(a2); string res=&quot;&quot;; if((numerator^denominator)&lt;0) &#123; res=res+&quot;-&quot;; i++; &#125; res=res+to_string(quo)+&quot;.&quot;; i+=to_string(quo).size()-1; unordered_map&lt;int,int&gt; map; numerator=abs(a1); while(numerator!=0) &#123; numerator=abs(numerator); if(map.find(numerator)==map.end()) &#123; map[numerator]=i; i++; &#125; else &#123; string tmp=res.substr(map[numerator]+2); string tmp1=res.substr(0,map[numerator]+2); res=tmp1+&quot;(&quot;+tmp+&quot;)&quot;; return res; &#125; long ttt=numerator; ttt*=10; long a=abs(ttt/denominator); long b=abs(ttt%denominator); res=res+to_string(a); numerator=b; &#125; return res; &#125; &#125; &#125;;","path":"2020/06/12/算法/166. 分数到小数/"},{"title":"设计模式","text":"设计模式学习[toc] 设计模式和原则单一职责的原则简单的说就是软件模块应该只有一个被修改的理由。例如Spring中，我们需要有dao 层和service层，而不是把它放在一起，这样后面数据库增加字段，或者业务逻辑更改的时候就不需要修改很多东西，更容易维护。 开闭原则就是在一个模块完成的之后，就不要去改变它，最好是通过继承和多态来增加功能。所以开闭就是，对外的拓展开放，对外的修改闭合。 里氏替换原则简单的说就是尽量不要重写父类的方法，最好是只新增功能，子类可以拓展父类的功能，但是不能改变 如果通过重写父类的方法来完成新的功能，这样写起来虽然简单，但是整个继承体系的可复用性会比较差，特别是运用多态比较频繁时，程序运行出错的概率会非常大。 例如几维鸟虽然生物学上是鸟，但是不会飞，如果在计算飞行的一些行为的时候，设计成继承鸟类，最后会出现错误，因此最好仔细考虑他们的继承关系，去除继承关系。 接口隔离原则接口隔离原则（Interface Segregation Principle，ISP）要求程序员尽量将臃肿庞大的接口拆分成更小的和更具体的接口，让接口中只包含客户感兴趣的方法。 要为各个类建立它们需要的专用接口，而不要试图去建立一个很庞大的接口供所有依赖它的类去调用。 接口隔离原则和单一职责都是为了提高类的内聚性、降低它们之间的耦合性，体现了封装的思想，但两者是不同的：单一职责原则注重的是职责，而接口隔离原则注重的是对接口依赖的隔离。单一职责原则主要是约束类，它针对的是程序中的实现和细节；接口隔离原则主要约束接口，主要针对抽象和程序整体框架的构建。 依赖倒置原则依赖倒置原则的原始定义为：高层模块不应该依赖低层模块，两者都应该依赖其抽象；抽象不应该依赖细节，细节应该依赖抽象。 由于在软件设计中，细节具有多变性，而抽象层则相对稳定，因此以抽象为基础搭建起来的架构要比以细节为基础搭建起来的架构要稳定得多。这里的抽象指的是接口或者抽象类，而细节是指具体的实现类。 使用接口或者抽象类的目的是制定好规范和契约，而不去涉及任何具体的操作，把展现细节的任务交给它们的实现类去完成。 在实际编程中只要遵循以下4点，就能在项目中满足这个规则。每个类尽量提供接口或抽象类，或者两者都具备。变量的声明类型尽量是接口或者是抽象类。任何类都不应该从具体类派生。使用继承时尽量遵循里氏替换原则。 创建型模式","path":"2020/06/03/设计模式/设计模式/"},{"title":"ART算法实现与理解","text":"Code这两个图显示了算法的原理，整体的几何意义也较为容易理解 import numpy as np def ART_My( A, b, X0, e0): e=e0+1 i=0 while(e&gt;e0): tmp=((A[i]@X0-b[i])/(np.linalg.norm(A[i]))*(A[i].T/np.linalg.norm(A[i]))) X=X0-np.reshape(tmp,(-1,1)) e=np.linalg.norm(X-X0) X0=X i=(i+1)%np.shape(A)[0] print(e) return X0 if __name__==&quot;__main__&quot;: A=np.array([[3,1],[1,5]]) b=np.array([[1],[1]]) e0=0.000001 X0=np.array([[0],[0]]) X=ART_My(A,b,X0,e0) print((X))","path":"2020/06/03/医学图像/ART算法实现与理解/"},{"title":"函数间隔和几何间隔","text":"对同一个超平面，通过比例缩放w和b，函数间隔也会同比例变化。也就是说，对于一个成功划分正负实例的超平面（不一定最优），该平面固定，但是通过缩放w和b，可以使其function margin取任何正值。而我们的目标是找到具有最大margin的超平面。显然通过最大化函数间隔没有意义，因为任何成功划分训练实例的超平面都可以使函数间隔无限大。我们注意到，对一个超平面，函数间隔与∥w∥的比值保持不变，也就是说几何间隔与超平面关联。所以，我们目标是最大化几何间隔，而且我们可以令函数间隔为1，然后最小化∥w∥达到最大化几何间隔目的。 SVM是通过超平面将样本分为两类。在超平面wx+b确定的情况下，||wx+b||可以相对地表示点距离超平面的远近。对于两类分类问题，如果wx+b&gt;0，可视为在平面上方，则的类别被判定为1；否则判定为-1。所以样本点与超平面之间的函数间隔定义为y(wx+b),但是该定义存在问题：即w和x同时缩小或放大M倍后，超平面并没有变化，但是函数间隔却变化了。w是法向量，所以，需要将w的大小固定,使得函数间隔固定。这时的间隔也就是几何间隔 。","path":"2020/05/21/深度学习/函数间隔和几何间隔/"},{"title":"大端和小端","text":"字节存储顺序主要分为大端序（Big-endian）和小端序（Little-endian），区别如下Big-endian：高位字节存入低地址，低位字节存入高地址Little-endian：低位字节存入低地址，高位字节存入高地址一般来说，x86系列CPU都是Little-endian字节序，PowerPC通常是Big-endian字节序。 因为网络协议也都是采用Big-endian方式传输数据的，所以有时也把Big-endian方式称为网络字节序","path":"2020/05/20/C++/大端和小端/"},{"title":"218. 天际线问题","text":"问题的求解方法一其实我们在题目标签看到了Line Sweep，[ 线扫描或扫描线 ] ，扫描线可以想象成一条向右扫过平面的竖直线，也是一个算法，一般是玩图形学的。 接着上面的步骤，可以通过扫描线算法将两个关键点集合进行合并。 如下图，扫描线从两个集合的起始点，同时向右移动，接触到第一个关键点，则判断这一个关键点是不是满足天际线的，如果是，则将这个关键点添加到“父”集合中；如果不是，则继续同时移动到下一个关键点。 但如何判断是否是属于“父”集合中的关键点呢？可以创建两个集合（“子”）的目前高度，然后多方角度找到满足关键点的条件。 扫描线移到[2 10]关键点时，10要大于rpre的，可以满足； 扫描线移到[3 15]关键点时，lpre此时目前的高度为10，而15要大于10的，可以满足； 扫描线移到[7 10]关键点时，rpre大于lpre可以满足，反之就不满足； 接着有一个集合已经遍历完了，剩下的集合的关键点肯定是满足的，因为没有其它的集合可以阻挡到这个集合，所以直接就是满足。 这个求解方法中的归并的写法比我以前写的要简洁一些，值得学习。这个问题的求解方法的重点在于合并两个点，合并过程中首先选择一个集合的小的，然后判断其与当前另外一个集合的当前值的关于，如果大于则一定可以加进去，因为这个值和自身高度同样也不同如果小于等于并且自身当前高度要大于另外一个集合的当前值，则可以加，否则就被盖住实际是看不到的。 在相等的情况下，我们应该考虑到相同X的位置的最高位置的不能和和此时的当前的最大位置相同，如果相同实际上是形成了一条直线，是看不到的。 class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; getSkyline(int[][] buildings) &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;List&lt;Integer&gt;&gt;(); if(buildings.length==0) return res; return divide(buildings,0,buildings.length-1); &#125; public List&lt;List&lt;Integer&gt;&gt; divide(int [][]buildings,int l,int r) &#123; List&lt;Integer&gt; list=new ArrayList&lt;Integer&gt;(); List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;List&lt;Integer&gt;&gt;(); if(r==l) &#123; res.add(Arrays.asList(buildings[l][0],buildings[l][2])); res.add(Arrays.asList(buildings[l][1],0)); return res; &#125; int a=l+(r-l)/2; List&lt;List&lt;Integer&gt;&gt; res1=divide(buildings,l,a); List&lt;List&lt;Integer&gt;&gt; res2=divide(buildings,a+1,r); int l1=0; int r1=0; int lh=0,rh=0; int leftX, leftY, rightX, rightY; while(l1&lt;res1.size()||r1&lt;res2.size()) &#123; if(l1&gt;=res1.size()) res.add(res2.get(r1++)); else if(r1&gt;=res2.size()) res.add(res1.get(l1++)); else &#123; leftX = res1.get(l1).get(0); // 不会出现null，可以直接用int类型 leftY = res1.get(l1).get(1); rightX = res2.get(r1).get(0); rightY = res2.get(r1).get(1); if(leftX&gt;rightX)//每次选择一个较小的 &#123; if(rightY&gt;lh) res.add(res2.get(r1)); else if(rh&gt;lh) &#123; res.add(Arrays.asList(rightX,lh)); &#125; rh=rightY; r1++; &#125; else if(leftX&lt;rightX) &#123; if(leftY&gt;rh) res.add(res1.get(l1)); else if(lh&gt;rh) res.add(Arrays.asList(leftX,rh)); lh=leftY; l1++; &#125; else &#123; int h=Math.max(lh,rh); if(leftY&gt;=rightY&amp;&amp;leftY!=h) &#123; res.add(res1.get(l1)); &#125; else if(leftY&lt;=rightY&amp;&amp;rightY!=h)//只要不汇聚到最高点就没问题 &#123; res.add(res2.get(r1)); &#125; lh=leftY; rh=rightY; l1++; r1++; &#125; &#125; &#125; return res; &#125; &#125; 这个方法是扫面线算法，方法较为巧妙，左上和右上节点分别设置为负数和正数，从左加入右先队列，从右边删除出，然后每次和最大的节点进行比较，不同就加入节点。这里的java的容器的比较器的写法是o2-o1，大于0就是顺序，否则逆序。 class Solution &#123; public List&lt;List&lt;Integer&gt;&gt; getSkyline(int[][] buildings) &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;List&lt;Integer&gt;&gt;(); Set&lt;Pair&lt;Integer,Integer&gt;&gt; pairs=new TreeSet&lt;&gt;((o1,o2)-&gt;!o1.getKey().equals(o2.getKey())?o1.getKey()-o2.getKey():o1.getValue()-o2.getValue()); for(int[] bu:buildings) &#123; pairs.add(new Pair&lt;&gt;(bu[0],-bu[2])); pairs.add(new Pair&lt;&gt;(bu[1],bu[2])); &#125; PriorityQueue&lt;Integer&gt; queue=new PriorityQueue&lt;&gt;((o1,o2)-&gt;o2-o1); int prev = 0; // 遍历 for (Pair&lt;Integer, Integer&gt; pair : pairs) &#123; if (pair.getValue() &lt; 0) queue.offer(-pair.getValue()); // 左端点 高度入堆 else queue.remove(pair.getValue()); // 右端点 高度出堆 Integer cur = queue.peek() == null ? 0 : queue.peek(); // 获取最大堆的当前顶点，当null时置为0 if (prev != cur) &#123; res.add(new ArrayList&lt;Integer&gt;() &#123; &#123; add(pair.getKey()); add(cur); &#125;&#125;); prev = cur; &#125; &#125; return res; &#125; &#125;","path":"2020/05/20/算法/218. 天际线问题/"},{"title":"为啥那么C++pop不返回值","text":"书上的解释也就是说，为什么先用top（），然后用pop（）来访问和删除站定的元素，而不是把它们合并一个返回类型T的成员函数。 这种设计有很好的理由。如果pop（）返回栈顶元素，则必须按值返回，而不是按引用返回。按引用返回是不可行的，因为元素 在栈中已经不存在，必须在按引用返回之前现将其存储到某个地方。如果选用动态内存，除非动态内存最终被删除，否则将导致内存泄露。 按照数值返回效率很差，因为它包含对类型T的复制构造函数的调用。让pop（）返回数值将会导致潜在的内存问题或效率很低下， 因此最好让它什么数值也不返回，而是通过使用top（）来得到栈顶的数值。 从异常上看这么使用 Stack stack; stack.push(object); Object obj=stack.pop() ; 当我们执行Object obj=stack.pop() 时，Object的构造函数被调用，而这里是可以反生异常的， 假设这时候发生异常，丢生的栈顶元素就回不去了。 而在java中pop（）是有返回值的源码是这么写的 int i = size(); Object object = peek(); removeElementAt(i - 1); return (E)object; 实质上java进行对象赋值的时候是进行引用的。但是C++是进行一个复制构造函数的调用，","path":"2020/05/20/C++/为什么C++pop不返回值/"},{"title":"145. 二叉树的后序遍历","text":"方法后序遍历的麻烦之处在于不知道现在自己是父节点的左节点还是右节点，只有知道才能决定下一步是访问右节点还是根节点，不知道的情况下就不清楚下一步应该访问弹出的栈元素的本身还是它的右节点。而前序遍历和中序遍历是总是只需要弹出栈中的元素，然后访问其右节点即可或者先访问自己再访问其右节点。 所以方法有三种： 开始的话，也是不停的往左子树走，然后直到为 null ，然后如果集合中没有栈顶元素，并且右子树不为空，那么我们就访问栈顶元素的右节点，并把栈顶元素加入集合中，如果集合中有，那么直接访问栈顶元素即可。class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); Set&lt;TreeNode&gt; set=new HashSet&lt;TreeNode&gt;(); TreeNode treenode=root; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; stack.push(treenode); treenode=treenode.left; &#125; else &#123; TreeNode tmp=stack.peek(); if(!set.contains(tmp)&amp;&amp;tmp.right!=null) &#123; treenode=tmp.right; set.add(tmp); &#125; else &#123; res.add(tmp.val); stack.pop(); &#125; &#125; &#125; return res; &#125; &#125; 如果当前节点的右节点和上一次遍历的节点相同，那就表明当前是从右节点过来的了class Solution &#123; public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); TreeNode treenode=root; TreeNode last=null; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; stack.push(treenode); treenode=treenode.left; &#125; else &#123; TreeNode tmp=stack.peek(); if(tmp.right!=null&amp;&amp;tmp.right!=last) &#123; treenode=tmp.right; &#125; else &#123; res.add(tmp.val); last=tmp; stack.pop(); &#125; &#125; &#125; return res; &#125; &#125; 只需要把每个节点 push 两次，然后判断当前 pop 节点和栈顶节点是否相同。相同的话，就意味着是从左子树到的根节点。不同的话，就意味着是从右子树到的根节点，此时就可以把节点加入到 list 中。这个方法比较巧妙 public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); if (root == null) &#123; return list; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); stack.push(root); while (!stack.isEmpty()) &#123; TreeNode cur = stack.pop(); if (cur == null) &#123; continue; &#125; if (!stack.isEmpty() &amp;&amp; cur == stack.peek()) &#123; stack.push(cur.right); stack.push(cur.right); stack.push(cur.left); stack.push(cur.left); &#125; else &#123; list.add(cur.val); &#125; &#125; return list; &#125; 可以转换成一个逆的前序遍历来实现public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123; List&lt;Integer&gt; res=new ArrayList&lt;Integer&gt;(); Stack&lt;TreeNode&gt; stack=new Stack&lt;TreeNode&gt;(); TreeNode treenode=root; while(!stack.isEmpty()||treenode!=null) &#123; if(treenode!=null) &#123; res.add(treenode.val); stack.add(treenode); treenode=treenode.right; &#125; else &#123; treenode=stack.pop().left; &#125; &#125; Collections.reverse(res); return res; &#125;","path":"2020/05/19/算法/145. 二叉树的后序遍历/"},{"title":"232. 用栈实现队列","text":"双栈实现队列，思路较为简单 ···class MyQueue { private Stack stack1; private Stack stack2; /* Initialize your data structure here. / public MyQueue() { stack1=new Stack(); stack2=new Stack(); } /** Push element x to the back of queue. */ public void push(int x) &#123; stack1.push(x); &#125; /** Removes the element from in front of queue and returns that element. */ public int pop() &#123; if(stack2.isEmpty()) &#123; StackMove(stack1,stack2); &#125; int res=stack2.peek(); stack2.pop(); return res; &#125; /** Get the front element. */ public int peek() &#123; if(stack2.isEmpty()) &#123; StackMove(stack1,stack2); &#125; int res=stack2.peek(); return res; &#125; /** Returns whether the queue is empty. */ public boolean empty() &#123; return stack1.isEmpty()&amp;&amp;stack2.isEmpty(); &#125; public void StackMove(Stack&lt;Integer&gt; stack1,Stack&lt;Integer&gt; stack2) &#123; if(stack2.isEmpty()) &#123; while(!stack1.isEmpty()) &#123; int a=stack1.peek(); stack2.push(a); stack1.pop(); &#125; &#125; &#125; } /** Your MyQueue object will be instantiated and called as such: MyQueue obj = new MyQueue(); obj.push(x); int param_2 = obj.pop(); int param_3 = obj.peek(); boolean param_4 = obj.empty();*/···","path":"2020/05/19/算法/232. 用栈实现队列/"},{"title":"225. 用队列实现栈","text":"队列实现栈主要是栈的pop操作比较困难，这个可以通过栈的循环出队入队来实现，复杂度为O(N)。&lt;!—hexoPostRenderEscape:class MyStack &#123;&lt;/span&gt; private Queue&lt;Integer&gt; quene=new LinkedList&lt;Integer&gt;(); private int mytop=0; /* Initialize your data structure here. / public MyStack() &lt;/span&gt;&#123; &#125; &lt;span class=&quot;hljs-comment&quot;&gt;/** Push element x onto stack. */&lt;/span&gt; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; x)&lt;/span&gt; &lt;/span&gt;&amp;#123; quene.offer(x); mytop=x; &amp;#125; &lt;span class=&quot;hljs-comment&quot;&gt;/** Removes the element on top of the stack and returns that element. */&lt;/span&gt; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;pop&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;;i&amp;lt;quene.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;()&lt;span class=&quot;hljs-number&quot;&gt;-1&lt;/span&gt;;i++) &amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; a=quene.poll(); quene.offer(a); &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(i==quene.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;()&lt;span class=&quot;hljs-number&quot;&gt;-2&lt;/span&gt;) mytop=a; &amp;#125; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; quene.poll(); &amp;#125; &lt;span class=&quot;hljs-comment&quot;&gt;/** Get the top element. */&lt;/span&gt; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;top&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(!quene.isEmpty()) &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; mytop; &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;; &amp;#125; &lt;span class=&quot;hljs-comment&quot;&gt;/** Returns whether the stack is empty. */&lt;/span&gt; &lt;span class=&quot;hljs-function&quot;&gt;&lt;span class=&quot;hljs-keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;boolean&lt;/span&gt; &lt;span class=&quot;hljs-title&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;hljs-params&quot;&gt;()&lt;/span&gt; &lt;/span&gt;&amp;#123; &lt;span class=&quot;hljs-keyword&quot;&gt;if&lt;/span&gt;(quene.&lt;span class=&quot;hljs-built_in&quot;&gt;size&lt;/span&gt;()==&lt;span class=&quot;hljs-number&quot;&gt;0&lt;/span&gt;) &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-literal&quot;&gt;true&lt;/span&gt;; &lt;span class=&quot;hljs-keyword&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;hljs-keyword&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;hljs-literal&quot;&gt;false&lt;/span&gt;; &amp;#125; &#125; /** * Your MyStack object will be instantiated and called as such: * MyStack obj = new MyStack(); * obj.push(x); * int param_2 = obj.pop(); * int param_3 = obj.top(); * boolean param_4 = obj.empty(); */&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2020/05/19/算法/225. 用队列实现栈/"},{"title":"linux短横线的区别","text":"linux短横线的区别rm -vf *** tar -xzvf ***.tar.gz gcc --version rm --help 从上面命令我们可以看出，绝大数命令有以下的规则： ① 参数前单杠的表明后面的参数是字符形式； ② 参数前双杠的则表明后面的参数是单词形式 tar xzvf ***.tar.gz tar -xzvf ***.tar.gz 两种命令行都是行的通的，并且功能都是解压软件包，那它们到底有什么不同呢，实际上这就涉及两种Linux风格，System V和BSD。它们对应关系如下： ① 参数前有横的是System V风格。 ② 参数前没有横的是BSD风格。 System V和BSD两种风格的区别主要是： 系统启动过程中 kernel 最后一步调用的是 init 程序，init 程序的执行有两种风格，即 System V 和 BSD。 System V 风格中 init 调用 /etc/inittab，BSD 风格调用 /etc/rc，它们的目的相同，都是根据 runlevel 执行一系列的程序。","path":"2020/05/18/操作系统/linux短横线的区别/"},{"title":"224. 基本计算器","text":"方法1和方法二：只有加减的话，相当于去掉括号，去掉括号的过程就是，把数字和字符串弹出，然后计算的过程，这个方法比较麻烦，应该可以采用字符串反向便利的方式进行计算，这样计算表达式就要方便很多，从左到右算就可以，如果还有乘除之类的话，那么在过程中应该还要判断字符的优先级，然后进行计算,还有一个需要注意的就是，数字可能有很多位。 方法一： class Solution &#123; public int calculate(String s) &#123; Stack &lt;Integer&gt; op1=new Stack &lt;Integer&gt;();//数字栈 Stack&lt;Character&gt; op2=new Stack&lt;Character&gt;();//字符栈 int t=0; int flag=1;//正在记录数字 for(int i=0;i&lt;s.length();i++) &#123; Character ch=s.charAt(i); if(flag==0&amp;&amp;!Character.isDigit(ch)) &#123; op1.push(t); System.out.println(t); flag=1; t=0; &#125; if(Character.isDigit(ch)) &#123; flag=0; int num=(int)(ch-&#39;0&#39;); t=t*10+num; &#125; else if(ch.equals(&#39;-&#39;)||ch.equals(&#39;+&#39;)||ch.equals(&#39;(&#39;)) &#123; op2.push(ch); &#125; else if(ch.equals(&#39;)&#39;)) &#123; op1.push(CalFormula(op1,op2)); &#125; &#125; if(flag==0) &#123; op1.push(t); System.out.println(t); flag=1; t=0; &#125; return CalFormula(op1,op2); &#125; public int CalFormula(Stack &lt;Integer&gt; op1 , Stack&lt;Character&gt; op2) &#123; Stack &lt;Integer&gt; op3=new Stack &lt;Integer&gt;();//数字栈 Stack&lt;Character&gt; op4=new Stack&lt;Character&gt;();//字符栈 while(!op2.isEmpty()&amp;&amp;!op2.peek().equals(&#39;(&#39;)) &#123; op3.push(op1.peek()); op1.pop(); op4.push(op2.peek()); op2.pop(); // System.out.println(op2.peek()); &#125; op3.push(op1.peek()); op1.pop(); if(!op2.isEmpty()&amp;&amp;op2.peek().equals(&#39;(&#39;)) op2.pop(); while(!op4.isEmpty()) &#123; int a=op3.peek(); op3.pop(); int b=op3.peek(); op3.pop(); char c=op4.peek(); op4.pop(); op3.push(cal(c,a,b)); &#125; return op3.peek(); &#125; public int cal(Character ch,Integer num,Integer num1) &#123; if(ch.equals(&#39;-&#39;)) return num-num1; else return num+num1; &#125; &#125; 方法2： class Solution &#123; public int calculate(String s) &#123; Stack &lt;Integer&gt; op1=new Stack &lt;Integer&gt;();//数字栈 Stack&lt;Character&gt; op2=new Stack&lt;Character&gt;();//字符栈 Integer t=0; StringBuffer nu=new StringBuffer(&quot;&quot;); int flag=1;//正在记录数字 StringBuffer a=new StringBuffer(s); String str=a.reverse().toString(); for(int i=0;i&lt;str.length();i++) &#123; Character ch=str.charAt(i); if(flag==0&amp;&amp;!Character.isDigit(ch)) &#123; t=Integer.parseInt(nu.reverse().toString()); op1.push(t); flag=1; nu=new StringBuffer(&quot;&quot;); &#125; if(Character.isDigit(ch)) &#123; nu.append(ch); flag=0; &#125; else if(ch.equals(&#39;-&#39;)||ch.equals(&#39;+&#39;)||ch.equals(&#39;)&#39;)) &#123; op2.push(ch); &#125; else if(ch.equals(&#39;(&#39;)) &#123; CalFormula(op1,op2); &#125; &#125; if(flag==0) &#123; t=Integer.parseInt(nu.reverse().toString()); op1.push(t); &#125; return CalFormula(op1,op2); &#125; public int CalFormula(Stack &lt;Integer&gt; op1 , Stack&lt;Character&gt; op2) &#123; Stack &lt;Integer&gt; op3=new Stack &lt;Integer&gt;();//数字栈 Stack&lt;Character&gt; op4=new Stack&lt;Character&gt;();//字符栈 while(!op2.isEmpty()&amp;&amp;!op2.peek().equals(&#39;)&#39;)) &#123; int a=op1.peek(); op1.pop(); int b=op1.peek(); op1.pop(); Character c=op2.peek(); op2.pop(); op1.push(cal(c,a,b)); &#125; if(!op2.isEmpty()&amp;&amp;op2.peek().equals(&#39;)&#39;)) op2.pop(); return op1.peek(); &#125; public int cal(Character ch,Integer num,Integer num1) &#123; if(ch.equals(&#39;-&#39;)) return num-num1; else return num+num1; &#125; &#125; 方法三采用一种双栈的方法，解法一经过了一个中间过程，先转为了后缀表达式然后进行求值。我们其实可以直接利用两个栈，边遍历边进行的，这个方法是我当时上课学的方法。从 这里 把过程贴到下边，和解法一其实有些类似的。 使用两个栈，stack0 用于存储操作数，stack1 用于存储操作符从左往右扫描，遇到操作数入栈 stack0遇到操作符时，如果当前优先级低于或等于栈顶操作符优先级，则从 stack0 弹出两个元素，从 stack1 弹出一个操作符，进行计算，将结果并压入stack0，继续与栈顶操作符的比较优先级。如果遇到操作符高于栈顶操作符优先级，则直接入栈 stack1遇到左括号，直接入栈 stack1。遇到右括号，则从 stack0 弹出两个元素，从 stack1 弹出一个操作符进行计算，并将结果加入到 stack0 中，重复这步直到遇到左括号和解法一一样，因为我们只有加法和减法，所以这个流程可以简化一下。 第 3 条改成「遇到操作符时，则从 stack0 弹出两个元素进行计算，并压入stack0，直到栈空或者遇到左括号，最后将当前操作符压入 stack1 」处。 class Solution &#123; public int calculate(String s) &#123; Stack &lt;Integer&gt; op1=new Stack &lt;Integer&gt;();//数字栈 Stack&lt;Character&gt; op2=new Stack&lt;Character&gt;();//字符栈 HashMap&lt;Character,Integer&gt; map=new HashMap&lt;Character,Integer&gt;(); map.put(&#39;+&#39;,1); map.put(&#39;-&#39;,1); map.put(&#39;(&#39;,-1); Integer t=0; int flag=1; Character ch; for(int i=0;i&lt;s.length();i++) &#123; ch=s.charAt(i); if(flag==0&amp;&amp;!Character.isDigit(ch)) &#123; op1.push(t); t=0; flag=1; &#125; if(Character.isDigit(ch)) &#123; flag=0; t=t*10+(int)(ch-&#39;0&#39;); &#125; else if(ch.equals(&#39;-&#39;)||ch.equals(&#39;+&#39;)) &#123; flag=1; while(!op2.isEmpty()&amp;&amp;!(map.get(op2.peek())&lt;map.get(ch))) &#123; int a=op1.peek(); op1.pop(); int b=op1.peek(); op1.pop(); Character c=op2.peek(); op2.pop(); op1.push(cal(c,b,a)); &#125; op2.push(ch); &#125; else if(ch.equals(&#39;(&#39;)) &#123; flag=1; op2.push(ch); &#125; else if(ch.equals(&#39;)&#39;)) &#123; flag=1; while(!op2.isEmpty()&amp;&amp;!op2.peek().equals(&#39;(&#39;)) &#123; int a=op1.peek(); op1.pop(); int b=op1.peek(); op1.pop(); Character c=op2.peek(); op2.pop(); op1.push(cal(c,b,a)); &#125; op2.pop(); &#125; &#125; if(flag==0) &#123; op1.push(t); &#125; while(!op2.isEmpty()) &#123; int a=op1.peek(); op1.pop(); int b=op1.peek(); op1.pop(); Character c=op2.peek(); op2.pop(); op1.push(cal(c,b,a)); &#125; return op1.peek(); &#125; public int cal(Character ch,Integer num,Integer num1) &#123; if(ch.equals(&#39;-&#39;)) return num-num1; else return num+num1; &#125; &#125; 双栈解法我们可以使用两个栈 nums 和 ops 。 nums ： 存放所有的数字ops ：存放所有的数字以外的操作，+/- 也看做是一种操作然后从前往后做，对遍历到的字符做分情况讨论： 空格 : 跳过( : 直接加入 ops 中，等待与之匹配的 )) : 使用现有的 nums 和 ops 进行计算，直到遇到左边最近的一个左括号为止，计算结果放到 nums数字 : 从当前位置开始继续往后取，将整一个连续数字整体取出，加入 nums+/- : 需要将操作放入 ops 中。在放入之前先把栈内可以算的都算掉，使用现有的 nums 和 ops 进行计算，直到没有操作或者遇到左括号，计算结果放到 nums一些细节： 由于第一个数可能是负数，为了减少边界判断。一个小技巧是先往 nums 添加一个 0为防止 () 内出现的首个字符为运算符，将所有的空格去掉，并将 (- 替换为 (0-，(+ 替换为 (0+（当然也可以不进行这样的预处理，将这个处理逻辑放到循环里去做） c++解法 int calculate(string s) &#123; stack&lt;int&gt; num; stack&lt;char&gt; op; int len=s.size(); num.push(0); char lastch=&#39; &#39;; for(int i=0;i&lt;len;++i) &#123; cout&lt;&lt;i&lt;&lt;endl; char ch=s[i]; if(ch==&#39; &#39;) continue; else if(ch&gt;=&#39;0&#39;&amp;&amp;ch&lt;=&#39;9&#39;) &#123; int curnum=0; int j=i; while(j&lt;len&amp;&amp;s[j]&gt;=&#39;0&#39;&amp;&amp;s[j]&lt;=&#39;9&#39;) &#123; curnum=curnum*10-&#39;0&#39;+s[j]; j++; &#125; num.push(curnum); i=j-1; &#125; else if(ch==&#39;(&#39;) &#123; op.push(&#39;(&#39;); &#125; else if(ch==&#39;)&#39;) &#123; while(!op.empty()) &#123; char myop = op.top(); if(myop != &#39;(&#39;) calc(num, op); else &#123; op.pop(); break; &#125; &#125; &#125; else &#123; if(i&gt;0&amp;&amp;(lastch==&#39;(&#39;||lastch==&#39;+&#39;||lastch==&#39;-&#39;)) &#123; num.push(0); &#125; while(!op.empty()) &#123; if(op.top()==&#39;(&#39;) &#123; break; &#125; calc(num, op); &#125; op.push(ch); &#125; if(ch!=&#39; &#39;) lastch=ch; &#125; while(!op.empty()) &#123; calc(num,op); &#125; return num.top(); &#125; void calc(stack&lt;int&gt; &amp;num,stack&lt;char&gt; &amp;op) &#123; if(num.size() &lt; 2 || op.empty()) return ; int a=num.top(); num.pop(); int b=num.top(); num.pop(); char ch=op.top(); op.pop(); // cout&lt;&lt;b&lt;&lt;&quot; &quot;&lt;&lt;ch&lt;&lt;&quot; &quot;&lt;&lt;a&lt;&lt;endl; if(ch==&#39;+&#39;) num.push(b+a); else num.push(b-a); &#125;","path":"2020/05/18/算法/224. 基本计算器/"},{"title":"统计学习方法-第九章EM算法及其推广","text":"第九章EM算法及其推广9.1 import numpy as np y=[1,1,0,1,0,0,1,0,1,1] pai=0.46 p=0.55 q=0.67 theta=2 while(theta&gt;0.0001): u_next=[] for i in range(len(y)): a=pai*(p**y[i])*((1-p)**(1-y[i])) b=(1-pai)*(q**y[i])*((1-q)**(1-y[i])) u_next.append(a/(a+b)) pai_next=0 p_next=0 q_next=0 tmp=0 pai_next=np.mean(u_next) p_next = sum(np.multiply(u_next,y))/sum(u_next) tmp=[1-u_next[i] for i in range(len(y))] q_next = sum(np.multiply(tmp,y))/sum(tmp) print(pai_next) print(p_next) print(q_next) print(&quot;\\n&quot;) theta=abs(pai_next-pai)+abs(p_next-p)+abs(q_next-q) pai=pai_next p=p_next q=q_next 求得&lt;!—hexoPostRenderEscape:0.4618628351139190.53459500378501120.6561346417857326 0.461862835113919070.53459500378501120.6561346417857326&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2020/05/18/深度学习/统计学习方法课后作业/"},{"title":"神经网络初始化与xavier初始化","text":"xavier初始化 深度学习初始化总结","path":"2020/05/18/深度学习/神经网络初始化与xavier初始化/"},{"title":"矩阵的范数","text":"关于矩阵的范数的一些总结 一范数，二范数，闵可夫斯基范数这些都比较常见，一般不用多说 核范数代表矩阵的奇异值之和，是用来约束低秩的一种范数，代表rank(w)的凸近似。 ||X||_*=\\sum_{i}^{}\\sigma_i(x)F范数即为就是对应元素的平方和再开方。f范数实际上就是衡量这个矩阵和对应的零矩阵的距离，","path":"2020/05/18/深度学习/矩阵的范数/"},{"title":"矩阵求导","text":"参考文章","path":"2020/05/18/深度学习/矩阵求导/"},{"title":"在hexo博客中写数学公式","text":"这个网站值得借鉴","path":"2020/05/18/文档相关/在hexo博客中写数学公式/"},{"title":"图像的k空间","text":"关于图像的k空间到底是什么意思呢，总的来说就算傅里叶域变换后的一种图，不能让人感性的感受到图，但是经过傅里叶反变换，总是能够变回原来的图像具体可见下面两篇博客k空间k空间","path":"2020/05/18/医学图像/图像的k空间/"},{"title":"矩阵的TV最小化","text":"在一个图像处理问题中如何有效的去除图像的噪声可以求解这样一个问题最小化图像的TV,TV即为梯度图像的一范数，当然需要加上正则化项，如果不加的化，全黑图才是最优的一个解，加上正则化之后可以获得图像的分块光滑图像，事实证明，效果很好。","path":"2020/05/18/医学图像/TV最小化/"},{"title":"softmax和SVM损失函数","text":"softmax可以参考softmax可以参考 softmax可以参考主要要理解熵的原理，以及交叉熵。以及softmax的正则化的内容 SVM损失函数可以参考SVM损失函数可以参考主要是要比正确分类的类别多出一个边界出来","path":"2020/05/18/深度学习/softmax和SVM损失函数/"},{"title":"Numpy中矩阵与向量的加法","text":"在Numpy中，矩阵与向量相加时，矩阵的每一行与向量相加，即要求矩阵的列数与向量的维数相等。&lt;!—hexoPostRenderEscape:import numpy as np x = np.array([[1, 2, 3], [4, 5, 6]]) array([[1, 2, 3],[4, 5, 6]])y = np.array([1, 2]) array([1, 2])z = np.array([1, 2, 3]) array([1, 2, 3])x + y 会报错x + z array([[2, 4, 6],[5, 7, 9]])&lt;/code&gt;&lt;/pre&gt;:hexoPostRenderEscape—&gt;","path":"2020/05/18/深度学习/numpy矩阵加法/"},{"title":"matlab并行","text":"parfor matlab用法matlab会弄出几个虚拟的小pc，一个算i=1:30部分循环,一个算i=50:80部分循环,再来一个算i=90:120部分循环，当然数字是我瞎编的，我是想说matlab将一个大循环分成小块，然后这些小块并行计算，最后再合在一起。这样，有一个问题，因为普通的循环是从i=1算到i=100，一个接一个算，如果下一次循环要依赖上一次循环怎么办？如果出现这种情况，那就不能用matlab的parfor了。用parfor的前提条件就是，循环的每次迭代独立，不相互依赖。举个简单的例子，计算1+2+3...+100就可以用parfor，但是如果计算斐波那契数列的前100个数字，那就不能用parfor了。","path":"2020/05/18/医学图像/matlab并行/"},{"title":"makedown数学公式写法","text":"此网站可以查看公式写法","path":"2020/05/18/文档相关/makedown数学公式写法/"},{"title":"conda 安装 pytorch","text":"关于conda安装pytorch的一些问题的总结 使用conda安装pytorch较为简单在pytorch官网选择自己需要的版本，以及是否带gpu的，我的由于是没有gpu的，所以是conda install pytorch torchvision cpuonly -c pytorch 但是下载的速度会很慢，而且会出现httperror,这时可以考虑更换源，选择国内的镜像源，例如清华的镜像更换镜像conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/pytorch/ 测试是否安装成功import torch 成功后代表安装成功 更多信息: 我的博客","path":"2020/05/18/深度学习/conda 安装 pytorch/"},{"title":"使用github+hexo部署博客","text":"可见这篇博客 更多信息: 我的博客","path":"2020/05/18/文档相关/github+hexo博客搭建/"},{"title":"图像生成","text":"可以参考这个博客图像生成cs231 同时这个人还总结了cs231的很多内容，可以都参考一下","path":"2020/05/18/深度学习/cs231图像生成/"}],"categories":[],"tags":[]}